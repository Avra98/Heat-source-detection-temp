{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n",
      "Epoch:1| Average Epoch loss:35.84172582048043409486| Ndiff loss:-13.9173364951|Sparsity loss:49.7590623156 \n",
      "tensor(-5.0163)\n",
      "tensor(-33.7797)\n",
      "Epoch:2| Average Epoch loss:26.70470602267111104311| Ndiff loss:-23.0844653505|Sparsity loss:49.7891713732 \n",
      "tensor(-5.0163)\n",
      "tensor(-64.2286)\n",
      "Epoch:3| Average Epoch loss:16.75217387267905877479| Ndiff loss:-33.0386043640|Sparsity loss:49.7907782366 \n",
      "tensor(-5.0163)\n",
      "tensor(-63.8692)\n",
      "Epoch:4| Average Epoch loss:9.45565267704918355207| Ndiff loss:-40.3433353892|Sparsity loss:49.7989880662 \n",
      "tensor(-5.0163)\n",
      "tensor(-52.6555)\n",
      "Epoch:5| Average Epoch loss:5.94835939578368932956| Ndiff loss:-43.8601927727|Sparsity loss:49.8085521685 \n",
      "tensor(-5.0163)\n",
      "tensor(-43.9161)\n",
      "Epoch:6| Average Epoch loss:4.18540060940408764623| Ndiff loss:-45.6285141320|Sparsity loss:49.8139147414 \n",
      "tensor(-5.0163)\n",
      "tensor(-36.9281)\n",
      "Epoch:7| Average Epoch loss:3.16913571589855891375| Ndiff loss:-46.6481935817|Sparsity loss:49.8173292976 \n",
      "tensor(-5.0163)\n",
      "tensor(-31.4324)\n",
      "Epoch:8| Average Epoch loss:2.52269141508352578995| Ndiff loss:-47.2966979370|Sparsity loss:49.8193893521 \n",
      "tensor(-5.0163)\n",
      "tensor(-26.5007)\n",
      "Epoch:9| Average Epoch loss:2.08085973857623729444| Ndiff loss:-47.7401335770|Sparsity loss:49.8209933156 \n",
      "tensor(-5.0163)\n",
      "tensor(-22.4396)\n",
      "Epoch:10| Average Epoch loss:1.76076738687547562634| Ndiff loss:-48.0614298934|Sparsity loss:49.8221972802 \n",
      "tensor(-5.0163)\n",
      "tensor(-19.1284)\n",
      "Epoch:11| Average Epoch loss:1.51883052155010789264| Ndiff loss:-48.3042323642|Sparsity loss:49.8230628858 \n",
      "tensor(-5.0163)\n",
      "tensor(-16.2161)\n",
      "Epoch:12| Average Epoch loss:1.33176492990821371265| Ndiff loss:-48.4918373453|Sparsity loss:49.8236022752 \n",
      "tensor(-5.0163)\n",
      "tensor(-13.1168)\n",
      "Epoch:13| Average Epoch loss:1.18206040073681695191| Ndiff loss:-48.6422372818|Sparsity loss:49.8242976825 \n",
      "tensor(-5.0163)\n",
      "tensor(-10.8175)\n",
      "Epoch:14| Average Epoch loss:1.05986949948894904061| Ndiff loss:-48.7648340395|Sparsity loss:49.8247035389 \n",
      "tensor(-5.0163)\n",
      "tensor(-8.5619)\n",
      "Epoch:15| Average Epoch loss:0.95890579021916066971| Ndiff loss:-48.8661371840|Sparsity loss:49.8250429742 \n",
      "tensor(-5.0163)\n",
      "tensor(-6.3675)\n",
      "Epoch:16| Average Epoch loss:0.87381786848654618982| Ndiff loss:-48.9515845358|Sparsity loss:49.8254024043 \n",
      "tensor(-5.0163)\n",
      "tensor(-4.4664)\n",
      "Epoch:17| Average Epoch loss:0.80069253921656702300| Ndiff loss:-49.0250354126|Sparsity loss:49.8257279518 \n",
      "tensor(-5.0163)\n",
      "tensor(-2.9059)\n",
      "Epoch:18| Average Epoch loss:0.73825682848217077936| Ndiff loss:-49.0875993428|Sparsity loss:49.8258561713 \n",
      "tensor(-5.0163)\n",
      "tensor(-1.0211)\n",
      "Epoch:19| Average Epoch loss:0.68376401377408924098| Ndiff loss:-49.1423538103|Sparsity loss:49.8261178241 \n",
      "tensor(-5.0163)\n",
      "tensor(0.5115)\n",
      "Epoch:20| Average Epoch loss:0.63572276934498161971| Ndiff loss:-49.1905698599|Sparsity loss:49.8262926293 \n",
      "tensor(-5.0163)\n",
      "tensor(1.9956)\n",
      "Epoch:21| Average Epoch loss:0.59341614449279633803| Ndiff loss:-49.2330249403|Sparsity loss:49.8264410848 \n",
      "tensor(-5.0163)\n",
      "tensor(3.4587)\n",
      "Epoch:22| Average Epoch loss:0.55571043836302969066| Ndiff loss:-49.2709144712|Sparsity loss:49.8266249095 \n",
      "tensor(-5.0163)\n",
      "tensor(4.6604)\n",
      "Epoch:23| Average Epoch loss:0.52193447120682046059| Ndiff loss:-49.3047968534|Sparsity loss:49.8267313246 \n",
      "tensor(-5.0163)\n",
      "tensor(5.9127)\n",
      "Epoch:24| Average Epoch loss:0.49139595888286774494| Ndiff loss:-49.3354532331|Sparsity loss:49.8268491920 \n",
      "tensor(-5.0163)\n",
      "tensor(7.0919)\n",
      "Epoch:25| Average Epoch loss:0.46380743937987822800| Ndiff loss:-49.3631455489|Sparsity loss:49.8269529883 \n",
      "tensor(-5.0163)\n",
      "tensor(8.2153)\n",
      "Epoch:26| Average Epoch loss:0.43864286068528657303| Ndiff loss:-49.3883911623|Sparsity loss:49.8270340230 \n",
      "tensor(-5.0163)\n",
      "tensor(9.3790)\n",
      "Epoch:27| Average Epoch loss:0.41575603991118648128| Ndiff loss:-49.4113899557|Sparsity loss:49.8271459956 \n",
      "tensor(-5.0163)\n",
      "tensor(10.3622)\n",
      "Epoch:28| Average Epoch loss:0.39467339677848539692| Ndiff loss:-49.4325610876|Sparsity loss:49.8272344844 \n",
      "tensor(-5.0163)\n",
      "tensor(11.2689)\n",
      "Epoch:29| Average Epoch loss:0.37526476186494606146| Ndiff loss:-49.4520258219|Sparsity loss:49.8272905838 \n",
      "tensor(-5.0163)\n",
      "tensor(12.2215)\n",
      "Epoch:30| Average Epoch loss:0.35741583095522799773| Ndiff loss:-49.4699487200|Sparsity loss:49.8273645509 \n",
      "tensor(-5.0163)\n",
      "tensor(13.1112)\n",
      "Epoch:31| Average Epoch loss:0.34085121529028306053| Ndiff loss:-49.4865641920|Sparsity loss:49.8274154073 \n",
      "tensor(-5.0163)\n",
      "tensor(14.0231)\n",
      "Epoch:32| Average Epoch loss:0.32529028217073691076| Ndiff loss:-49.5021883686|Sparsity loss:49.8274786507 \n",
      "tensor(-5.0163)\n",
      "tensor(14.8746)\n",
      "Epoch:33| Average Epoch loss:0.31093293677776479011| Ndiff loss:-49.5165994837|Sparsity loss:49.8275324205 \n",
      "tensor(-5.0163)\n",
      "tensor(15.6910)\n",
      "Epoch:34| Average Epoch loss:0.29729356505255882803| Ndiff loss:-49.5302947195|Sparsity loss:49.8275882846 \n",
      "tensor(-5.0163)\n",
      "tensor(16.4493)\n",
      "Epoch:35| Average Epoch loss:0.28460469000274141171| Ndiff loss:-49.5430256150|Sparsity loss:49.8276303050 \n",
      "tensor(-5.0163)\n",
      "tensor(17.1976)\n",
      "Epoch:36| Average Epoch loss:0.27242452497647640097| Ndiff loss:-49.5552515920|Sparsity loss:49.8276761170 \n",
      "tensor(-5.0163)\n",
      "tensor(17.8956)\n",
      "Epoch:37| Average Epoch loss:0.26087293195061495021| Ndiff loss:-49.5668439521|Sparsity loss:49.8277168841 \n",
      "tensor(-5.0163)\n",
      "tensor(18.5637)\n",
      "Epoch:38| Average Epoch loss:0.24978513434232971213| Ndiff loss:-49.5779539702|Sparsity loss:49.8277391046 \n",
      "tensor(-5.0163)\n",
      "tensor(19.2645)\n",
      "Epoch:39| Average Epoch loss:0.23884601730250626384| Ndiff loss:-49.5889302982|Sparsity loss:49.8277763155 \n",
      "tensor(-5.0163)\n",
      "tensor(19.8923)\n",
      "Epoch:40| Average Epoch loss:0.22770428871453141095| Ndiff loss:-49.6001027756|Sparsity loss:49.8278070644 \n",
      "tensor(-5.0163)\n",
      "tensor(20.4685)\n",
      "Epoch:41| Average Epoch loss:0.21637365046250897627| Ndiff loss:-49.6114543093|Sparsity loss:49.8278279597 \n",
      "tensor(-5.0163)\n",
      "tensor(21.0132)\n",
      "Epoch:42| Average Epoch loss:0.20417765648804694911| Ndiff loss:-49.6236773561|Sparsity loss:49.8278550126 \n",
      "tensor(-5.0163)\n",
      "tensor(21.4795)\n",
      "Epoch:43| Average Epoch loss:0.19186235762606665411| Ndiff loss:-49.6359669284|Sparsity loss:49.8278292860 \n",
      "tensor(-5.0163)\n",
      "tensor(22.1255)\n",
      "Epoch:44| Average Epoch loss:0.18104177634075765968| Ndiff loss:-49.6467959852|Sparsity loss:49.8278377615 \n",
      "tensor(-5.0163)\n",
      "tensor(22.7423)\n",
      "Epoch:45| Average Epoch loss:0.17189151201626629017| Ndiff loss:-49.6559572873|Sparsity loss:49.8278487993 \n",
      "tensor(-5.0163)\n",
      "tensor(23.3774)\n",
      "Epoch:46| Average Epoch loss:0.16372004888816485413| Ndiff loss:-49.6641457308|Sparsity loss:49.8278657797 \n",
      "tensor(-5.0163)\n",
      "tensor(24.0233)\n",
      "Epoch:47| Average Epoch loss:0.15577980729708051921| Ndiff loss:-49.6721197124|Sparsity loss:49.8278995197 \n",
      "tensor(-5.0163)\n",
      "tensor(24.5492)\n",
      "Epoch:48| Average Epoch loss:0.14780048740521717354| Ndiff loss:-49.6801218792|Sparsity loss:49.8279223666 \n",
      "tensor(-5.0163)\n",
      "tensor(25.0210)\n",
      "Epoch:49| Average Epoch loss:0.13940013308985083063| Ndiff loss:-49.6885460921|Sparsity loss:49.8279462252 \n",
      "tensor(-5.0163)\n",
      "tensor(25.3928)\n",
      "Epoch:50| Average Epoch loss:0.12981872477695372003| Ndiff loss:-49.6980933997|Sparsity loss:49.8279121245 \n",
      "tensor(-5.0163)\n",
      "tensor(25.8579)\n",
      "Epoch:51| Average Epoch loss:0.11905504465094393640| Ndiff loss:-49.7088497545|Sparsity loss:49.8279047991 \n",
      "tensor(-5.0163)\n",
      "tensor(26.2836)\n",
      "Epoch:52| Average Epoch loss:0.11037906013253756532| Ndiff loss:-49.7174827836|Sparsity loss:49.8278618437 \n",
      "tensor(-5.0163)\n",
      "tensor(26.8733)\n",
      "Epoch:53| Average Epoch loss:0.10442988215299367494| Ndiff loss:-49.7234547030|Sparsity loss:49.8278845852 \n",
      "tensor(-5.0163)\n",
      "tensor(27.4269)\n",
      "Epoch:54| Average Epoch loss:0.09893560073740835514| Ndiff loss:-49.7289684682|Sparsity loss:49.8279040689 \n",
      "tensor(-5.0163)\n",
      "tensor(27.9781)\n",
      "Epoch:55| Average Epoch loss:0.09374398572418012054| Ndiff loss:-49.7341927227|Sparsity loss:49.8279367085 \n",
      "tensor(-5.0163)\n",
      "tensor(28.4490)\n",
      "Epoch:56| Average Epoch loss:0.08885554278577956211| Ndiff loss:-49.7391097854|Sparsity loss:49.8279653282 \n",
      "tensor(-5.0163)\n",
      "tensor(28.8605)\n",
      "Epoch:57| Average Epoch loss:0.08409046618670501516| Ndiff loss:-49.7438876567|Sparsity loss:49.8279781229 \n",
      "tensor(-5.0163)\n",
      "tensor(29.2824)\n",
      "Epoch:58| Average Epoch loss:0.07955675961826041975| Ndiff loss:-49.7484354871|Sparsity loss:49.8279922467 \n",
      "tensor(-5.0163)\n",
      "tensor(29.7276)\n",
      "Epoch:59| Average Epoch loss:0.07522338856480893787| Ndiff loss:-49.7528033316|Sparsity loss:49.8280267202 \n",
      "tensor(-5.0163)\n",
      "tensor(30.0731)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:60| Average Epoch loss:0.07098213924523871787| Ndiff loss:-49.7570460299|Sparsity loss:49.8280281691 \n",
      "tensor(-5.0163)\n",
      "tensor(30.4805)\n",
      "Epoch:61| Average Epoch loss:0.06690304692519274954| Ndiff loss:-49.7611465248|Sparsity loss:49.8280495717 \n",
      "tensor(-5.0163)\n",
      "tensor(30.8671)\n",
      "Epoch:62| Average Epoch loss:0.06300283539967803381| Ndiff loss:-49.7650665592|Sparsity loss:49.8280693946 \n",
      "tensor(-5.0163)\n",
      "tensor(31.2090)\n",
      "Epoch:63| Average Epoch loss:0.05923912387184810530| Ndiff loss:-49.7688480185|Sparsity loss:49.8280871424 \n",
      "tensor(-5.0163)\n",
      "tensor(31.5493)\n",
      "Epoch:64| Average Epoch loss:0.05559732614133178902| Ndiff loss:-49.7724951262|Sparsity loss:49.8280924523 \n",
      "tensor(-5.0163)\n",
      "tensor(31.9148)\n",
      "Epoch:65| Average Epoch loss:0.05206985673510584195| Ndiff loss:-49.7760421952|Sparsity loss:49.8281120520 \n",
      "tensor(-5.0163)\n",
      "tensor(32.2557)\n",
      "Epoch:66| Average Epoch loss:0.04865837900958069895| Ndiff loss:-49.7794734385|Sparsity loss:49.8281318175 \n",
      "tensor(-5.0163)\n",
      "tensor(32.5406)\n",
      "Epoch:67| Average Epoch loss:0.04535404982361276177| Ndiff loss:-49.7827745565|Sparsity loss:49.8281286064 \n",
      "tensor(-5.0163)\n",
      "tensor(32.9291)\n",
      "Epoch:68| Average Epoch loss:0.04218298239415139983| Ndiff loss:-49.7859730704|Sparsity loss:49.8281560528 \n",
      "tensor(-5.0163)\n",
      "tensor(33.2176)\n",
      "Epoch:69| Average Epoch loss:0.03905943437920535166| Ndiff loss:-49.7891077025|Sparsity loss:49.8281671369 \n",
      "tensor(-5.0163)\n",
      "tensor(33.5157)\n",
      "Epoch:70| Average Epoch loss:0.03602953641797491946| Ndiff loss:-49.7921404974|Sparsity loss:49.8281700338 \n",
      "tensor(-5.0163)\n",
      "tensor(33.8541)\n",
      "Epoch:71| Average Epoch loss:0.03310580046315002301| Ndiff loss:-49.7950797382|Sparsity loss:49.8281855387 \n",
      "tensor(-5.0163)\n",
      "tensor(34.1783)\n",
      "Epoch:72| Average Epoch loss:0.03013010930430858048| Ndiff loss:-49.7980648882|Sparsity loss:49.8281949975 \n",
      "tensor(-5.0163)\n",
      "tensor(34.5045)\n",
      "Epoch:73| Average Epoch loss:0.02726694805659275050| Ndiff loss:-49.8009454157|Sparsity loss:49.8282123638 \n",
      "tensor(-5.0163)\n",
      "tensor(34.7884)\n",
      "Epoch:74| Average Epoch loss:0.02461897072926275479| Ndiff loss:-49.8035998672|Sparsity loss:49.8282188379 \n",
      "tensor(-5.0163)\n",
      "tensor(35.0912)\n",
      "Epoch:75| Average Epoch loss:0.02201898000848877268| Ndiff loss:-49.8062140096|Sparsity loss:49.8282329896 \n",
      "tensor(-5.0163)\n",
      "tensor(35.3541)\n",
      "Epoch:76| Average Epoch loss:0.01947011537460083611| Ndiff loss:-49.8087661067|Sparsity loss:49.8282362220 \n",
      "tensor(-5.0163)\n",
      "tensor(35.6608)\n",
      "Epoch:77| Average Epoch loss:0.01703520521894969636| Ndiff loss:-49.8112138018|Sparsity loss:49.8282490071 \n",
      "tensor(-5.0163)\n",
      "tensor(35.9448)\n",
      "Epoch:78| Average Epoch loss:0.01466208931290048471| Ndiff loss:-49.8135997933|Sparsity loss:49.8282618826 \n",
      "tensor(-5.0163)\n",
      "tensor(36.2166)\n",
      "Epoch:79| Average Epoch loss:0.01226001549507276661| Ndiff loss:-49.8160081413|Sparsity loss:49.8282681567 \n",
      "tensor(-5.0163)\n",
      "tensor(36.4962)\n",
      "Epoch:80| Average Epoch loss:0.00999871342990211846| Ndiff loss:-49.8182827040|Sparsity loss:49.8282814175 \n",
      "tensor(-5.0163)\n",
      "tensor(36.7414)\n",
      "Epoch:81| Average Epoch loss:0.00780404655353924160| Ndiff loss:-49.8204821023|Sparsity loss:49.8282861488 \n",
      "tensor(-5.0163)\n",
      "tensor(37.0063)\n",
      "Epoch:82| Average Epoch loss:0.00564131961512615021| Ndiff loss:-49.8226525759|Sparsity loss:49.8282938955 \n",
      "tensor(-5.0163)\n",
      "tensor(37.2762)\n",
      "Epoch:83| Average Epoch loss:0.00355718552160726956| Ndiff loss:-49.8247499562|Sparsity loss:49.8283071417 \n",
      "tensor(-5.0163)\n",
      "tensor(37.5185)\n",
      "Epoch:84| Average Epoch loss:0.00150497047490934688| Ndiff loss:-49.8267990308|Sparsity loss:49.8283040013 \n",
      "tensor(-5.0163)\n",
      "tensor(37.8172)\n",
      "Epoch:85| Average Epoch loss:-0.00046666148828972750| Ndiff loss:-49.8287932599|Sparsity loss:49.8283265985 \n",
      "tensor(-5.0163)\n",
      "tensor(38.0353)\n",
      "Epoch:86| Average Epoch loss:-0.00243794802496211105| Ndiff loss:-49.8307631217|Sparsity loss:49.8283251737 \n",
      "tensor(-5.0163)\n",
      "tensor(38.2876)\n",
      "Epoch:87| Average Epoch loss:-0.00434103080300434711| Ndiff loss:-49.8326740764|Sparsity loss:49.8283330456 \n",
      "tensor(-5.0163)\n",
      "tensor(38.5684)\n",
      "Epoch:88| Average Epoch loss:-0.00618332187972114866| Ndiff loss:-49.8345283911|Sparsity loss:49.8283450693 \n",
      "tensor(-5.0163)\n",
      "tensor(38.7905)\n",
      "Epoch:89| Average Epoch loss:-0.00801764705381636904| Ndiff loss:-49.8363693722|Sparsity loss:49.8283517251 \n",
      "tensor(-5.0163)\n",
      "tensor(39.0122)\n",
      "Epoch:90| Average Epoch loss:-0.00978975477302097136| Ndiff loss:-49.8381440523|Sparsity loss:49.8283542976 \n",
      "tensor(-5.0163)\n",
      "tensor(39.2676)\n",
      "Epoch:91| Average Epoch loss:-0.01151490422033063510| Ndiff loss:-49.8398805652|Sparsity loss:49.8283656610 \n",
      "tensor(-5.0163)\n",
      "tensor(39.4948)\n",
      "Epoch:92| Average Epoch loss:-0.01322239481223716831| Ndiff loss:-49.8415959485|Sparsity loss:49.8283735537 \n",
      "tensor(-5.0163)\n",
      "tensor(39.7149)\n",
      "Epoch:93| Average Epoch loss:-0.01488535675957475962| Ndiff loss:-49.8432612050|Sparsity loss:49.8283758483 \n",
      "tensor(-5.0163)\n",
      "tensor(39.9557)\n",
      "Epoch:94| Average Epoch loss:-0.01650308876252597895| Ndiff loss:-49.8448890693|Sparsity loss:49.8283859805 \n",
      "tensor(-5.0163)\n",
      "tensor(40.1615)\n",
      "Epoch:95| Average Epoch loss:-0.01808661234033850582| Ndiff loss:-49.8464777870|Sparsity loss:49.8283911747 \n",
      "tensor(-5.0163)\n",
      "tensor(40.3843)\n",
      "Epoch:96| Average Epoch loss:-0.01964825400713405418| Ndiff loss:-49.8480468091|Sparsity loss:49.8283985551 \n",
      "tensor(-5.0163)\n",
      "tensor(40.5933)\n",
      "Epoch:97| Average Epoch loss:-0.02117509107939320734| Ndiff loss:-49.8495748432|Sparsity loss:49.8283997521 \n",
      "tensor(-5.0163)\n",
      "tensor(40.8389)\n",
      "Epoch:98| Average Epoch loss:-0.02266389098975491595| Ndiff loss:-49.8510754992|Sparsity loss:49.8284116082 \n",
      "tensor(-5.0163)\n",
      "tensor(41.0385)\n",
      "Epoch:99| Average Epoch loss:-0.02412539352490128408| Ndiff loss:-49.8525409841|Sparsity loss:49.8284155905 \n",
      "tensor(-5.0163)\n",
      "tensor(41.2408)\n",
      "Epoch:100| Average Epoch loss:-0.02555669347927667923| Ndiff loss:-49.8539777714|Sparsity loss:49.8284210779 \n",
      "tensor(-5.0163)\n",
      "tensor(41.4514)\n",
      "Epoch:101| Average Epoch loss:-0.02695643372666801929| Ndiff loss:-49.8553829061|Sparsity loss:49.8284264724 \n",
      "tensor(-5.0163)\n",
      "tensor(41.6601)\n",
      "Epoch:102| Average Epoch loss:-0.02834063564441811900| Ndiff loss:-49.8567710179|Sparsity loss:49.8284303823 \n",
      "tensor(-5.0163)\n",
      "tensor(41.8797)\n",
      "Epoch:103| Average Epoch loss:-0.02969829723733576066| Ndiff loss:-49.8581390680|Sparsity loss:49.8284407708 \n",
      "tensor(-5.0163)\n",
      "tensor(42.0648)\n",
      "Epoch:104| Average Epoch loss:-0.03102057515713833521| Ndiff loss:-49.8594592593|Sparsity loss:49.8284386842 \n",
      "tensor(-5.0163)\n",
      "tensor(42.2950)\n",
      "Epoch:105| Average Epoch loss:-0.03231196240422681137| Ndiff loss:-49.8607643185|Sparsity loss:49.8284523561 \n",
      "tensor(-5.0163)\n",
      "tensor(42.4687)\n",
      "Epoch:106| Average Epoch loss:-0.03359333794581252641| Ndiff loss:-49.8620428180|Sparsity loss:49.8284494800 \n",
      "tensor(-5.0163)\n",
      "tensor(42.6860)\n",
      "Epoch:107| Average Epoch loss:-0.03483083109049781717| Ndiff loss:-49.8632918814|Sparsity loss:49.8284610503 \n",
      "tensor(-5.0163)\n",
      "tensor(42.8717)\n",
      "Epoch:108| Average Epoch loss:-0.03607666243283544349| Ndiff loss:-49.8645396975|Sparsity loss:49.8284630351 \n",
      "tensor(-5.0163)\n",
      "tensor(43.0693)\n",
      "Epoch:109| Average Epoch loss:-0.03728065406910532897| Ndiff loss:-49.8657507029|Sparsity loss:49.8284700489 \n",
      "tensor(-5.0163)\n",
      "tensor(43.2481)\n",
      "Epoch:110| Average Epoch loss:-0.03846862565303826170| Ndiff loss:-49.8669418193|Sparsity loss:49.8284731936 \n",
      "tensor(-5.0163)\n",
      "tensor(43.4382)\n",
      "Epoch:111| Average Epoch loss:-0.03962667192617056605| Ndiff loss:-49.8681076864|Sparsity loss:49.8284810145 \n",
      "tensor(-5.0163)\n",
      "tensor(43.6024)\n",
      "Epoch:112| Average Epoch loss:-0.04077439871942564048| Ndiff loss:-49.8692536121|Sparsity loss:49.8284792134 \n",
      "tensor(-5.0163)\n",
      "tensor(43.8138)\n",
      "Epoch:113| Average Epoch loss:-0.04189134539725753587| Ndiff loss:-49.8703786039|Sparsity loss:49.8284872585 \n",
      "tensor(-5.0163)\n",
      "tensor(44.0007)\n",
      "Epoch:114| Average Epoch loss:-0.04298654128902986565| Ndiff loss:-49.8714801837|Sparsity loss:49.8284936424 \n",
      "tensor(-5.0163)\n",
      "tensor(44.1682)\n",
      "Epoch:115| Average Epoch loss:-0.04407659593924546232| Ndiff loss:-49.8725733965|Sparsity loss:49.8284968006 \n",
      "tensor(-5.0163)\n",
      "tensor(44.3459)\n",
      "Epoch:116| Average Epoch loss:-0.04514206448147382866| Ndiff loss:-49.8736411931|Sparsity loss:49.8284991286 \n",
      "tensor(-5.0163)\n",
      "tensor(44.5387)\n",
      "Epoch:117| Average Epoch loss:-0.04620662707915891565| Ndiff loss:-49.8747121547|Sparsity loss:49.8285055276 \n",
      "tensor(-5.0163)\n",
      "tensor(44.7066)\n",
      "Epoch:118| Average Epoch loss:-0.04725299895432518577| Ndiff loss:-49.8757644347|Sparsity loss:49.8285114357 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-5.0163)\n",
      "tensor(44.8659)\n",
      "Epoch:119| Average Epoch loss:-0.04828026172125356175| Ndiff loss:-49.8767938429|Sparsity loss:49.8285135811 \n",
      "tensor(-5.0163)\n",
      "tensor(45.0420)\n",
      "Epoch:120| Average Epoch loss:-0.04927987376043792972| Ndiff loss:-49.8777963751|Sparsity loss:49.8285165014 \n",
      "tensor(-5.0163)\n",
      "tensor(45.2331)\n",
      "Epoch:121| Average Epoch loss:-0.05028279628928760542| Ndiff loss:-49.8788071015|Sparsity loss:49.8285243053 \n",
      "tensor(-5.0163)\n",
      "tensor(45.3838)\n",
      "Epoch:122| Average Epoch loss:-0.05124729517602114731| Ndiff loss:-49.8797721124|Sparsity loss:49.8285248172 \n",
      "tensor(-5.0163)\n",
      "tensor(45.5491)\n",
      "Epoch:123| Average Epoch loss:-0.05221229802392891861| Ndiff loss:-49.8807452592|Sparsity loss:49.8285329611 \n",
      "tensor(-5.0163)\n",
      "tensor(45.7010)\n",
      "Epoch:124| Average Epoch loss:-0.05317126251838880796| Ndiff loss:-49.8817012250|Sparsity loss:49.8285299625 \n",
      "tensor(-5.0163)\n",
      "tensor(45.8953)\n",
      "Epoch:125| Average Epoch loss:-0.05409153034412818306| Ndiff loss:-49.8826325148|Sparsity loss:49.8285409844 \n",
      "tensor(-5.0163)\n",
      "tensor(46.0375)\n",
      "Epoch:126| Average Epoch loss:-0.05502056857444435900| Ndiff loss:-49.8835608938|Sparsity loss:49.8285403253 \n",
      "tensor(-5.0163)\n",
      "tensor(46.2029)\n",
      "Epoch:127| Average Epoch loss:-0.05592282675833596534| Ndiff loss:-49.8844701739|Sparsity loss:49.8285473472 \n",
      "tensor(-5.0163)\n",
      "tensor(46.3464)\n",
      "Epoch:128| Average Epoch loss:-0.05680979603579277420| Ndiff loss:-49.8853590397|Sparsity loss:49.8285492436 \n",
      "tensor(-5.0163)\n",
      "tensor(46.4949)\n",
      "Epoch:129| Average Epoch loss:-0.05768110324430213848| Ndiff loss:-49.8862320873|Sparsity loss:49.8285509840 \n",
      "tensor(-5.0163)\n",
      "tensor(46.6569)\n",
      "Epoch:130| Average Epoch loss:-0.05857640566321167808| Ndiff loss:-49.8871335684|Sparsity loss:49.8285571627 \n",
      "tensor(-5.0163)\n",
      "tensor(46.8069)\n",
      "Epoch:131| Average Epoch loss:-0.05948141206495134031| Ndiff loss:-49.8880417625|Sparsity loss:49.8285603504 \n",
      "tensor(-5.0163)\n",
      "tensor(46.9497)\n",
      "Epoch:132| Average Epoch loss:-0.06030355352957488674| Ndiff loss:-49.8888661297|Sparsity loss:49.8285625761 \n",
      "tensor(-5.0163)\n",
      "tensor(47.1118)\n",
      "Epoch:133| Average Epoch loss:-0.06111489894300229514| Ndiff loss:-49.8896818431|Sparsity loss:49.8285669442 \n",
      "tensor(-5.0163)\n",
      "tensor(47.2551)\n",
      "Epoch:134| Average Epoch loss:-0.06191790585157816440| Ndiff loss:-49.8904874009|Sparsity loss:49.8285694951 \n",
      "tensor(-5.0163)\n",
      "tensor(47.4088)\n",
      "Epoch:135| Average Epoch loss:-0.06270638586071639042| Ndiff loss:-49.8912805968|Sparsity loss:49.8285742109 \n",
      "tensor(-5.0163)\n",
      "tensor(47.5505)\n",
      "Epoch:136| Average Epoch loss:-0.06348206871861981904| Ndiff loss:-49.8920563117|Sparsity loss:49.8285742429 \n",
      "tensor(-5.0163)\n",
      "tensor(47.7145)\n",
      "Epoch:137| Average Epoch loss:-0.06424456988916284195| Ndiff loss:-49.8928264323|Sparsity loss:49.8285818624 \n",
      "tensor(-5.0163)\n",
      "tensor(47.8461)\n",
      "Epoch:138| Average Epoch loss:-0.06500257286099318799| Ndiff loss:-49.8935861264|Sparsity loss:49.8285835535 \n",
      "tensor(-5.0163)\n",
      "tensor(47.9793)\n",
      "Epoch:139| Average Epoch loss:-0.06574348589680825694| Ndiff loss:-49.8943288192|Sparsity loss:49.8285853333 \n",
      "tensor(-5.0163)\n",
      "tensor(48.1356)\n",
      "Epoch:140| Average Epoch loss:-0.06647894384216199160| Ndiff loss:-49.8950698843|Sparsity loss:49.8285909405 \n",
      "tensor(-5.0163)\n",
      "tensor(48.2639)\n",
      "Epoch:141| Average Epoch loss:-0.06720295350917974975| Ndiff loss:-49.8957930663|Sparsity loss:49.8285901127 \n",
      "tensor(-5.0163)\n",
      "tensor(48.4124)\n",
      "Epoch:142| Average Epoch loss:-0.06791533291105306125| Ndiff loss:-49.8965117359|Sparsity loss:49.8285964030 \n",
      "tensor(-5.0163)\n",
      "tensor(48.5440)\n",
      "Epoch:143| Average Epoch loss:-0.06862526670784260818| Ndiff loss:-49.8972204802|Sparsity loss:49.8285952135 \n",
      "tensor(-5.0163)\n",
      "tensor(48.6960)\n",
      "Epoch:144| Average Epoch loss:-0.06931484470403424802| Ndiff loss:-49.8979181795|Sparsity loss:49.8286033348 \n",
      "tensor(-5.0163)\n",
      "tensor(48.8098)\n",
      "Epoch:145| Average Epoch loss:-0.07000351342237465246| Ndiff loss:-49.8986033479|Sparsity loss:49.8285998344 \n",
      "tensor(-5.0163)\n",
      "tensor(48.9657)\n",
      "Epoch:146| Average Epoch loss:-0.07067261115810039018| Ndiff loss:-49.8992818860|Sparsity loss:49.8286092749 \n",
      "tensor(-5.0163)\n",
      "tensor(49.0859)\n",
      "Epoch:147| Average Epoch loss:-0.07134687062085652565| Ndiff loss:-49.8999530385|Sparsity loss:49.8286061679 \n",
      "tensor(-5.0163)\n",
      "tensor(49.2321)\n",
      "Epoch:148| Average Epoch loss:-0.07200560423636580276| Ndiff loss:-49.9006202592|Sparsity loss:49.8286146550 \n",
      "tensor(-5.0163)\n",
      "tensor(49.3410)\n",
      "Epoch:149| Average Epoch loss:-0.07265555764639902714| Ndiff loss:-49.9012668595|Sparsity loss:49.8286113018 \n",
      "tensor(-5.0163)\n",
      "tensor(49.4959)\n",
      "Epoch:150| Average Epoch loss:-0.07329186734805680226| Ndiff loss:-49.9019106063|Sparsity loss:49.8286187390 \n",
      "tensor(-5.0163)\n",
      "tensor(49.6219)\n",
      "Epoch:151| Average Epoch loss:-0.07393357890855353776| Ndiff loss:-49.9025515475|Sparsity loss:49.8286179686 \n",
      "tensor(-5.0163)\n",
      "tensor(49.7579)\n",
      "Epoch:152| Average Epoch loss:-0.07455445260105422745| Ndiff loss:-49.9031771082|Sparsity loss:49.8286226556 \n",
      "tensor(-5.0163)\n",
      "tensor(49.8906)\n",
      "Epoch:153| Average Epoch loss:-0.07518033748759596346| Ndiff loss:-49.9038035712|Sparsity loss:49.8286232337 \n",
      "tensor(-5.0163)\n",
      "tensor(50.0271)\n",
      "Epoch:154| Average Epoch loss:-0.07578260688682982027| Ndiff loss:-49.9044121537|Sparsity loss:49.8286295468 \n",
      "tensor(-5.0163)\n",
      "tensor(50.1331)\n",
      "Epoch:155| Average Epoch loss:-0.07638797141158211457| Ndiff loss:-49.9050164364|Sparsity loss:49.8286284650 \n",
      "tensor(-5.0163)\n",
      "tensor(50.2649)\n",
      "Epoch:156| Average Epoch loss:-0.07698612403954009642| Ndiff loss:-49.9056191373|Sparsity loss:49.8286330132 \n",
      "tensor(-5.0163)\n",
      "tensor(50.3921)\n",
      "Epoch:157| Average Epoch loss:-0.07756970204010116277| Ndiff loss:-49.9062036572|Sparsity loss:49.8286339552 \n",
      "tensor(-5.0163)\n",
      "tensor(50.5104)\n",
      "Epoch:158| Average Epoch loss:-0.07814808493488298313| Ndiff loss:-49.9067858167|Sparsity loss:49.8286377318 \n",
      "tensor(-5.0163)\n",
      "tensor(50.6376)\n",
      "Epoch:159| Average Epoch loss:-0.07872831981870120899| Ndiff loss:-49.9073659837|Sparsity loss:49.8286376639 \n",
      "tensor(-5.0163)\n",
      "tensor(50.7730)\n",
      "Epoch:160| Average Epoch loss:-0.07928901759790187020| Ndiff loss:-49.9079331909|Sparsity loss:49.8286441733 \n",
      "tensor(-5.0163)\n",
      "tensor(50.8684)\n",
      "Epoch:161| Average Epoch loss:-0.07985612461003041562| Ndiff loss:-49.9084989428|Sparsity loss:49.8286428182 \n",
      "tensor(-5.0163)\n",
      "tensor(50.9998)\n",
      "Epoch:162| Average Epoch loss:-0.08043130195241982028| Ndiff loss:-49.9090789579|Sparsity loss:49.8286476560 \n",
      "tensor(-5.0163)\n",
      "tensor(51.1167)\n",
      "Epoch:163| Average Epoch loss:-0.08099222769525285526| Ndiff loss:-49.9096407703|Sparsity loss:49.8286485426 \n",
      "tensor(-5.0163)\n",
      "tensor(51.2355)\n",
      "Epoch:164| Average Epoch loss:-0.08153760629018454165| Ndiff loss:-49.9101910514|Sparsity loss:49.8286534451 \n",
      "tensor(-5.0163)\n",
      "tensor(51.3453)\n",
      "Epoch:165| Average Epoch loss:-0.08207503034025778743| Ndiff loss:-49.9107254393|Sparsity loss:49.8286504090 \n",
      "tensor(-5.0163)\n",
      "tensor(51.4884)\n",
      "Epoch:166| Average Epoch loss:-0.08258945004015355584| Ndiff loss:-49.9112476408|Sparsity loss:49.8286581907 \n",
      "tensor(-5.0163)\n",
      "tensor(51.5915)\n",
      "Epoch:167| Average Epoch loss:-0.08313032658669783359| Ndiff loss:-49.9117857783|Sparsity loss:49.8286554517 \n",
      "tensor(-5.0163)\n",
      "tensor(51.7230)\n",
      "Epoch:168| Average Epoch loss:-0.08363460987143550573| Ndiff loss:-49.9122964011|Sparsity loss:49.8286617912 \n",
      "tensor(-5.0163)\n",
      "tensor(51.8290)\n",
      "Epoch:169| Average Epoch loss:-0.08415364683937553991| Ndiff loss:-49.9128147421|Sparsity loss:49.8286610953 \n",
      "tensor(-5.0163)\n",
      "tensor(51.9438)\n",
      "Epoch:170| Average Epoch loss:-0.08465527117650929745| Ndiff loss:-49.9133210923|Sparsity loss:49.8286658211 \n",
      "tensor(-5.0163)\n",
      "tensor(52.0455)\n",
      "Epoch:171| Average Epoch loss:-0.08515658365729844581| Ndiff loss:-49.9138212638|Sparsity loss:49.8286646801 \n",
      "tensor(-5.0163)\n",
      "tensor(52.1708)\n",
      "Epoch:172| Average Epoch loss:-0.08564899838026186762| Ndiff loss:-49.9143183116|Sparsity loss:49.8286693132 \n",
      "tensor(-5.0163)\n",
      "tensor(52.2812)\n",
      "Epoch:173| Average Epoch loss:-0.08613936661726384614| Ndiff loss:-49.9148094110|Sparsity loss:49.8286700444 \n",
      "tensor(-5.0163)\n",
      "tensor(52.3900)\n",
      "Epoch:174| Average Epoch loss:-0.08662048257238591509| Ndiff loss:-49.9152931952|Sparsity loss:49.8286727127 \n",
      "tensor(-5.0163)\n",
      "tensor(52.5036)\n",
      "Epoch:175| Average Epoch loss:-0.08709488521708566577| Ndiff loss:-49.9157685975|Sparsity loss:49.8286737123 \n",
      "tensor(-5.0163)\n",
      "tensor(52.6177)\n",
      "Epoch:176| Average Epoch loss:-0.08756427442378840464| Ndiff loss:-49.9162416799|Sparsity loss:49.8286774055 \n",
      "tensor(-5.0163)\n",
      "tensor(52.7213)\n",
      "Epoch:177| Average Epoch loss:-0.08803121027950390476| Ndiff loss:-49.9167104987|Sparsity loss:49.8286792884 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-5.0163)\n",
      "tensor(52.8183)\n",
      "Epoch:178| Average Epoch loss:-0.08850348303238123049| Ndiff loss:-49.9171841590|Sparsity loss:49.8286806759 \n",
      "tensor(-5.0163)\n",
      "tensor(52.9281)\n",
      "Epoch:179| Average Epoch loss:-0.08896508502338523749| Ndiff loss:-49.9176474337|Sparsity loss:49.8286823487 \n",
      "tensor(-5.0163)\n",
      "tensor(53.0365)\n",
      "Epoch:180| Average Epoch loss:-0.08941801345256233935| Ndiff loss:-49.9181034982|Sparsity loss:49.8286854847 \n",
      "tensor(-5.0163)\n",
      "tensor(53.1318)\n",
      "Epoch:181| Average Epoch loss:-0.08987817318414631496| Ndiff loss:-49.9185628526|Sparsity loss:49.8286846794 \n",
      "tensor(-5.0163)\n",
      "tensor(53.2584)\n",
      "Epoch:182| Average Epoch loss:-0.09032747041682674671| Ndiff loss:-49.9190179662|Sparsity loss:49.8286904958 \n",
      "tensor(-5.0163)\n",
      "tensor(53.3468)\n",
      "Epoch:183| Average Epoch loss:-0.09077222932001068056| Ndiff loss:-49.9194597631|Sparsity loss:49.8286875338 \n",
      "tensor(-5.0163)\n",
      "tensor(53.4763)\n",
      "Epoch:184| Average Epoch loss:-0.09120900052824509885| Ndiff loss:-49.9199031762|Sparsity loss:49.8286941757 \n",
      "tensor(-5.0163)\n",
      "tensor(53.5685)\n",
      "Epoch:185| Average Epoch loss:-0.09164109946014499519| Ndiff loss:-49.9203325029|Sparsity loss:49.8286914035 \n",
      "tensor(-5.0163)\n",
      "tensor(53.6850)\n",
      "Epoch:186| Average Epoch loss:-0.09206676137264421800| Ndiff loss:-49.9207655783|Sparsity loss:49.8286988170 \n",
      "tensor(-5.0163)\n",
      "tensor(53.7685)\n",
      "Epoch:187| Average Epoch loss:-0.09249078178506506265| Ndiff loss:-49.9211850261|Sparsity loss:49.8286942443 \n",
      "tensor(-5.0163)\n",
      "tensor(53.8880)\n",
      "Epoch:188| Average Epoch loss:-0.09291250581602344960| Ndiff loss:-49.9216141361|Sparsity loss:49.8287016303 \n",
      "tensor(-5.0163)\n",
      "tensor(53.9749)\n",
      "Epoch:189| Average Epoch loss:-0.09333969067637720718| Ndiff loss:-49.9220381219|Sparsity loss:49.8286984312 \n",
      "tensor(-5.0163)\n",
      "tensor(54.0924)\n",
      "Epoch:190| Average Epoch loss:-0.09374704518535439957| Ndiff loss:-49.9224504615|Sparsity loss:49.8287034163 \n",
      "tensor(-5.0163)\n",
      "tensor(54.1875)\n",
      "Epoch:191| Average Epoch loss:-0.09415560289568958297| Ndiff loss:-49.9228583765|Sparsity loss:49.8287027736 \n",
      "tensor(-5.0163)\n",
      "tensor(54.2930)\n",
      "Epoch:192| Average Epoch loss:-0.09455746553054725223| Ndiff loss:-49.9232650605|Sparsity loss:49.8287075949 \n",
      "tensor(-5.0163)\n",
      "tensor(54.3841)\n",
      "Epoch:193| Average Epoch loss:-0.09502630974234488326| Ndiff loss:-49.9237338288|Sparsity loss:49.8287075190 \n",
      "tensor(-5.0163)\n",
      "tensor(54.4720)\n",
      "Epoch:194| Average Epoch loss:-0.09548978997712451178| Ndiff loss:-49.9242000382|Sparsity loss:49.8287102483 \n",
      "tensor(-5.0163)\n",
      "tensor(54.5734)\n",
      "Epoch:195| Average Epoch loss:-0.09594892170272828480| Ndiff loss:-49.9246607819|Sparsity loss:49.8287118602 \n",
      "tensor(-5.0163)\n",
      "tensor(54.6707)\n",
      "Epoch:196| Average Epoch loss:-0.09640379060861389848| Ndiff loss:-49.9251178506|Sparsity loss:49.8287140600 \n",
      "tensor(-5.0163)\n",
      "tensor(54.7695)\n",
      "Epoch:197| Average Epoch loss:-0.09683069843063031590| Ndiff loss:-49.9255463757|Sparsity loss:49.8287156772 \n",
      "tensor(-5.0163)\n",
      "tensor(54.8664)\n",
      "Epoch:198| Average Epoch loss:-0.09720773236335172873| Ndiff loss:-49.9259252534|Sparsity loss:49.8287175211 \n",
      "tensor(-5.0163)\n",
      "tensor(54.9576)\n",
      "Epoch:199| Average Epoch loss:-0.09758945862520936043| Ndiff loss:-49.9263077725|Sparsity loss:49.8287183139 \n",
      "tensor(-5.0163)\n",
      "tensor(55.0519)\n",
      "Epoch:200| Average Epoch loss:-0.09795466316688934694| Ndiff loss:-49.9266760365|Sparsity loss:49.8287213733 \n",
      "tensor(-5.0163)\n",
      "tensor(55.1443)\n",
      "Epoch:201| Average Epoch loss:-0.09832357074619145487| Ndiff loss:-49.9270447255|Sparsity loss:49.8287211547 \n",
      "tensor(-5.0163)\n",
      "tensor(55.2408)\n",
      "Epoch:202| Average Epoch loss:-0.09868020020886131283| Ndiff loss:-49.9274048596|Sparsity loss:49.8287246594 \n",
      "tensor(-5.0163)\n",
      "tensor(55.3267)\n",
      "Epoch:203| Average Epoch loss:-0.09904093090889611040| Ndiff loss:-49.9277645791|Sparsity loss:49.8287236482 \n",
      "tensor(-5.0163)\n",
      "tensor(55.4248)\n",
      "Epoch:204| Average Epoch loss:-0.09939134581410948022| Ndiff loss:-49.9281184214|Sparsity loss:49.8287270756 \n",
      "tensor(-5.0163)\n",
      "tensor(55.5132)\n",
      "Epoch:205| Average Epoch loss:-0.09974557532472477783| Ndiff loss:-49.9284729762|Sparsity loss:49.8287274009 \n",
      "tensor(-5.0163)\n",
      "tensor(55.6060)\n",
      "Epoch:206| Average Epoch loss:-0.10008882997356770284| Ndiff loss:-49.9288182108|Sparsity loss:49.8287293808 \n",
      "tensor(-5.0163)\n",
      "tensor(55.6936)\n",
      "Epoch:207| Average Epoch loss:-0.10043126847476220587| Ndiff loss:-49.9291628974|Sparsity loss:49.8287316290 \n",
      "tensor(-5.0163)\n",
      "tensor(55.7771)\n",
      "Epoch:208| Average Epoch loss:-0.10077458131884615977| Ndiff loss:-49.9295063799|Sparsity loss:49.8287317986 \n",
      "tensor(-5.0163)\n",
      "tensor(55.8681)\n",
      "Epoch:209| Average Epoch loss:-0.10111237017817013839| Ndiff loss:-49.9298470352|Sparsity loss:49.8287346650 \n",
      "tensor(-5.0163)\n",
      "tensor(55.9544)\n",
      "Epoch:210| Average Epoch loss:-0.10144557589391961505| Ndiff loss:-49.9301793280|Sparsity loss:49.8287337521 \n",
      "tensor(-5.0163)\n",
      "tensor(56.0536)\n",
      "Epoch:211| Average Epoch loss:-0.10177884377120507975| Ndiff loss:-49.9305152459|Sparsity loss:49.8287364022 \n",
      "tensor(-5.0163)\n",
      "tensor(56.1454)\n",
      "Epoch:212| Average Epoch loss:-0.10210597027058791741| Ndiff loss:-49.9308440927|Sparsity loss:49.8287381224 \n",
      "tensor(-5.0163)\n",
      "tensor(56.2297)\n",
      "Epoch:213| Average Epoch loss:-0.10243377834444326868| Ndiff loss:-49.9311731770|Sparsity loss:49.8287393986 \n",
      "tensor(-5.0163)\n",
      "tensor(56.3174)\n",
      "Epoch:214| Average Epoch loss:-0.10275668612782043465| Ndiff loss:-49.9314988376|Sparsity loss:49.8287421514 \n",
      "tensor(-5.0163)\n",
      "tensor(56.3880)\n",
      "Epoch:215| Average Epoch loss:-0.10308637488672427185| Ndiff loss:-49.9318267853|Sparsity loss:49.8287404105 \n",
      "tensor(-5.0163)\n",
      "tensor(56.4923)\n",
      "Epoch:216| Average Epoch loss:-0.10340717169878585469| Ndiff loss:-49.9321509106|Sparsity loss:49.8287437389 \n",
      "tensor(-5.0163)\n",
      "tensor(56.5809)\n",
      "Epoch:217| Average Epoch loss:-0.10372901187197472450| Ndiff loss:-49.9324743570|Sparsity loss:49.8287453451 \n",
      "tensor(-5.0163)\n",
      "tensor(56.6560)\n",
      "Epoch:218| Average Epoch loss:-0.10404152699525247294| Ndiff loss:-49.9327864869|Sparsity loss:49.8287449599 \n",
      "tensor(-5.0163)\n",
      "tensor(56.7553)\n",
      "Epoch:219| Average Epoch loss:-0.10435587163272133648| Ndiff loss:-49.9331064159|Sparsity loss:49.8287505443 \n",
      "tensor(-5.0163)\n",
      "tensor(56.8114)\n",
      "Epoch:220| Average Epoch loss:-0.10466441149725487503| Ndiff loss:-49.9334101404|Sparsity loss:49.8287457289 \n",
      "tensor(-5.0163)\n",
      "tensor(56.9339)\n",
      "Epoch:221| Average Epoch loss:-0.10495246237719671467| Ndiff loss:-49.9337079751|Sparsity loss:49.8287555127 \n",
      "tensor(-5.0163)\n",
      "tensor(56.9715)\n",
      "Epoch:222| Average Epoch loss:-0.10525675651484710238| Ndiff loss:-49.9340027623|Sparsity loss:49.8287460058 \n",
      "tensor(-5.0163)\n",
      "tensor(57.0970)\n",
      "Epoch:223| Average Epoch loss:-0.10555765274973320789| Ndiff loss:-49.9343141204|Sparsity loss:49.8287564677 \n",
      "tensor(-5.0163)\n",
      "tensor(57.1603)\n",
      "Epoch:224| Average Epoch loss:-0.10587291097143847196| Ndiff loss:-49.9346228662|Sparsity loss:49.8287499552 \n",
      "tensor(-5.0163)\n",
      "tensor(57.2703)\n",
      "Epoch:225| Average Epoch loss:-0.10615856761652943396| Ndiff loss:-49.9349174667|Sparsity loss:49.8287588991 \n",
      "tensor(-5.0163)\n",
      "tensor(57.3293)\n",
      "Epoch:226| Average Epoch loss:-0.10646565718155504010| Ndiff loss:-49.9352182260|Sparsity loss:49.8287525689 \n",
      "tensor(-5.0163)\n",
      "tensor(57.4408)\n",
      "Epoch:227| Average Epoch loss:-0.10675051596974841073| Ndiff loss:-49.9355123453|Sparsity loss:49.8287618293 \n",
      "tensor(-5.0163)\n",
      "tensor(57.4872)\n",
      "Epoch:228| Average Epoch loss:-0.10704743198959221218| Ndiff loss:-49.9358021744|Sparsity loss:49.8287547424 \n",
      "tensor(-5.0163)\n",
      "tensor(57.6017)\n",
      "Epoch:229| Average Epoch loss:-0.10733075398506504439| Ndiff loss:-49.9360958262|Sparsity loss:49.8287650722 \n",
      "tensor(-5.0163)\n",
      "tensor(57.6396)\n",
      "Epoch:230| Average Epoch loss:-0.10761482121497047137| Ndiff loss:-49.9363712049|Sparsity loss:49.8287563837 \n",
      "tensor(-5.0163)\n",
      "tensor(57.7651)\n",
      "Epoch:231| Average Epoch loss:-0.10789823376147822387| Ndiff loss:-49.9366650138|Sparsity loss:49.8287667800 \n",
      "tensor(-5.0163)\n",
      "tensor(57.8089)\n",
      "Epoch:232| Average Epoch loss:-0.10818405762411763271| Ndiff loss:-49.9369438415|Sparsity loss:49.8287597839 \n",
      "tensor(-5.0163)\n",
      "tensor(57.9211)\n",
      "Epoch:233| Average Epoch loss:-0.10846152371056819175| Ndiff loss:-49.9372308620|Sparsity loss:49.8287693383 \n",
      "tensor(-5.0163)\n",
      "tensor(57.9621)\n",
      "Epoch:234| Average Epoch loss:-0.10873133770740829596| Ndiff loss:-49.9374924349|Sparsity loss:49.8287610972 \n",
      "tensor(-5.0163)\n",
      "tensor(58.0815)\n",
      "Epoch:235| Average Epoch loss:-0.10899197888115746968| Ndiff loss:-49.9377653430|Sparsity loss:49.8287733641 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-5.0163)\n",
      "tensor(58.1084)\n",
      "Epoch:236| Average Epoch loss:-0.10926058230953354655| Ndiff loss:-49.9380223740|Sparsity loss:49.8287617917 \n",
      "tensor(-5.0163)\n",
      "tensor(58.2461)\n",
      "Epoch:237| Average Epoch loss:-0.10951404824561371265| Ndiff loss:-49.9382891798|Sparsity loss:49.8287751316 \n",
      "tensor(-5.0163)\n",
      "tensor(58.2833)\n",
      "Epoch:238| Average Epoch loss:-0.10979871952180768335| Ndiff loss:-49.9385638814|Sparsity loss:49.8287651618 \n",
      "tensor(-5.0163)\n",
      "tensor(58.4003)\n",
      "Epoch:239| Average Epoch loss:-0.11005131346714788765| Ndiff loss:-49.9388282702|Sparsity loss:49.8287769567 \n",
      "tensor(-5.0163)\n",
      "tensor(58.4419)\n",
      "Epoch:240| Average Epoch loss:-0.11032816664044393928| Ndiff loss:-49.9390948961|Sparsity loss:49.8287667294 \n",
      "tensor(-5.0163)\n",
      "tensor(58.5687)\n",
      "Epoch:241| Average Epoch loss:-0.11057849010703711679| Ndiff loss:-49.9393581700|Sparsity loss:49.8287796799 \n",
      "tensor(-5.0163)\n",
      "tensor(58.5968)\n",
      "Epoch:242| Average Epoch loss:-0.11084445250481028689| Ndiff loss:-49.9396140812|Sparsity loss:49.8287696287 \n",
      "tensor(-5.0163)\n",
      "tensor(58.7136)\n",
      "Epoch:243| Average Epoch loss:-0.11108356065482599684| Ndiff loss:-49.9398665555|Sparsity loss:49.8287829948 \n",
      "tensor(-5.0163)\n",
      "tensor(58.7378)\n",
      "Epoch:244| Average Epoch loss:-0.11133973197508871544| Ndiff loss:-49.9401095421|Sparsity loss:49.8287698101 \n",
      "tensor(-5.0163)\n",
      "tensor(58.8744)\n",
      "Epoch:245| Average Epoch loss:-0.11157572549484681690| Ndiff loss:-49.9403622353|Sparsity loss:49.8287865098 \n",
      "tensor(-5.0163)\n",
      "tensor(58.8769)\n",
      "Epoch:246| Average Epoch loss:-0.11182649557876603308| Ndiff loss:-49.9405977072|Sparsity loss:49.8287712116 \n",
      "tensor(-5.0163)\n",
      "tensor(59.0185)\n",
      "Epoch:247| Average Epoch loss:-0.11207765216846965473| Ndiff loss:-49.9408653529|Sparsity loss:49.8287877008 \n",
      "tensor(-5.0163)\n",
      "tensor(59.0337)\n",
      "Epoch:248| Average Epoch loss:-0.11233674836238766170| Ndiff loss:-49.9411113461|Sparsity loss:49.8287745977 \n",
      "tensor(-5.0163)\n",
      "tensor(59.1597)\n",
      "Epoch:249| Average Epoch loss:-0.11257859960510706310| Ndiff loss:-49.9413671192|Sparsity loss:49.8287885196 \n",
      "tensor(-5.0163)\n",
      "tensor(59.1894)\n",
      "Epoch:250| Average Epoch loss:-0.11283872488691157332| Ndiff loss:-49.9416159707|Sparsity loss:49.8287772459 \n",
      "tensor(-5.0163)\n",
      "tensor(59.3155)\n",
      "Epoch:251| Average Epoch loss:-0.11305986412417073916| Ndiff loss:-49.9418498837|Sparsity loss:49.8287900196 \n",
      "tensor(-5.0163)\n",
      "tensor(59.3461)\n",
      "Epoch:252| Average Epoch loss:-0.11331225017365298413| Ndiff loss:-49.9420918471|Sparsity loss:49.8287795969 \n",
      "tensor(-5.0163)\n",
      "tensor(59.4629)\n",
      "Epoch:253| Average Epoch loss:-0.11352524567031589686| Ndiff loss:-49.9423193267|Sparsity loss:49.8287940810 \n",
      "tensor(-5.0163)\n",
      "tensor(59.4728)\n",
      "Epoch:254| Average Epoch loss:-0.11375705681551630255| Ndiff loss:-49.9425369962|Sparsity loss:49.8287799393 \n",
      "tensor(-5.0163)\n",
      "tensor(59.6080)\n",
      "Epoch:255| Average Epoch loss:-0.11397573421442391828| Ndiff loss:-49.9427726503|Sparsity loss:49.8287969161 \n",
      "tensor(-5.0163)\n",
      "tensor(59.6062)\n",
      "Epoch:256| Average Epoch loss:-0.11420415335336168983| Ndiff loss:-49.9429846410|Sparsity loss:49.8287804876 \n",
      "tensor(-5.0163)\n",
      "tensor(59.7603)\n",
      "Epoch:257| Average Epoch loss:-0.11440644073638416012| Ndiff loss:-49.9432052600|Sparsity loss:49.8287988193 \n",
      "tensor(-5.0163)\n",
      "tensor(59.7578)\n",
      "Epoch:258| Average Epoch loss:-0.11465693138494180425| Ndiff loss:-49.9434396150|Sparsity loss:49.8287826836 \n",
      "tensor(-5.0163)\n",
      "tensor(59.9018)\n",
      "Epoch:259| Average Epoch loss:-0.11484965528116061750| Ndiff loss:-49.9436506401|Sparsity loss:49.8288009849 \n",
      "tensor(-5.0163)\n",
      "tensor(59.8975)\n",
      "Epoch:260| Average Epoch loss:-0.11509116257210057210| Ndiff loss:-49.9438753118|Sparsity loss:49.8287841492 \n",
      "tensor(-5.0163)\n",
      "tensor(60.0405)\n",
      "Epoch:261| Average Epoch loss:-0.11529219271093656130| Ndiff loss:-49.9440945213|Sparsity loss:49.8288023286 \n",
      "tensor(-5.0163)\n",
      "tensor(60.0397)\n",
      "Epoch:262| Average Epoch loss:-0.11553780707092226043| Ndiff loss:-49.9443248110|Sparsity loss:49.8287870039 \n",
      "tensor(-5.0163)\n",
      "tensor(60.1764)\n",
      "Epoch:263| Average Epoch loss:-0.11573198059192474352| Ndiff loss:-49.9445359537|Sparsity loss:49.8288039731 \n",
      "tensor(-5.0163)\n",
      "tensor(60.1805)\n",
      "Epoch:264| Average Epoch loss:-0.11597241160419989592| Ndiff loss:-49.9447615572|Sparsity loss:49.8287891456 \n",
      "tensor(-5.0163)\n",
      "tensor(60.3139)\n",
      "Epoch:265| Average Epoch loss:-0.11617659603578506244| Ndiff loss:-49.9449811210|Sparsity loss:49.8288045250 \n",
      "tensor(-5.0163)\n",
      "tensor(60.3307)\n",
      "Epoch:266| Average Epoch loss:-0.11640913690181520224| Ndiff loss:-49.9452018340|Sparsity loss:49.8287926971 \n",
      "tensor(-5.0163)\n",
      "tensor(60.4437)\n",
      "Epoch:267| Average Epoch loss:-0.11662022588100660891| Ndiff loss:-49.9454251233|Sparsity loss:49.8288048975 \n",
      "tensor(-5.0163)\n",
      "tensor(60.4769)\n",
      "Epoch:268| Average Epoch loss:-0.11684861544733730898| Ndiff loss:-49.9456444927|Sparsity loss:49.8287958772 \n",
      "tensor(-5.0163)\n",
      "tensor(60.5817)\n",
      "Epoch:269| Average Epoch loss:-0.11704876850414712430| Ndiff loss:-49.9458548267|Sparsity loss:49.8288060582 \n",
      "tensor(-5.0163)\n",
      "tensor(60.6156)\n",
      "Epoch:270| Average Epoch loss:-0.11726871191184902454| Ndiff loss:-49.9460671311|Sparsity loss:49.8287984192 \n",
      "tensor(-5.0163)\n",
      "tensor(60.7110)\n",
      "Epoch:271| Average Epoch loss:-0.11746263370938139770| Ndiff loss:-49.9462694342|Sparsity loss:49.8288068005 \n",
      "tensor(-5.0163)\n",
      "tensor(60.7508)\n",
      "Epoch:272| Average Epoch loss:-0.11768173789943069119| Ndiff loss:-49.9464820628|Sparsity loss:49.8288003249 \n",
      "tensor(-5.0163)\n",
      "tensor(60.8458)\n",
      "Epoch:273| Average Epoch loss:-0.11787529901841233004| Ndiff loss:-49.9466843791|Sparsity loss:49.8288090801 \n",
      "tensor(-5.0163)\n",
      "tensor(60.8754)\n",
      "Epoch:274| Average Epoch loss:-0.11808478929995776252| Ndiff loss:-49.9468872841|Sparsity loss:49.8288024948 \n",
      "tensor(-5.0163)\n",
      "tensor(60.9693)\n",
      "Epoch:275| Average Epoch loss:-0.11827882529353120344| Ndiff loss:-49.9470897595|Sparsity loss:49.8288109342 \n",
      "tensor(-5.0163)\n",
      "tensor(61.0030)\n",
      "Epoch:276| Average Epoch loss:-0.11847694873003433713| Ndiff loss:-49.9472806271|Sparsity loss:49.8288036784 \n",
      "tensor(-5.0163)\n",
      "tensor(61.0978)\n",
      "Epoch:277| Average Epoch loss:-0.11866455109187670769| Ndiff loss:-49.9474780537|Sparsity loss:49.8288135026 \n",
      "tensor(-5.0163)\n",
      "tensor(61.1240)\n",
      "Epoch:278| Average Epoch loss:-0.11885950793634354750| Ndiff loss:-49.9476633234|Sparsity loss:49.8288038155 \n",
      "tensor(-5.0163)\n",
      "tensor(61.2409)\n",
      "Epoch:279| Average Epoch loss:-0.11903971166025290040| Ndiff loss:-49.9478547970|Sparsity loss:49.8288150853 \n",
      "tensor(-5.0163)\n",
      "tensor(61.2599)\n",
      "Epoch:280| Average Epoch loss:-0.11924811147443431514| Ndiff loss:-49.9480541870|Sparsity loss:49.8288060755 \n",
      "tensor(-5.0163)\n",
      "tensor(61.3661)\n",
      "Epoch:281| Average Epoch loss:-0.11942625981766773202| Ndiff loss:-49.9482436218|Sparsity loss:49.8288173620 \n",
      "tensor(-5.0163)\n",
      "tensor(61.3809)\n",
      "Epoch:282| Average Epoch loss:-0.11962028476887927309| Ndiff loss:-49.9484271079|Sparsity loss:49.8288068232 \n",
      "tensor(-5.0163)\n",
      "tensor(61.4955)\n",
      "Epoch:283| Average Epoch loss:-0.11979058122607513792| Ndiff loss:-49.9486101713|Sparsity loss:49.8288195901 \n",
      "tensor(-5.0163)\n",
      "tensor(61.5047)\n",
      "Epoch:284| Average Epoch loss:-0.11999008564955736256| Ndiff loss:-49.9487986250|Sparsity loss:49.8288085393 \n",
      "tensor(-5.0163)\n",
      "tensor(61.6183)\n",
      "Epoch:285| Average Epoch loss:-0.12017444984322819823| Ndiff loss:-49.9489938071|Sparsity loss:49.8288193572 \n",
      "tensor(-5.0163)\n",
      "tensor(61.6448)\n",
      "Epoch:286| Average Epoch loss:-0.12037528355398229019| Ndiff loss:-49.9491865600|Sparsity loss:49.8288112764 \n",
      "tensor(-5.0163)\n",
      "tensor(61.7452)\n",
      "Epoch:287| Average Epoch loss:-0.12054876104942104098| Ndiff loss:-49.9493697764|Sparsity loss:49.8288210154 \n",
      "tensor(-5.0163)\n",
      "tensor(61.7688)\n",
      "Epoch:288| Average Epoch loss:-0.12074099166372755099| Ndiff loss:-49.9495549376|Sparsity loss:49.8288139459 \n",
      "tensor(-5.0163)\n",
      "tensor(61.8566)\n",
      "Epoch:289| Average Epoch loss:-0.12092409305559964627| Ndiff loss:-49.9497450122|Sparsity loss:49.8288209191 \n",
      "tensor(-5.0163)\n",
      "tensor(61.9005)\n",
      "Epoch:290| Average Epoch loss:-0.12110992096811815100| Ndiff loss:-49.9499262793|Sparsity loss:49.8288163583 \n",
      "tensor(-5.0163)\n",
      "tensor(61.9809)\n",
      "Epoch:291| Average Epoch loss:-0.12128470456231434105| Ndiff loss:-49.9501074078|Sparsity loss:49.8288227032 \n",
      "tensor(-5.0163)\n",
      "tensor(62.0212)\n",
      "Epoch:292| Average Epoch loss:-0.12146522990612140802| Ndiff loss:-49.9502828529|Sparsity loss:49.8288176230 \n",
      "tensor(-5.0163)\n",
      "tensor(62.1070)\n",
      "Epoch:293| Average Epoch loss:-0.12163852923124768290| Ndiff loss:-49.9504624317|Sparsity loss:49.8288239025 \n",
      "tensor(-5.0163)\n",
      "tensor(62.1451)\n",
      "Epoch:294| Average Epoch loss:-0.12182091207925911658| Ndiff loss:-49.9506403784|Sparsity loss:49.8288194663 \n",
      "tensor(-5.0163)\n",
      "tensor(62.2318)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:295| Average Epoch loss:-0.12198584628627766324| Ndiff loss:-49.9508115002|Sparsity loss:49.8288256539 \n",
      "tensor(-5.0163)\n",
      "tensor(62.2644)\n",
      "Epoch:296| Average Epoch loss:-0.12216528832128561999| Ndiff loss:-49.9509862683|Sparsity loss:49.8288209800 \n",
      "tensor(-5.0163)\n",
      "tensor(62.3484)\n",
      "Epoch:297| Average Epoch loss:-0.12233073805522604038| Ndiff loss:-49.9511582595|Sparsity loss:49.8288275214 \n",
      "tensor(-5.0163)\n",
      "tensor(62.3767)\n",
      "Epoch:298| Average Epoch loss:-0.12250279287364228276| Ndiff loss:-49.9513244059|Sparsity loss:49.8288216130 \n",
      "tensor(-5.0163)\n",
      "tensor(62.4690)\n",
      "Epoch:299| Average Epoch loss:-0.12266468925382728594| Ndiff loss:-49.9514944191|Sparsity loss:49.8288297298 \n",
      "tensor(-5.0163)\n",
      "tensor(62.4916)\n",
      "Epoch:300| Average Epoch loss:-0.12283582674660564749| Ndiff loss:-49.9516583325|Sparsity loss:49.8288225058 \n",
      "tensor(-5.0163)\n",
      "tensor(62.5857)\n",
      "Epoch:301| Average Epoch loss:-0.12299275512196355953| Ndiff loss:-49.9518239558|Sparsity loss:49.8288312007 \n",
      "tensor(-5.0163)\n",
      "tensor(62.6065)\n",
      "Epoch:302| Average Epoch loss:-0.12316630559067694162| Ndiff loss:-49.9519896140|Sparsity loss:49.8288233084 \n",
      "tensor(-5.0163)\n",
      "tensor(62.7089)\n",
      "Epoch:303| Average Epoch loss:-0.12332185989386898473| Ndiff loss:-49.9521548058|Sparsity loss:49.8288329459 \n",
      "tensor(-5.0163)\n",
      "tensor(62.7279)\n",
      "Epoch:304| Average Epoch loss:-0.12349119188527445112| Ndiff loss:-49.9523162703|Sparsity loss:49.8288250784 \n",
      "tensor(-5.0163)\n",
      "tensor(62.8224)\n",
      "Epoch:305| Average Epoch loss:-0.12365540549392406433| Ndiff loss:-49.9524888618|Sparsity loss:49.8288334564 \n",
      "tensor(-5.0163)\n",
      "tensor(62.8501)\n",
      "Epoch:306| Average Epoch loss:-0.12382575804328983804| Ndiff loss:-49.9526532494|Sparsity loss:49.8288274914 \n",
      "tensor(-5.0163)\n",
      "tensor(62.9369)\n",
      "Epoch:307| Average Epoch loss:-0.12398239614069853087| Ndiff loss:-49.9528164059|Sparsity loss:49.8288340098 \n",
      "tensor(-5.0163)\n",
      "tensor(62.9725)\n",
      "Epoch:308| Average Epoch loss:-0.12414963370593312675| Ndiff loss:-49.9529788448|Sparsity loss:49.8288292111 \n",
      "tensor(-5.0163)\n",
      "tensor(63.0548)\n",
      "Epoch:309| Average Epoch loss:-0.12430118119778693631| Ndiff loss:-49.9531370635|Sparsity loss:49.8288358823 \n",
      "tensor(-5.0163)\n",
      "tensor(63.0819)\n",
      "Epoch:310| Average Epoch loss:-0.12446273056818747682| Ndiff loss:-49.9532933341|Sparsity loss:49.8288306035 \n",
      "tensor(-5.0163)\n",
      "tensor(63.1643)\n",
      "Epoch:311| Average Epoch loss:-0.12461147293924391966| Ndiff loss:-49.9534478196|Sparsity loss:49.8288363467 \n",
      "tensor(-5.0163)\n",
      "tensor(63.2035)\n",
      "Epoch:312| Average Epoch loss:-0.12478021194182373210| Ndiff loss:-49.9536129596|Sparsity loss:49.8288327476 \n",
      "tensor(-5.0163)\n",
      "tensor(63.2784)\n",
      "Epoch:313| Average Epoch loss:-0.12493288626657299278| Ndiff loss:-49.9537703607|Sparsity loss:49.8288374744 \n",
      "tensor(-5.0163)\n",
      "tensor(63.3134)\n",
      "Epoch:314| Average Epoch loss:-0.12508974058056901435| Ndiff loss:-49.9539238888|Sparsity loss:49.8288341482 \n",
      "tensor(-5.0163)\n",
      "tensor(63.3901)\n",
      "Epoch:315| Average Epoch loss:-0.12524228907318857296| Ndiff loss:-49.9540803096|Sparsity loss:49.8288380205 \n",
      "tensor(-5.0163)\n",
      "tensor(63.4371)\n",
      "Epoch:316| Average Epoch loss:-0.12539779010759014022| Ndiff loss:-49.9542345816|Sparsity loss:49.8288367915 \n",
      "tensor(-5.0163)\n",
      "tensor(63.4965)\n",
      "Epoch:317| Average Epoch loss:-0.12554788657211130021| Ndiff loss:-49.9543859877|Sparsity loss:49.8288381011 \n",
      "tensor(-5.0163)\n",
      "tensor(63.5504)\n",
      "Epoch:318| Average Epoch loss:-0.12569864246030151844| Ndiff loss:-49.9545376797|Sparsity loss:49.8288390372 \n",
      "tensor(-5.0163)\n",
      "tensor(63.6042)\n",
      "Epoch:319| Average Epoch loss:-0.12584827815908206095| Ndiff loss:-49.9546876037|Sparsity loss:49.8288393255 \n",
      "tensor(-5.0163)\n",
      "tensor(63.6590)\n",
      "Epoch:320| Average Epoch loss:-0.12599827786663592155| Ndiff loss:-49.9548388954|Sparsity loss:49.8288406175 \n",
      "tensor(-5.0163)\n",
      "tensor(63.7058)\n",
      "Epoch:321| Average Epoch loss:-0.12614861392938633844| Ndiff loss:-49.9549886719|Sparsity loss:49.8288400580 \n",
      "tensor(-5.0163)\n",
      "tensor(63.7683)\n",
      "Epoch:322| Average Epoch loss:-0.12629626468164703579| Ndiff loss:-49.9551378701|Sparsity loss:49.8288416054 \n",
      "tensor(-5.0163)\n",
      "tensor(63.8226)\n",
      "Epoch:323| Average Epoch loss:-0.12644581649975547566| Ndiff loss:-49.9552875406|Sparsity loss:49.8288417241 \n",
      "tensor(-5.0163)\n",
      "tensor(63.8759)\n",
      "Epoch:324| Average Epoch loss:-0.12659095000626408023| Ndiff loss:-49.9554345850|Sparsity loss:49.8288436350 \n",
      "tensor(-5.0163)\n",
      "tensor(63.9190)\n",
      "Epoch:325| Average Epoch loss:-0.12673683443573066643| Ndiff loss:-49.9555789405|Sparsity loss:49.8288421061 \n",
      "tensor(-5.0163)\n",
      "tensor(63.9854)\n",
      "Epoch:326| Average Epoch loss:-0.12688100996925064101| Ndiff loss:-49.9557258732|Sparsity loss:49.8288448633 \n",
      "tensor(-5.0163)\n",
      "tensor(64.0310)\n",
      "Epoch:327| Average Epoch loss:-0.12702602474923374576| Ndiff loss:-49.9558695099|Sparsity loss:49.8288434852 \n",
      "tensor(-5.0163)\n",
      "tensor(64.0937)\n",
      "Epoch:328| Average Epoch loss:-0.12716735955309133033| Ndiff loss:-49.9560135884|Sparsity loss:49.8288462289 \n",
      "tensor(-5.0163)\n",
      "tensor(64.1361)\n",
      "Epoch:329| Average Epoch loss:-0.12731111207330295110| Ndiff loss:-49.9561559608|Sparsity loss:49.8288448487 \n",
      "tensor(-5.0163)\n",
      "tensor(64.1962)\n",
      "Epoch:330| Average Epoch loss:-0.12745337554068847385| Ndiff loss:-49.9563001165|Sparsity loss:49.8288467410 \n",
      "tensor(-5.0163)\n",
      "tensor(64.2500)\n",
      "Epoch:331| Average Epoch loss:-0.12759548627763372952| Ndiff loss:-49.9564419403|Sparsity loss:49.8288464540 \n",
      "tensor(-5.0163)\n",
      "tensor(64.3026)\n",
      "Epoch:332| Average Epoch loss:-0.12773333671495656905| Ndiff loss:-49.9565819200|Sparsity loss:49.8288485833 \n",
      "tensor(-5.0163)\n",
      "tensor(64.3455)\n",
      "Epoch:333| Average Epoch loss:-0.12787321987879274321| Ndiff loss:-49.9567201626|Sparsity loss:49.8288469427 \n",
      "tensor(-5.0163)\n",
      "tensor(64.4112)\n",
      "Epoch:334| Average Epoch loss:-0.12800985124439950846| Ndiff loss:-49.9568594862|Sparsity loss:49.8288496350 \n",
      "tensor(-5.0163)\n",
      "tensor(64.4542)\n",
      "Epoch:335| Average Epoch loss:-0.12814871090923082853| Ndiff loss:-49.9569969863|Sparsity loss:49.8288482754 \n",
      "tensor(-5.0163)\n",
      "tensor(64.5139)\n",
      "Epoch:336| Average Epoch loss:-0.12828344060043800345| Ndiff loss:-49.9571346110|Sparsity loss:49.8288511704 \n",
      "tensor(-5.0163)\n",
      "tensor(64.5535)\n",
      "Epoch:337| Average Epoch loss:-0.12841974603829184320| Ndiff loss:-49.9572690553|Sparsity loss:49.8288493093 \n",
      "tensor(-5.0163)\n",
      "tensor(64.6205)\n",
      "Epoch:338| Average Epoch loss:-0.12855199964721228389| Ndiff loss:-49.9574041373|Sparsity loss:49.8288521377 \n",
      "tensor(-5.0163)\n",
      "tensor(64.6619)\n",
      "Epoch:339| Average Epoch loss:-0.12868486261082642819| Ndiff loss:-49.9575357635|Sparsity loss:49.8288509009 \n",
      "tensor(-5.0163)\n",
      "tensor(64.7202)\n",
      "Epoch:340| Average Epoch loss:-0.12881740922902945590| Ndiff loss:-49.9576703904|Sparsity loss:49.8288529812 \n",
      "tensor(-5.0163)\n",
      "tensor(64.7634)\n",
      "Epoch:341| Average Epoch loss:-0.12894990901591027455| Ndiff loss:-49.9578017248|Sparsity loss:49.8288518158 \n",
      "tensor(-5.0163)\n",
      "tensor(64.8294)\n",
      "Epoch:342| Average Epoch loss:-0.12907590890192663369| Ndiff loss:-49.9579302793|Sparsity loss:49.8288543704 \n",
      "tensor(-5.0163)\n",
      "tensor(64.8715)\n",
      "Epoch:343| Average Epoch loss:-0.12920714294664431554| Ndiff loss:-49.9580598570|Sparsity loss:49.8288527141 \n",
      "tensor(-5.0163)\n",
      "tensor(64.9305)\n",
      "Epoch:344| Average Epoch loss:-0.12933293720601607424| Ndiff loss:-49.9581888143|Sparsity loss:49.8288558771 \n",
      "tensor(-5.0163)\n",
      "tensor(64.9692)\n",
      "Epoch:345| Average Epoch loss:-0.12946321709478070261| Ndiff loss:-49.9583170753|Sparsity loss:49.8288538582 \n",
      "tensor(-5.0163)\n",
      "tensor(65.0283)\n",
      "Epoch:346| Average Epoch loss:-0.12958979815697288518| Ndiff loss:-49.9584467361|Sparsity loss:49.8288569380 \n",
      "tensor(-5.0163)\n",
      "tensor(65.0690)\n",
      "Epoch:347| Average Epoch loss:-0.12971732616212250377| Ndiff loss:-49.9585725053|Sparsity loss:49.8288551791 \n",
      "tensor(-5.0163)\n",
      "tensor(65.1271)\n",
      "Epoch:348| Average Epoch loss:-0.12984280848892973403| Ndiff loss:-49.9587005484|Sparsity loss:49.8288577399 \n",
      "tensor(-5.0163)\n",
      "tensor(65.1686)\n",
      "Epoch:349| Average Epoch loss:-0.12996951501685238828| Ndiff loss:-49.9588252038|Sparsity loss:49.8288556888 \n",
      "tensor(-5.0163)\n",
      "tensor(65.2347)\n",
      "Epoch:350| Average Epoch loss:-0.13009086276822204309| Ndiff loss:-49.9589498441|Sparsity loss:49.8288589813 \n",
      "tensor(-5.0163)\n",
      "tensor(65.2724)\n",
      "Epoch:351| Average Epoch loss:-0.13021603932397043946| Ndiff loss:-49.9590730771|Sparsity loss:49.8288570378 \n",
      "tensor(-5.0163)\n",
      "tensor(65.3325)\n",
      "Epoch:352| Average Epoch loss:-0.13033923612421144389| Ndiff loss:-49.9591989744|Sparsity loss:49.8288597382 \n",
      "tensor(-5.0163)\n",
      "tensor(65.3742)\n",
      "Epoch:353| Average Epoch loss:-0.13046127231884696585| Ndiff loss:-49.9593201990|Sparsity loss:49.8288589267 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-5.0163)\n",
      "tensor(65.4242)\n",
      "Epoch:354| Average Epoch loss:-0.13058516041171033817| Ndiff loss:-49.9594452084|Sparsity loss:49.8288600480 \n",
      "tensor(-5.0163)\n",
      "tensor(65.4712)\n",
      "Epoch:355| Average Epoch loss:-0.13070789855483708197| Ndiff loss:-49.9595680741|Sparsity loss:49.8288601756 \n",
      "tensor(-5.0163)\n",
      "tensor(65.5244)\n",
      "Epoch:356| Average Epoch loss:-0.13082630914450593673| Ndiff loss:-49.9596878323|Sparsity loss:49.8288615232 \n",
      "tensor(-5.0163)\n",
      "tensor(65.5645)\n",
      "Epoch:357| Average Epoch loss:-0.13094575496495666767| Ndiff loss:-49.9598067547|Sparsity loss:49.8288609997 \n",
      "tensor(-5.0163)\n",
      "tensor(65.6176)\n",
      "Epoch:358| Average Epoch loss:-0.13106301134223249938| Ndiff loss:-49.9599253057|Sparsity loss:49.8288622943 \n",
      "tensor(-5.0163)\n",
      "tensor(65.6628)\n",
      "Epoch:359| Average Epoch loss:-0.13118190668308019053| Ndiff loss:-49.9600441608|Sparsity loss:49.8288622541 \n",
      "tensor(-5.0163)\n",
      "tensor(65.7148)\n",
      "Epoch:360| Average Epoch loss:-0.13130142985326287430| Ndiff loss:-49.9601645341|Sparsity loss:49.8288631043 \n",
      "tensor(-5.0163)\n",
      "tensor(65.7621)\n",
      "Epoch:361| Average Epoch loss:-0.13141733686145684601| Ndiff loss:-49.9602810059|Sparsity loss:49.8288636690 \n",
      "tensor(-5.0163)\n",
      "tensor(65.8094)\n",
      "Epoch:362| Average Epoch loss:-0.13153388190886319831| Ndiff loss:-49.9603973378|Sparsity loss:49.8288634559 \n",
      "tensor(-5.0163)\n",
      "tensor(65.8651)\n",
      "Epoch:363| Average Epoch loss:-0.13164932527215197910| Ndiff loss:-49.9605141697|Sparsity loss:49.8288648444 \n",
      "tensor(-5.0163)\n",
      "tensor(65.9092)\n",
      "Epoch:364| Average Epoch loss:-0.13176681622910318969| Ndiff loss:-49.9606316109|Sparsity loss:49.8288647947 \n",
      "tensor(-5.0163)\n",
      "tensor(65.9620)\n",
      "Epoch:365| Average Epoch loss:-0.13188072236333228671| Ndiff loss:-49.9607467295|Sparsity loss:49.8288660071 \n",
      "tensor(-5.0163)\n",
      "tensor(66.0009)\n",
      "Epoch:366| Average Epoch loss:-0.13199404025949312835| Ndiff loss:-49.9608596981|Sparsity loss:49.8288656578 \n",
      "tensor(-5.0163)\n",
      "tensor(66.0508)\n",
      "Epoch:367| Average Epoch loss:-0.13210683961948296861| Ndiff loss:-49.9609733315|Sparsity loss:49.8288664918 \n",
      "tensor(-5.0163)\n",
      "tensor(66.1003)\n",
      "Epoch:368| Average Epoch loss:-0.13222126092672206732| Ndiff loss:-49.9610883511|Sparsity loss:49.8288670902 \n",
      "tensor(-5.0163)\n",
      "tensor(66.1465)\n",
      "Epoch:369| Average Epoch loss:-0.13233312623047055467| Ndiff loss:-49.9612007689|Sparsity loss:49.8288676426 \n",
      "tensor(-5.0163)\n",
      "tensor(66.1899)\n",
      "Epoch:370| Average Epoch loss:-0.13244417294895585724| Ndiff loss:-49.9613120200|Sparsity loss:49.8288678470 \n",
      "tensor(-5.0163)\n",
      "tensor(66.2392)\n",
      "Epoch:371| Average Epoch loss:-0.13255578530234757295| Ndiff loss:-49.9614240966|Sparsity loss:49.8288683113 \n",
      "tensor(-5.0163)\n",
      "tensor(66.2881)\n",
      "Epoch:372| Average Epoch loss:-0.13266549036517361060| Ndiff loss:-49.9615345102|Sparsity loss:49.8288690198 \n",
      "tensor(-5.0163)\n",
      "tensor(66.3358)\n",
      "Epoch:373| Average Epoch loss:-0.13277484854358492794| Ndiff loss:-49.9616440050|Sparsity loss:49.8288691564 \n",
      "tensor(-5.0163)\n",
      "tensor(66.3814)\n",
      "Epoch:374| Average Epoch loss:-0.13288556191505898618| Ndiff loss:-49.9617557351|Sparsity loss:49.8288701732 \n",
      "tensor(-5.0163)\n",
      "tensor(66.4240)\n",
      "Epoch:375| Average Epoch loss:-0.13299366454786978875| Ndiff loss:-49.9618641175|Sparsity loss:49.8288704530 \n",
      "tensor(-5.0163)\n",
      "tensor(66.4683)\n",
      "Epoch:376| Average Epoch loss:-0.13310132911457411842| Ndiff loss:-49.9619714388|Sparsity loss:49.8288701096 \n",
      "tensor(-5.0163)\n",
      "tensor(66.5239)\n",
      "Epoch:377| Average Epoch loss:-0.13320890497582305034| Ndiff loss:-49.9620808952|Sparsity loss:49.8288719902 \n",
      "tensor(-5.0163)\n",
      "tensor(66.5610)\n",
      "Epoch:378| Average Epoch loss:-0.13331582036959904736| Ndiff loss:-49.9621870751|Sparsity loss:49.8288712547 \n",
      "tensor(-5.0163)\n",
      "tensor(66.6135)\n",
      "Epoch:379| Average Epoch loss:-0.13342231549824429271| Ndiff loss:-49.9622952025|Sparsity loss:49.8288728870 \n",
      "tensor(-5.0163)\n",
      "tensor(66.6515)\n",
      "Epoch:380| Average Epoch loss:-0.13352818368945623684| Ndiff loss:-49.9624002444|Sparsity loss:49.8288720607 \n",
      "tensor(-5.0163)\n",
      "tensor(66.7022)\n",
      "Epoch:381| Average Epoch loss:-0.13363232337888833468| Ndiff loss:-49.9625060947|Sparsity loss:49.8288737713 \n",
      "tensor(-5.0163)\n",
      "tensor(66.7434)\n",
      "Epoch:382| Average Epoch loss:-0.13373763252512244071| Ndiff loss:-49.9626109055|Sparsity loss:49.8288732730 \n",
      "tensor(-5.0163)\n",
      "tensor(66.7909)\n",
      "Epoch:383| Average Epoch loss:-0.13384291479740223485| Ndiff loss:-49.9627171261|Sparsity loss:49.8288742113 \n",
      "tensor(-5.0163)\n",
      "tensor(66.8326)\n",
      "Epoch:384| Average Epoch loss:-0.13394603315178660319| Ndiff loss:-49.9628204828|Sparsity loss:49.8288744497 \n",
      "tensor(-5.0163)\n",
      "tensor(66.8774)\n",
      "Epoch:385| Average Epoch loss:-0.13404933316720976655| Ndiff loss:-49.9629243469|Sparsity loss:49.8288750137 \n",
      "tensor(-5.0163)\n",
      "tensor(66.9234)\n",
      "Epoch:386| Average Epoch loss:-0.13415263785813991149| Ndiff loss:-49.9630278095|Sparsity loss:49.8288751717 \n",
      "tensor(-5.0163)\n",
      "tensor(66.9678)\n",
      "Epoch:387| Average Epoch loss:-0.13425424262662055686| Ndiff loss:-49.9631306361|Sparsity loss:49.8288763934 \n",
      "tensor(-5.0163)\n",
      "tensor(67.0043)\n",
      "Epoch:388| Average Epoch loss:-0.13435674926950605390| Ndiff loss:-49.9632325232|Sparsity loss:49.8288757739 \n",
      "tensor(-5.0163)\n",
      "tensor(67.0542)\n",
      "Epoch:389| Average Epoch loss:-0.13445664587599992501| Ndiff loss:-49.9633340100|Sparsity loss:49.8288773642 \n",
      "tensor(-5.0163)\n",
      "tensor(67.0901)\n",
      "Epoch:390| Average Epoch loss:-0.13455770759163598882| Ndiff loss:-49.9634344307|Sparsity loss:49.8288767231 \n",
      "tensor(-5.0163)\n",
      "tensor(67.1411)\n",
      "Epoch:391| Average Epoch loss:-0.13465910362489255658| Ndiff loss:-49.9635363222|Sparsity loss:49.8288772186 \n",
      "tensor(-5.0163)\n",
      "tensor(67.1902)\n",
      "Epoch:392| Average Epoch loss:-0.13475820752836831229| Ndiff loss:-49.9636362811|Sparsity loss:49.8288780736 \n",
      "tensor(-5.0163)\n",
      "tensor(67.2332)\n",
      "Epoch:393| Average Epoch loss:-0.13485793443567375971| Ndiff loss:-49.9637363840|Sparsity loss:49.8288784496 \n",
      "tensor(-5.0163)\n",
      "tensor(67.2753)\n",
      "Epoch:394| Average Epoch loss:-0.13495499237227667755| Ndiff loss:-49.9638344153|Sparsity loss:49.8288794229 \n",
      "tensor(-5.0163)\n",
      "tensor(67.3140)\n",
      "Epoch:395| Average Epoch loss:-0.13505379660239252848| Ndiff loss:-49.9639324403|Sparsity loss:49.8288786437 \n",
      "tensor(-5.0163)\n",
      "tensor(67.3647)\n",
      "Epoch:396| Average Epoch loss:-0.13514972433292904430| Ndiff loss:-49.9640300555|Sparsity loss:49.8288803311 \n",
      "tensor(-5.0163)\n",
      "tensor(67.4002)\n",
      "Epoch:397| Average Epoch loss:-0.13524810384714669453| Ndiff loss:-49.9641274887|Sparsity loss:49.8288793849 \n",
      "tensor(-5.0163)\n",
      "tensor(67.4534)\n",
      "Epoch:398| Average Epoch loss:-0.13534277428660837495| Ndiff loss:-49.9642239166|Sparsity loss:49.8288811424 \n",
      "tensor(-5.0163)\n",
      "tensor(67.4893)\n",
      "Epoch:399| Average Epoch loss:-0.13544231492336875067| Ndiff loss:-49.9643227845|Sparsity loss:49.8288804696 \n",
      "tensor(-5.0163)\n",
      "tensor(67.5384)\n",
      "Epoch:400| Average Epoch loss:-0.13553578639225113966| Ndiff loss:-49.9644177788|Sparsity loss:49.8288819924 \n",
      "tensor(-5.0163)\n",
      "tensor(67.5724)\n",
      "Epoch:401| Average Epoch loss:-0.13563291677391081658| Ndiff loss:-49.9645141989|Sparsity loss:49.8288812821 \n",
      "tensor(-5.0163)\n",
      "tensor(67.6239)\n",
      "Epoch:402| Average Epoch loss:-0.13572700678000751418| Ndiff loss:-49.9646093601|Sparsity loss:49.8288823533 \n",
      "tensor(-5.0163)\n",
      "tensor(67.6648)\n",
      "Epoch:403| Average Epoch loss:-0.13582121385977824479| Ndiff loss:-49.9647041354|Sparsity loss:49.8288829216 \n",
      "tensor(-5.0163)\n",
      "tensor(67.6998)\n",
      "Epoch:404| Average Epoch loss:-0.13591482392685824698| Ndiff loss:-49.9647972520|Sparsity loss:49.8288824281 \n",
      "tensor(-5.0163)\n",
      "tensor(67.7498)\n",
      "Epoch:405| Average Epoch loss:-0.13600856484462772733| Ndiff loss:-49.9648925277|Sparsity loss:49.8288839629 \n",
      "tensor(-5.0163)\n",
      "tensor(67.7854)\n",
      "Epoch:406| Average Epoch loss:-0.13610127466726573697| Ndiff loss:-49.9649850700|Sparsity loss:49.8288837953 \n",
      "tensor(-5.0163)\n",
      "tensor(67.8263)\n",
      "Epoch:407| Average Epoch loss:-0.13619492027422333558| Ndiff loss:-49.9650791993|Sparsity loss:49.8288842791 \n",
      "tensor(-5.0163)\n",
      "tensor(67.8717)\n",
      "Epoch:408| Average Epoch loss:-0.13628637810873595049| Ndiff loss:-49.9651707877|Sparsity loss:49.8288844096 \n",
      "tensor(-5.0163)\n",
      "tensor(67.9140)\n",
      "Epoch:409| Average Epoch loss:-0.13637699538885705852| Ndiff loss:-49.9652621546|Sparsity loss:49.8288851592 \n",
      "tensor(-5.0163)\n",
      "tensor(67.9569)\n",
      "Epoch:410| Average Epoch loss:-0.13646878843748982968| Ndiff loss:-49.9653540535|Sparsity loss:49.8288852651 \n",
      "tensor(-5.0163)\n",
      "tensor(68.0012)\n",
      "Epoch:411| Average Epoch loss:-0.13655895378479954161| Ndiff loss:-49.9654454054|Sparsity loss:49.8288864516 \n",
      "tensor(-5.0163)\n",
      "tensor(68.0349)\n",
      "Epoch:412| Average Epoch loss:-0.13664948181886810152| Ndiff loss:-49.9655354222|Sparsity loss:49.8288859403 \n",
      "tensor(-5.0163)\n",
      "tensor(68.0778)\n",
      "Epoch:413| Average Epoch loss:-0.13673919030967476851| Ndiff loss:-49.9656257242|Sparsity loss:49.8288865339 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-5.0163)\n",
      "tensor(68.1222)\n",
      "Epoch:414| Average Epoch loss:-0.13682836018200936201| Ndiff loss:-49.9657156895|Sparsity loss:49.8288873294 \n",
      "tensor(-5.0163)\n",
      "tensor(68.1579)\n",
      "Epoch:415| Average Epoch loss:-0.13691690918871460281| Ndiff loss:-49.9658036002|Sparsity loss:49.8288866910 \n",
      "tensor(-5.0163)\n",
      "tensor(68.2093)\n",
      "Epoch:416| Average Epoch loss:-0.13700498533860600014| Ndiff loss:-49.9658933308|Sparsity loss:49.8288883454 \n",
      "tensor(-5.0163)\n",
      "tensor(68.2443)\n",
      "Epoch:417| Average Epoch loss:-0.13709391539154383577| Ndiff loss:-49.9659814092|Sparsity loss:49.8288874939 \n",
      "tensor(-5.0163)\n",
      "tensor(68.2926)\n",
      "Epoch:418| Average Epoch loss:-0.13718090854812536872| Ndiff loss:-49.9660699751|Sparsity loss:49.8288890666 \n",
      "tensor(-5.0163)\n",
      "tensor(68.3259)\n",
      "Epoch:419| Average Epoch loss:-0.13726901436756319685| Ndiff loss:-49.9661574104|Sparsity loss:49.8288883960 \n",
      "tensor(-5.0163)\n",
      "tensor(68.3729)\n",
      "Epoch:420| Average Epoch loss:-0.13735537142241149855| Ndiff loss:-49.9662453849|Sparsity loss:49.8288900135 \n",
      "tensor(-5.0163)\n",
      "tensor(68.4036)\n",
      "Epoch:421| Average Epoch loss:-0.13744223846961745039| Ndiff loss:-49.9663310647|Sparsity loss:49.8288888262 \n",
      "tensor(-5.0163)\n",
      "tensor(68.4558)\n",
      "Epoch:422| Average Epoch loss:-0.13752935232584601044| Ndiff loss:-49.9664201502|Sparsity loss:49.8288907979 \n",
      "tensor(-5.0163)\n",
      "tensor(68.4889)\n",
      "Epoch:423| Average Epoch loss:-0.13761403218787135461| Ndiff loss:-49.9665041628|Sparsity loss:49.8288901306 \n",
      "tensor(-5.0163)\n",
      "tensor(68.5290)\n",
      "Epoch:424| Average Epoch loss:-0.13769963011676644715| Ndiff loss:-49.9665904487|Sparsity loss:49.8288908186 \n",
      "tensor(-5.0163)\n",
      "tensor(68.5694)\n",
      "Epoch:425| Average Epoch loss:-0.13778483060092916457| Ndiff loss:-49.9666759714|Sparsity loss:49.8288911408 \n",
      "tensor(-5.0163)\n",
      "tensor(68.6120)\n",
      "Epoch:426| Average Epoch loss:-0.13786923792221333906| Ndiff loss:-49.9667610757|Sparsity loss:49.8288918378 \n",
      "tensor(-5.0163)\n",
      "tensor(68.6475)\n",
      "Epoch:427| Average Epoch loss:-0.13795315816832559586| Ndiff loss:-49.9668446935|Sparsity loss:49.8288915353 \n",
      "tensor(-5.0163)\n",
      "tensor(68.6895)\n",
      "Epoch:428| Average Epoch loss:-0.13803652531635021705| Ndiff loss:-49.9669295384|Sparsity loss:49.8288930131 \n",
      "tensor(-5.0163)\n",
      "tensor(68.7202)\n",
      "Epoch:429| Average Epoch loss:-0.13812184871976956879| Ndiff loss:-49.9670138393|Sparsity loss:49.8288919905 \n",
      "tensor(-5.0163)\n",
      "tensor(68.7699)\n",
      "Epoch:430| Average Epoch loss:-0.13820277494490676440| Ndiff loss:-49.9670958912|Sparsity loss:49.8288931162 \n",
      "tensor(-5.0163)\n",
      "tensor(68.8087)\n",
      "Epoch:431| Average Epoch loss:-0.13828569027493309296| Ndiff loss:-49.9671790327|Sparsity loss:49.8288933425 \n",
      "tensor(-5.0163)\n",
      "tensor(68.8480)\n",
      "Epoch:432| Average Epoch loss:-0.13836867947155756520| Ndiff loss:-49.9672626927|Sparsity loss:49.8288940133 \n",
      "tensor(-5.0163)\n",
      "tensor(68.8839)\n",
      "Epoch:433| Average Epoch loss:-0.13844783105335642381| Ndiff loss:-49.9673412263|Sparsity loss:49.8288933952 \n",
      "tensor(-5.0163)\n",
      "tensor(68.9340)\n",
      "Epoch:434| Average Epoch loss:-0.13853045398952013034| Ndiff loss:-49.9674256250|Sparsity loss:49.8288951710 \n",
      "tensor(-5.0163)\n",
      "tensor(68.9640)\n",
      "Epoch:435| Average Epoch loss:-0.13861207811946366086| Ndiff loss:-49.9675064939|Sparsity loss:49.8288944158 \n",
      "tensor(-5.0163)\n",
      "tensor(69.0066)\n",
      "Epoch:436| Average Epoch loss:-0.13869317072345666020| Ndiff loss:-49.9675883181|Sparsity loss:49.8288951474 \n",
      "tensor(-5.0163)\n",
      "tensor(69.0469)\n",
      "Epoch:437| Average Epoch loss:-0.13877403341085584043| Ndiff loss:-49.9676698268|Sparsity loss:49.8288957933 \n",
      "tensor(-5.0163)\n",
      "tensor(69.0811)\n",
      "Epoch:438| Average Epoch loss:-0.13885362413567867157| Ndiff loss:-49.9677492761|Sparsity loss:49.8288956520 \n",
      "tensor(-5.0163)\n",
      "tensor(69.1253)\n",
      "Epoch:439| Average Epoch loss:-0.13893324256279981910| Ndiff loss:-49.9678295716|Sparsity loss:49.8288963290 \n",
      "tensor(-5.0163)\n",
      "tensor(69.1613)\n",
      "Epoch:440| Average Epoch loss:-0.13901270740428492423| Ndiff loss:-49.9679094431|Sparsity loss:49.8288967357 \n",
      "tensor(-5.0163)\n",
      "tensor(69.1947)\n",
      "Epoch:441| Average Epoch loss:-0.13909143005094964929| Ndiff loss:-49.9679882891|Sparsity loss:49.8288968591 \n",
      "tensor(-5.0163)\n",
      "tensor(69.2346)\n",
      "Epoch:442| Average Epoch loss:-0.13916991238612691495| Ndiff loss:-49.9680668125|Sparsity loss:49.8288969001 \n",
      "tensor(-5.0163)\n",
      "tensor(69.2777)\n",
      "Epoch:443| Average Epoch loss:-0.13924714167838794787| Ndiff loss:-49.9681453781|Sparsity loss:49.8288982365 \n",
      "tensor(-5.0163)\n",
      "tensor(69.3075)\n",
      "Epoch:444| Average Epoch loss:-0.13932527129326960358| Ndiff loss:-49.9682229183|Sparsity loss:49.8288976470 \n",
      "tensor(-5.0163)\n",
      "tensor(69.3525)\n",
      "Epoch:445| Average Epoch loss:-0.13940291995265929881| Ndiff loss:-49.9683012507|Sparsity loss:49.8288983307 \n",
      "tensor(-5.0163)\n",
      "tensor(69.3912)\n",
      "Epoch:446| Average Epoch loss:-0.13948054587059466325| Ndiff loss:-49.9683788368|Sparsity loss:49.8288982909 \n",
      "tensor(-5.0163)\n",
      "tensor(69.4305)\n",
      "Epoch:447| Average Epoch loss:-0.13955654616269205781| Ndiff loss:-49.9684556852|Sparsity loss:49.8288991390 \n",
      "tensor(-5.0163)\n",
      "tensor(69.4671)\n",
      "Epoch:448| Average Epoch loss:-0.13963295755414190102| Ndiff loss:-49.9685318142|Sparsity loss:49.8288988566 \n",
      "tensor(-5.0163)\n",
      "tensor(69.5086)\n",
      "Epoch:449| Average Epoch loss:-0.13970818928065201203| Ndiff loss:-49.9686082439|Sparsity loss:49.8289000546 \n",
      "tensor(-5.0163)\n",
      "tensor(69.5413)\n",
      "Epoch:450| Average Epoch loss:-0.13978404476303771253| Ndiff loss:-49.9686838462|Sparsity loss:49.8288998014 \n",
      "tensor(-5.0163)\n",
      "tensor(69.5807)\n",
      "Epoch:451| Average Epoch loss:-0.13986060712434777997| Ndiff loss:-49.9687605967|Sparsity loss:49.8288999896 \n",
      "tensor(-5.0163)\n",
      "tensor(69.6229)\n",
      "Epoch:452| Average Epoch loss:-0.13993625683910890234| Ndiff loss:-49.9688368899|Sparsity loss:49.8289006330 \n",
      "tensor(-5.0163)\n",
      "tensor(69.6605)\n",
      "Epoch:453| Average Epoch loss:-0.14001090117322295692| Ndiff loss:-49.9689114869|Sparsity loss:49.8289005857 \n",
      "tensor(-5.0163)\n",
      "tensor(69.7013)\n",
      "Epoch:454| Average Epoch loss:-0.14008481285929144655| Ndiff loss:-49.9689860329|Sparsity loss:49.8289012200 \n",
      "tensor(-5.0163)\n",
      "tensor(69.7361)\n",
      "Epoch:455| Average Epoch loss:-0.14015911279846685056| Ndiff loss:-49.9690606094|Sparsity loss:49.8289014966 \n",
      "tensor(-5.0163)\n",
      "tensor(69.7713)\n",
      "Epoch:456| Average Epoch loss:-0.14023252320918505598| Ndiff loss:-49.9691345739|Sparsity loss:49.8289020507 \n",
      "tensor(-5.0163)\n",
      "tensor(69.8066)\n",
      "Epoch:457| Average Epoch loss:-0.14030663428259948500| Ndiff loss:-49.9692085078|Sparsity loss:49.8289018735 \n",
      "tensor(-5.0163)\n",
      "tensor(69.8471)\n",
      "Epoch:458| Average Epoch loss:-0.14037951806020032564| Ndiff loss:-49.9692819264|Sparsity loss:49.8289024083 \n",
      "tensor(-5.0163)\n",
      "tensor(69.8859)\n",
      "Epoch:459| Average Epoch loss:-0.14045244721630073537| Ndiff loss:-49.9693554096|Sparsity loss:49.8289029624 \n",
      "tensor(-5.0163)\n",
      "tensor(69.9177)\n",
      "Epoch:460| Average Epoch loss:-0.14052464961341509797| Ndiff loss:-49.9694278369|Sparsity loss:49.8289031873 \n",
      "tensor(-5.0163)\n",
      "tensor(69.9547)\n",
      "Epoch:461| Average Epoch loss:-0.14059690789829482060| Ndiff loss:-49.9695005581|Sparsity loss:49.8289036502 \n",
      "tensor(-5.0163)\n",
      "tensor(69.9883)\n",
      "Epoch:462| Average Epoch loss:-0.14066815442083166476| Ndiff loss:-49.9695717681|Sparsity loss:49.8289036136 \n",
      "tensor(-5.0163)\n",
      "tensor(70.0303)\n",
      "Epoch:463| Average Epoch loss:-0.14074147745346207716| Ndiff loss:-49.9696453662|Sparsity loss:49.8289038887 \n",
      "tensor(-5.0163)\n",
      "tensor(70.0679)\n",
      "Epoch:464| Average Epoch loss:-0.14081180511591759319| Ndiff loss:-49.9697165249|Sparsity loss:49.8289047198 \n",
      "tensor(-5.0163)\n",
      "tensor(70.1006)\n",
      "Epoch:465| Average Epoch loss:-0.14088268855346600117| Ndiff loss:-49.9697870227|Sparsity loss:49.8289043341 \n",
      "tensor(-5.0163)\n",
      "tensor(70.1426)\n",
      "Epoch:466| Average Epoch loss:-0.14095333498226303437| Ndiff loss:-49.9698586804|Sparsity loss:49.8289053454 \n",
      "tensor(-5.0163)\n",
      "tensor(70.1727)\n",
      "Epoch:467| Average Epoch loss:-0.14102370343357270577| Ndiff loss:-49.9699291946|Sparsity loss:49.8289054912 \n",
      "tensor(-5.0163)\n",
      "tensor(70.2061)\n",
      "Epoch:468| Average Epoch loss:-0.14109462495573055207| Ndiff loss:-49.9699999661|Sparsity loss:49.8289053411 \n",
      "tensor(-5.0163)\n",
      "tensor(70.2477)\n",
      "Epoch:469| Average Epoch loss:-0.14116340837666049857| Ndiff loss:-49.9700697562|Sparsity loss:49.8289063478 \n",
      "tensor(-5.0163)\n",
      "tensor(70.2778)\n",
      "Epoch:470| Average Epoch loss:-0.14123298129154290836| Ndiff loss:-49.9701388243|Sparsity loss:49.8289058430 \n",
      "tensor(-5.0163)\n",
      "tensor(70.3205)\n",
      "Epoch:471| Average Epoch loss:-0.14130217497356412082| Ndiff loss:-49.9702088931|Sparsity loss:49.8289067181 \n",
      "tensor(-5.0163)\n",
      "tensor(70.3540)\n",
      "Epoch:472| Average Epoch loss:-0.14137145368347681096| Ndiff loss:-49.9702778868|Sparsity loss:49.8289064332 \n",
      "tensor(-5.0163)\n",
      "tensor(70.3943)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:473| Average Epoch loss:-0.14143935412397112827| Ndiff loss:-49.9703465840|Sparsity loss:49.8289072299 \n",
      "tensor(-5.0163)\n",
      "tensor(70.4290)\n",
      "Epoch:474| Average Epoch loss:-0.14150833553030789380| Ndiff loss:-49.9704156808|Sparsity loss:49.8289073452 \n",
      "tensor(-5.0163)\n",
      "tensor(70.4646)\n",
      "Epoch:475| Average Epoch loss:-0.14157617005984945990| Ndiff loss:-49.9704839489|Sparsity loss:49.8289077789 \n",
      "tensor(-5.0163)\n",
      "tensor(70.5014)\n",
      "Epoch:476| Average Epoch loss:-0.14164465707200926681| Ndiff loss:-49.9705527363|Sparsity loss:49.8289080792 \n",
      "tensor(-5.0163)\n",
      "tensor(70.5350)\n",
      "Epoch:477| Average Epoch loss:-0.14171219836649445734| Ndiff loss:-49.9706203042|Sparsity loss:49.8289081058 \n",
      "tensor(-5.0163)\n",
      "tensor(70.5732)\n",
      "Epoch:478| Average Epoch loss:-0.14177810267389723275| Ndiff loss:-49.9706869895|Sparsity loss:49.8289088868 \n",
      "tensor(-5.0163)\n",
      "tensor(70.6048)\n",
      "Epoch:479| Average Epoch loss:-0.14184555700463816197| Ndiff loss:-49.9707542075|Sparsity loss:49.8289086505 \n",
      "tensor(-5.0163)\n",
      "tensor(70.6402)\n",
      "Epoch:480| Average Epoch loss:-0.14191196205224917981| Ndiff loss:-49.9708211855|Sparsity loss:49.8289092235 \n",
      "tensor(-5.0163)\n",
      "tensor(70.6767)\n",
      "Epoch:481| Average Epoch loss:-0.14197820190109192162| Ndiff loss:-49.9708876773|Sparsity loss:49.8289094754 \n",
      "tensor(-5.0163)\n",
      "tensor(70.7140)\n",
      "Epoch:482| Average Epoch loss:-0.14204397804454693688| Ndiff loss:-49.9709536082|Sparsity loss:49.8289096302 \n",
      "tensor(-5.0163)\n",
      "tensor(70.7479)\n",
      "Epoch:483| Average Epoch loss:-0.14210989561353276622| Ndiff loss:-49.9710204139|Sparsity loss:49.8289105183 \n",
      "tensor(-5.0163)\n",
      "tensor(70.7736)\n",
      "Epoch:484| Average Epoch loss:-0.14217533899943765596| Ndiff loss:-49.9710855983|Sparsity loss:49.8289102593 \n",
      "tensor(-5.0163)\n",
      "tensor(70.8109)\n",
      "Epoch:485| Average Epoch loss:-0.14224109941738660723| Ndiff loss:-49.9711519705|Sparsity loss:49.8289108711 \n",
      "tensor(-5.0163)\n",
      "tensor(70.8456)\n",
      "Epoch:486| Average Epoch loss:-0.14230551586149906007| Ndiff loss:-49.9712161372|Sparsity loss:49.8289106213 \n",
      "tensor(-5.0163)\n",
      "tensor(70.8845)\n",
      "Epoch:487| Average Epoch loss:-0.14236982042078713540| Ndiff loss:-49.9712813834|Sparsity loss:49.8289115630 \n",
      "tensor(-5.0163)\n",
      "tensor(70.9139)\n",
      "Epoch:488| Average Epoch loss:-0.14243516553634213984| Ndiff loss:-49.9713464414|Sparsity loss:49.8289112759 \n",
      "tensor(-5.0163)\n",
      "tensor(70.9514)\n",
      "Epoch:489| Average Epoch loss:-0.14249867231197577144| Ndiff loss:-49.9714107004|Sparsity loss:49.8289120281 \n",
      "tensor(-5.0163)\n",
      "tensor(70.9830)\n",
      "Epoch:490| Average Epoch loss:-0.14256262322251422869| Ndiff loss:-49.9714745608|Sparsity loss:49.8289119376 \n",
      "tensor(-5.0163)\n",
      "tensor(71.0175)\n",
      "Epoch:491| Average Epoch loss:-0.14262624591143099884| Ndiff loss:-49.9715387024|Sparsity loss:49.8289124565 \n",
      "tensor(-5.0163)\n",
      "tensor(71.0513)\n",
      "Epoch:492| Average Epoch loss:-0.14268980903173536512| Ndiff loss:-49.9716021384|Sparsity loss:49.8289123294 \n",
      "tensor(-5.0163)\n",
      "tensor(71.0880)\n",
      "Epoch:493| Average Epoch loss:-0.14275275790027011635| Ndiff loss:-49.9716658926|Sparsity loss:49.8289131347 \n",
      "tensor(-5.0163)\n",
      "tensor(71.1206)\n",
      "Epoch:494| Average Epoch loss:-0.14281478863662833145| Ndiff loss:-49.9717278905|Sparsity loss:49.8289131019 \n",
      "tensor(-5.0163)\n",
      "tensor(71.1538)\n",
      "Epoch:495| Average Epoch loss:-0.14287858162265246187| Ndiff loss:-49.9717921370|Sparsity loss:49.8289135554 \n",
      "tensor(-5.0163)\n",
      "tensor(71.1857)\n",
      "Epoch:496| Average Epoch loss:-0.14293948079426144204| Ndiff loss:-49.9718533276|Sparsity loss:49.8289138468 \n",
      "tensor(-5.0163)\n",
      "tensor(71.2174)\n",
      "Epoch:497| Average Epoch loss:-0.14300233559568631403| Ndiff loss:-49.9719158927|Sparsity loss:49.8289135571 \n",
      "tensor(-5.0163)\n",
      "tensor(71.2576)\n",
      "Epoch:498| Average Epoch loss:-0.14306416436558203054| Ndiff loss:-49.9719786494|Sparsity loss:49.8289144851 \n",
      "tensor(-5.0163)\n",
      "tensor(71.2877)\n",
      "Epoch:499| Average Epoch loss:-0.14312619462640757684| Ndiff loss:-49.9720404829|Sparsity loss:49.8289142883 \n",
      "tensor(-5.0163)\n",
      "tensor(71.3240)\n",
      "Epoch:500| Average Epoch loss:-0.14318727856174914836| Ndiff loss:-49.9721023273|Sparsity loss:49.8289150487 \n",
      "tensor(-5.0163)\n",
      "tensor(71.3539)\n",
      "Epoch:501| Average Epoch loss:-0.14324873075186297933| Ndiff loss:-49.9721638279|Sparsity loss:49.8289150971 \n",
      "tensor(-5.0163)\n",
      "tensor(71.3861)\n",
      "Epoch:502| Average Epoch loss:-0.14330984816661404557| Ndiff loss:-49.9722249091|Sparsity loss:49.8289150609 \n",
      "tensor(-5.0163)\n",
      "tensor(71.4246)\n",
      "Epoch:503| Average Epoch loss:-0.14336961227979352906| Ndiff loss:-49.9722855341|Sparsity loss:49.8289159218 \n",
      "tensor(-5.0163)\n",
      "tensor(71.4521)\n",
      "Epoch:504| Average Epoch loss:-0.14343030728844041732| Ndiff loss:-49.9723457168|Sparsity loss:49.8289154095 \n",
      "tensor(-5.0163)\n",
      "tensor(71.4928)\n",
      "Epoch:505| Average Epoch loss:-0.14348921099351605313| Ndiff loss:-49.9724059720|Sparsity loss:49.8289167610 \n",
      "tensor(-5.0163)\n",
      "tensor(71.5169)\n",
      "Epoch:506| Average Epoch loss:-0.14355088474875346560| Ndiff loss:-49.9724668784|Sparsity loss:49.8289159937 \n",
      "tensor(-5.0163)\n",
      "tensor(71.5564)\n",
      "Epoch:507| Average Epoch loss:-0.14360946035128366316| Ndiff loss:-49.9725264782|Sparsity loss:49.8289170178 \n",
      "tensor(-5.0163)\n",
      "tensor(71.5857)\n",
      "Epoch:508| Average Epoch loss:-0.14366949041147869526| Ndiff loss:-49.9725858957|Sparsity loss:49.8289164053 \n",
      "tensor(-5.0163)\n",
      "tensor(71.6217)\n",
      "Epoch:509| Average Epoch loss:-0.14372810081069983812| Ndiff loss:-49.9726454303|Sparsity loss:49.8289173295 \n",
      "tensor(-5.0163)\n",
      "tensor(71.6538)\n",
      "Epoch:510| Average Epoch loss:-0.14378708671195797320| Ndiff loss:-49.9727042976|Sparsity loss:49.8289172109 \n",
      "tensor(-5.0163)\n",
      "tensor(71.6893)\n",
      "Epoch:511| Average Epoch loss:-0.14384704708930545758| Ndiff loss:-49.9727648939|Sparsity loss:49.8289178468 \n",
      "tensor(-5.0163)\n",
      "tensor(71.7182)\n",
      "Epoch:512| Average Epoch loss:-0.14390438580429629201| Ndiff loss:-49.9728222867|Sparsity loss:49.8289179009 \n",
      "tensor(-5.0163)\n",
      "tensor(71.7476)\n",
      "Epoch:513| Average Epoch loss:-0.14396274148683080307| Ndiff loss:-49.9728806238|Sparsity loss:49.8289178823 \n",
      "tensor(-5.0163)\n",
      "tensor(71.7861)\n",
      "Epoch:514| Average Epoch loss:-0.14402100445285981323| Ndiff loss:-49.9729398933|Sparsity loss:49.8289188888 \n",
      "tensor(-5.0163)\n",
      "tensor(71.8116)\n",
      "Epoch:515| Average Epoch loss:-0.14407827501326408992| Ndiff loss:-49.9729967768|Sparsity loss:49.8289185018 \n",
      "tensor(-5.0163)\n",
      "tensor(71.8483)\n",
      "Epoch:516| Average Epoch loss:-0.14413569661366310015| Ndiff loss:-49.9730547652|Sparsity loss:49.8289190686 \n",
      "tensor(-5.0163)\n",
      "tensor(71.8807)\n",
      "Epoch:517| Average Epoch loss:-0.14419357049276568250| Ndiff loss:-49.9731127809|Sparsity loss:49.8289192104 \n",
      "tensor(-5.0163)\n",
      "tensor(71.9122)\n",
      "Epoch:518| Average Epoch loss:-0.14425045915435280586| Ndiff loss:-49.9731700732|Sparsity loss:49.8289196140 \n",
      "tensor(-5.0163)\n",
      "tensor(71.9411)\n",
      "Epoch:519| Average Epoch loss:-0.14430864060708692431| Ndiff loss:-49.9732280391|Sparsity loss:49.8289193985 \n",
      "tensor(-5.0163)\n",
      "tensor(71.9768)\n",
      "Epoch:520| Average Epoch loss:-0.14436423010508095399| Ndiff loss:-49.9732844923|Sparsity loss:49.8289202622 \n",
      "tensor(-5.0163)\n",
      "tensor(72.0063)\n",
      "Epoch:521| Average Epoch loss:-0.14442003777683570798| Ndiff loss:-49.9733399771|Sparsity loss:49.8289199393 \n",
      "tensor(-5.0163)\n",
      "tensor(72.0391)\n",
      "Epoch:522| Average Epoch loss:-0.14447649404854268074| Ndiff loss:-49.9733969693|Sparsity loss:49.8289204753 \n",
      "tensor(-5.0163)\n",
      "tensor(72.0729)\n",
      "Epoch:523| Average Epoch loss:-0.14453282127687139269| Ndiff loss:-49.9734534549|Sparsity loss:49.8289206336 \n",
      "tensor(-5.0163)\n",
      "tensor(72.1065)\n",
      "Epoch:524| Average Epoch loss:-0.14458894549309736499| Ndiff loss:-49.9735101191|Sparsity loss:49.8289211736 \n",
      "tensor(-5.0163)\n",
      "tensor(72.1343)\n",
      "Epoch:525| Average Epoch loss:-0.14464457259724661231| Ndiff loss:-49.9735653317|Sparsity loss:49.8289207591 \n",
      "tensor(-5.0163)\n",
      "tensor(72.1734)\n",
      "Epoch:526| Average Epoch loss:-0.14469922756109415696| Ndiff loss:-49.9736209002|Sparsity loss:49.8289216727 \n",
      "tensor(-5.0163)\n",
      "tensor(72.2004)\n",
      "Epoch:527| Average Epoch loss:-0.14475529012662846640| Ndiff loss:-49.9736767811|Sparsity loss:49.8289214910 \n",
      "tensor(-5.0163)\n",
      "tensor(72.2327)\n",
      "Epoch:528| Average Epoch loss:-0.14481021994914616835| Ndiff loss:-49.9737320984|Sparsity loss:49.8289218784 \n",
      "tensor(-5.0163)\n",
      "tensor(72.2676)\n",
      "Epoch:529| Average Epoch loss:-0.14486438366775822306| Ndiff loss:-49.9737866809|Sparsity loss:49.8289222972 \n",
      "tensor(-5.0163)\n",
      "tensor(72.2959)\n",
      "Epoch:530| Average Epoch loss:-0.14491932329720491612| Ndiff loss:-49.9738416809|Sparsity loss:49.8289223576 \n",
      "tensor(-5.0163)\n",
      "tensor(72.3260)\n",
      "Epoch:531| Average Epoch loss:-0.14497381160309785741| Ndiff loss:-49.9738964666|Sparsity loss:49.8289226550 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-5.0163)\n",
      "tensor(72.3578)\n",
      "Epoch:532| Average Epoch loss:-0.14502674066323192892| Ndiff loss:-49.9739494815|Sparsity loss:49.8289227408 \n",
      "tensor(-5.0163)\n",
      "tensor(72.3912)\n",
      "Epoch:533| Average Epoch loss:-0.14508117633335931851| Ndiff loss:-49.9740042916|Sparsity loss:49.8289231153 \n",
      "tensor(-5.0163)\n",
      "tensor(72.4226)\n",
      "Epoch:534| Average Epoch loss:-0.14513522082891266995| Ndiff loss:-49.9740586289|Sparsity loss:49.8289234080 \n",
      "tensor(-5.0163)\n",
      "tensor(72.4524)\n",
      "Epoch:535| Average Epoch loss:-0.14518887692931770061| Ndiff loss:-49.9741123669|Sparsity loss:49.8289234900 \n",
      "tensor(-5.0163)\n",
      "tensor(72.4871)\n",
      "Epoch:536| Average Epoch loss:-0.14524220043342081499| Ndiff loss:-49.9741660742|Sparsity loss:49.8289238738 \n",
      "tensor(-5.0163)\n",
      "tensor(72.5160)\n",
      "Epoch:537| Average Epoch loss:-0.14529422020677568161| Ndiff loss:-49.9742182594|Sparsity loss:49.8289240392 \n",
      "tensor(-5.0163)\n",
      "tensor(72.5424)\n",
      "Epoch:538| Average Epoch loss:-0.14534779255166560552| Ndiff loss:-49.9742718951|Sparsity loss:49.8289241026 \n",
      "tensor(-5.0163)\n",
      "tensor(72.5790)\n",
      "Epoch:539| Average Epoch loss:-0.14540067133526848875| Ndiff loss:-49.9743253378|Sparsity loss:49.8289246664 \n",
      "tensor(-5.0163)\n",
      "tensor(72.6070)\n",
      "Epoch:540| Average Epoch loss:-0.14545303479016760684| Ndiff loss:-49.9743774755|Sparsity loss:49.8289244407 \n",
      "tensor(-5.0163)\n",
      "tensor(72.6408)\n",
      "Epoch:541| Average Epoch loss:-0.14550510250480128138| Ndiff loss:-49.9744301705|Sparsity loss:49.8289250680 \n",
      "tensor(-5.0163)\n",
      "tensor(72.6702)\n",
      "Epoch:542| Average Epoch loss:-0.14555724450160509309| Ndiff loss:-49.9744826070|Sparsity loss:49.8289253625 \n",
      "tensor(-5.0163)\n",
      "tensor(72.6975)\n",
      "Epoch:543| Average Epoch loss:-0.14560924690283508220| Ndiff loss:-49.9745346760|Sparsity loss:49.8289254291 \n",
      "tensor(-5.0163)\n",
      "tensor(72.7265)\n",
      "Epoch:544| Average Epoch loss:-0.14566064083904312065| Ndiff loss:-49.9745864201|Sparsity loss:49.8289257793 \n",
      "tensor(-5.0163)\n",
      "tensor(72.7542)\n",
      "Epoch:545| Average Epoch loss:-0.14571219902097037879| Ndiff loss:-49.9746379968|Sparsity loss:49.8289257978 \n",
      "tensor(-5.0163)\n",
      "tensor(72.7884)\n",
      "Epoch:546| Average Epoch loss:-0.14576434693603268489| Ndiff loss:-49.9746901424|Sparsity loss:49.8289257954 \n",
      "tensor(-5.0163)\n",
      "tensor(72.8225)\n",
      "Epoch:547| Average Epoch loss:-0.14581421888557521971| Ndiff loss:-49.9747408186|Sparsity loss:49.8289265997 \n",
      "tensor(-5.0163)\n",
      "tensor(72.8492)\n",
      "Epoch:548| Average Epoch loss:-0.14586555287036123696| Ndiff loss:-49.9747919682|Sparsity loss:49.8289264153 \n",
      "tensor(-5.0163)\n",
      "tensor(72.8794)\n",
      "Epoch:549| Average Epoch loss:-0.14591669891011704863| Ndiff loss:-49.9748434617|Sparsity loss:49.8289267628 \n",
      "tensor(-5.0163)\n",
      "tensor(72.9106)\n",
      "Epoch:550| Average Epoch loss:-0.14596752791482556222| Ndiff loss:-49.9748946544|Sparsity loss:49.8289271265 \n",
      "tensor(-5.0163)\n",
      "tensor(72.9391)\n",
      "Epoch:551| Average Epoch loss:-0.14601816908886966484| Ndiff loss:-49.9749451197|Sparsity loss:49.8289269506 \n",
      "tensor(-5.0163)\n",
      "tensor(72.9741)\n",
      "Epoch:552| Average Epoch loss:-0.14606822882526848684| Ndiff loss:-49.9749959108|Sparsity loss:49.8289276820 \n",
      "tensor(-5.0163)\n",
      "tensor(73.0000)\n",
      "Epoch:553| Average Epoch loss:-0.14611755835665560244| Ndiff loss:-49.9750449955|Sparsity loss:49.8289274372 \n",
      "tensor(-5.0163)\n",
      "tensor(73.0310)\n",
      "Epoch:554| Average Epoch loss:-0.14616778586092729619| Ndiff loss:-49.9750955467|Sparsity loss:49.8289277608 \n",
      "tensor(-5.0163)\n",
      "tensor(73.0634)\n",
      "Epoch:555| Average Epoch loss:-0.14621775938838904585| Ndiff loss:-49.9751460527|Sparsity loss:49.8289282933 \n",
      "tensor(-5.0163)\n",
      "tensor(73.0891)\n",
      "Epoch:556| Average Epoch loss:-0.14626701568077196680| Ndiff loss:-49.9751951612|Sparsity loss:49.8289281455 \n",
      "tensor(-5.0163)\n",
      "tensor(73.1242)\n",
      "Epoch:557| Average Epoch loss:-0.14631562343571027918| Ndiff loss:-49.9752444544|Sparsity loss:49.8289288310 \n",
      "tensor(-5.0163)\n",
      "tensor(73.1501)\n",
      "Epoch:558| Average Epoch loss:-0.14636486235480777873| Ndiff loss:-49.9752930965|Sparsity loss:49.8289282342 \n",
      "tensor(-5.0163)\n",
      "tensor(73.1860)\n",
      "Epoch:559| Average Epoch loss:-0.14641434701456843004| Ndiff loss:-49.9753436455|Sparsity loss:49.8289292985 \n",
      "tensor(-5.0163)\n",
      "tensor(73.2102)\n",
      "Epoch:560| Average Epoch loss:-0.14646272832190179725| Ndiff loss:-49.9753916676|Sparsity loss:49.8289289393 \n",
      "tensor(-5.0163)\n",
      "tensor(73.2426)\n",
      "Epoch:561| Average Epoch loss:-0.14651164092769125569| Ndiff loss:-49.9754409856|Sparsity loss:49.8289293447 \n",
      "tensor(-5.0163)\n",
      "tensor(73.2733)\n",
      "Epoch:562| Average Epoch loss:-0.14655948368222521117| Ndiff loss:-49.9754890594|Sparsity loss:49.8289295757 \n",
      "tensor(-5.0163)\n",
      "tensor(73.3017)\n",
      "Epoch:563| Average Epoch loss:-0.14660874599206430435| Ndiff loss:-49.9755386983|Sparsity loss:49.8289299524 \n",
      "tensor(-5.0163)\n",
      "tensor(73.3293)\n",
      "Epoch:564| Average Epoch loss:-0.14665597997621304671| Ndiff loss:-49.9755858912|Sparsity loss:49.8289299112 \n",
      "tensor(-5.0163)\n",
      "tensor(73.3594)\n",
      "Epoch:565| Average Epoch loss:-0.14670495801638239186| Ndiff loss:-49.9756350472|Sparsity loss:49.8289300892 \n",
      "tensor(-5.0163)\n",
      "tensor(73.3908)\n",
      "Epoch:566| Average Epoch loss:-0.14675121537877564015| Ndiff loss:-49.9756817321|Sparsity loss:49.8289305167 \n",
      "tensor(-5.0163)\n",
      "tensor(73.4189)\n",
      "Epoch:567| Average Epoch loss:-0.14679900390579922465| Ndiff loss:-49.9757293939|Sparsity loss:49.8289303900 \n",
      "tensor(-5.0163)\n",
      "tensor(73.4501)\n",
      "Epoch:568| Average Epoch loss:-0.14684625977094453719| Ndiff loss:-49.9757774203|Sparsity loss:49.8289311605 \n",
      "tensor(-5.0163)\n",
      "tensor(73.4720)\n",
      "Epoch:569| Average Epoch loss:-0.14689397930706368789| Ndiff loss:-49.9758248074|Sparsity loss:49.8289308281 \n",
      "tensor(-5.0163)\n",
      "tensor(73.5042)\n",
      "Epoch:570| Average Epoch loss:-0.14694044860237870376| Ndiff loss:-49.9758718689|Sparsity loss:49.8289314203 \n",
      "tensor(-5.0163)\n",
      "tensor(73.5323)\n",
      "Epoch:571| Average Epoch loss:-0.14698812855515561160| Ndiff loss:-49.9759193089|Sparsity loss:49.8289311804 \n",
      "tensor(-5.0163)\n",
      "tensor(73.5655)\n",
      "Epoch:572| Average Epoch loss:-0.14703518437883447700| Ndiff loss:-49.9759668535|Sparsity loss:49.8289316691 \n",
      "tensor(-5.0163)\n",
      "tensor(73.5938)\n",
      "Epoch:573| Average Epoch loss:-0.14708106169737197866| Ndiff loss:-49.9760128883|Sparsity loss:49.8289318266 \n",
      "tensor(-5.0163)\n",
      "tensor(73.6220)\n",
      "Epoch:574| Average Epoch loss:-0.14712722223891935847| Ndiff loss:-49.9760592432|Sparsity loss:49.8289320210 \n",
      "tensor(-5.0163)\n",
      "tensor(73.6523)\n",
      "Epoch:575| Average Epoch loss:-0.14717434070259194367| Ndiff loss:-49.9761066242|Sparsity loss:49.8289322835 \n",
      "tensor(-5.0163)\n",
      "tensor(73.6798)\n",
      "Epoch:576| Average Epoch loss:-0.14721963607270460717| Ndiff loss:-49.9761523429|Sparsity loss:49.8289327068 \n",
      "tensor(-5.0163)\n",
      "tensor(73.7053)\n",
      "Epoch:577| Average Epoch loss:-0.14726582672793497863| Ndiff loss:-49.9761984710|Sparsity loss:49.8289326443 \n",
      "tensor(-5.0163)\n",
      "tensor(73.7334)\n",
      "Epoch:578| Average Epoch loss:-0.14731095352478323912| Ndiff loss:-49.9762437330|Sparsity loss:49.8289327794 \n",
      "tensor(-5.0163)\n",
      "tensor(73.7663)\n",
      "Epoch:579| Average Epoch loss:-0.14735779056233944129| Ndiff loss:-49.9762907853|Sparsity loss:49.8289329947 \n",
      "tensor(-5.0163)\n",
      "tensor(73.7939)\n",
      "Epoch:580| Average Epoch loss:-0.14740266538044327627| Ndiff loss:-49.9763358145|Sparsity loss:49.8289331491 \n",
      "tensor(-5.0163)\n",
      "tensor(73.8250)\n",
      "Epoch:581| Average Epoch loss:-0.14744798437206244057| Ndiff loss:-49.9763815578|Sparsity loss:49.8289335734 \n",
      "tensor(-5.0163)\n",
      "tensor(73.8502)\n",
      "Epoch:582| Average Epoch loss:-0.14749278761722686704| Ndiff loss:-49.9764265077|Sparsity loss:49.8289337200 \n",
      "tensor(-5.0163)\n",
      "tensor(73.8791)\n",
      "Epoch:583| Average Epoch loss:-0.14753752876997694443| Ndiff loss:-49.9764713819|Sparsity loss:49.8289338531 \n",
      "tensor(-5.0163)\n",
      "tensor(73.9099)\n",
      "Epoch:584| Average Epoch loss:-0.14758252214807121572| Ndiff loss:-49.9765166514|Sparsity loss:49.8289341293 \n",
      "tensor(-5.0163)\n",
      "tensor(73.9356)\n",
      "Epoch:585| Average Epoch loss:-0.14762741784606980833| Ndiff loss:-49.9765615258|Sparsity loss:49.8289341080 \n",
      "tensor(-5.0163)\n",
      "tensor(73.9669)\n",
      "Epoch:586| Average Epoch loss:-0.14767099596138144602| Ndiff loss:-49.9766055503|Sparsity loss:49.8289345543 \n",
      "tensor(-5.0163)\n",
      "tensor(73.9933)\n",
      "Epoch:587| Average Epoch loss:-0.14771525643538574446| Ndiff loss:-49.9766499237|Sparsity loss:49.8289346672 \n",
      "tensor(-5.0163)\n",
      "tensor(74.0200)\n",
      "Epoch:588| Average Epoch loss:-0.14775983903500231054| Ndiff loss:-49.9766947586|Sparsity loss:49.8289349196 \n",
      "tensor(-5.0163)\n",
      "tensor(74.0483)\n",
      "Epoch:589| Average Epoch loss:-0.14780469906639759348| Ndiff loss:-49.9767395781|Sparsity loss:49.8289348790 \n",
      "tensor(-5.0163)\n",
      "tensor(74.0787)\n",
      "Epoch:590| Average Epoch loss:-0.14784725671828782834| Ndiff loss:-49.9767825640|Sparsity loss:49.8289353073 \n",
      "tensor(-5.0163)\n",
      "tensor(74.1043)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:591| Average Epoch loss:-0.14789144390480993274| Ndiff loss:-49.9768267790|Sparsity loss:49.8289353351 \n",
      "tensor(-5.0163)\n",
      "tensor(74.1335)\n",
      "Epoch:592| Average Epoch loss:-0.14793478152661362901| Ndiff loss:-49.9768705095|Sparsity loss:49.8289357280 \n",
      "tensor(-5.0163)\n",
      "tensor(74.1604)\n",
      "Epoch:593| Average Epoch loss:-0.14797809045656309945| Ndiff loss:-49.9769135670|Sparsity loss:49.8289354766 \n",
      "tensor(-5.0163)\n",
      "tensor(74.1936)\n",
      "Epoch:594| Average Epoch loss:-0.14802137036928186831| Ndiff loss:-49.9769575799|Sparsity loss:49.8289362095 \n",
      "tensor(-5.0163)\n",
      "tensor(74.2164)\n",
      "Epoch:595| Average Epoch loss:-0.14806509315133414839| Ndiff loss:-49.9770012251|Sparsity loss:49.8289361319 \n",
      "tensor(-5.0163)\n",
      "tensor(74.2433)\n",
      "Epoch:596| Average Epoch loss:-0.14810728373989057172| Ndiff loss:-49.9770437245|Sparsity loss:49.8289364407 \n",
      "tensor(-5.0163)\n",
      "tensor(74.2713)\n",
      "Epoch:597| Average Epoch loss:-0.14815071781946542728| Ndiff loss:-49.9770873159|Sparsity loss:49.8289365981 \n",
      "tensor(-5.0163)\n",
      "tensor(74.2974)\n",
      "Epoch:598| Average Epoch loss:-0.14819308939252254231| Ndiff loss:-49.9771299135|Sparsity loss:49.8289368241 \n",
      "tensor(-5.0163)\n",
      "tensor(74.3242)\n",
      "Epoch:599| Average Epoch loss:-0.14823527537108638352| Ndiff loss:-49.9771721664|Sparsity loss:49.8289368910 \n",
      "tensor(-5.0163)\n",
      "tensor(74.3518)\n",
      "Epoch:600| Average Epoch loss:-0.14827718718090526773| Ndiff loss:-49.9772144180|Sparsity loss:49.8289372308 \n",
      "tensor(-5.0163)\n",
      "tensor(74.3804)\n",
      "Epoch:601| Average Epoch loss:-0.14831956384698427587| Ndiff loss:-49.9772565910|Sparsity loss:49.8289370272 \n",
      "tensor(-5.0163)\n",
      "tensor(74.4122)\n",
      "Epoch:602| Average Epoch loss:-0.14836167869300986855| Ndiff loss:-49.9772993599|Sparsity loss:49.8289376812 \n",
      "tensor(-5.0163)\n",
      "tensor(74.4370)\n",
      "Epoch:603| Average Epoch loss:-0.14840413936104784876| Ndiff loss:-49.9773418379|Sparsity loss:49.8289376985 \n",
      "tensor(-5.0163)\n",
      "tensor(74.4628)\n",
      "Epoch:604| Average Epoch loss:-0.14844610604122840392| Ndiff loss:-49.9773838991|Sparsity loss:49.8289377931 \n",
      "tensor(-5.0163)\n",
      "tensor(74.4914)\n",
      "Epoch:605| Average Epoch loss:-0.14848790088750382643| Ndiff loss:-49.9774260349|Sparsity loss:49.8289381340 \n",
      "tensor(-5.0163)\n",
      "tensor(74.5186)\n",
      "Epoch:606| Average Epoch loss:-0.14852892599946165841| Ndiff loss:-49.9774670664|Sparsity loss:49.8289381404 \n",
      "tensor(-5.0163)\n",
      "tensor(74.5477)\n",
      "Epoch:607| Average Epoch loss:-0.14857038936180838595| Ndiff loss:-49.9775089236|Sparsity loss:49.8289385342 \n",
      "tensor(-5.0163)\n",
      "tensor(74.5709)\n",
      "Epoch:608| Average Epoch loss:-0.14861169704062782149| Ndiff loss:-49.9775501533|Sparsity loss:49.8289384563 \n",
      "tensor(-5.0163)\n",
      "tensor(74.6016)\n",
      "Epoch:609| Average Epoch loss:-0.14865290395013039393| Ndiff loss:-49.9775916277|Sparsity loss:49.8289387237 \n",
      "tensor(-5.0163)\n",
      "tensor(74.6282)\n",
      "Epoch:610| Average Epoch loss:-0.14869406874292956378| Ndiff loss:-49.9776331195|Sparsity loss:49.8289390507 \n",
      "tensor(-5.0163)\n",
      "tensor(74.6536)\n",
      "Epoch:611| Average Epoch loss:-0.14873447781412074686| Ndiff loss:-49.9776734703|Sparsity loss:49.8289389925 \n",
      "tensor(-5.0163)\n",
      "tensor(74.6830)\n",
      "Epoch:612| Average Epoch loss:-0.14877528173466694761| Ndiff loss:-49.9777146992|Sparsity loss:49.8289394175 \n",
      "tensor(-5.0163)\n",
      "tensor(74.7085)\n",
      "Epoch:613| Average Epoch loss:-0.14881569083274234777| Ndiff loss:-49.9777551497|Sparsity loss:49.8289394588 \n",
      "tensor(-5.0163)\n",
      "tensor(74.7350)\n",
      "Epoch:614| Average Epoch loss:-0.14885629880507758593| Ndiff loss:-49.9777959977|Sparsity loss:49.8289396989 \n",
      "tensor(-5.0163)\n",
      "tensor(74.7621)\n",
      "Epoch:615| Average Epoch loss:-0.14889690463444399393| Ndiff loss:-49.9778367535|Sparsity loss:49.8289398488 \n",
      "tensor(-5.0163)\n",
      "tensor(74.7883)\n",
      "Epoch:616| Average Epoch loss:-0.14893643511316531636| Ndiff loss:-49.9778763255|Sparsity loss:49.8289398904 \n",
      "tensor(-5.0163)\n",
      "tensor(74.8180)\n",
      "Epoch:617| Average Epoch loss:-0.14897632271037627993| Ndiff loss:-49.9779168086|Sparsity loss:49.8289404859 \n",
      "tensor(-5.0163)\n",
      "tensor(74.8392)\n",
      "Epoch:618| Average Epoch loss:-0.14901645150582373822| Ndiff loss:-49.9779567473|Sparsity loss:49.8289402958 \n",
      "tensor(-5.0163)\n",
      "tensor(74.8668)\n",
      "Epoch:619| Average Epoch loss:-0.14905645555286284321| Ndiff loss:-49.9779970739|Sparsity loss:49.8289406184 \n",
      "tensor(-5.0163)\n",
      "tensor(74.8907)\n",
      "Epoch:620| Average Epoch loss:-0.14909543165068545045| Ndiff loss:-49.9780361310|Sparsity loss:49.8289406993 \n",
      "tensor(-5.0163)\n",
      "tensor(74.9160)\n",
      "Epoch:621| Average Epoch loss:-0.14913537722389710871| Ndiff loss:-49.9780763154|Sparsity loss:49.8289409382 \n",
      "tensor(-5.0163)\n",
      "tensor(74.9402)\n",
      "Epoch:622| Average Epoch loss:-0.14917465079493574809| Ndiff loss:-49.9781155410|Sparsity loss:49.8289408902 \n",
      "tensor(-5.0163)\n",
      "tensor(74.9692)\n",
      "Epoch:623| Average Epoch loss:-0.14921344758502838590| Ndiff loss:-49.9781548572|Sparsity loss:49.8289414096 \n",
      "tensor(-5.0163)\n",
      "tensor(74.9957)\n",
      "Epoch:624| Average Epoch loss:-0.14925268364363988849| Ndiff loss:-49.9781939263|Sparsity loss:49.8289412426 \n",
      "tensor(-5.0163)\n",
      "tensor(75.0252)\n",
      "Epoch:625| Average Epoch loss:-0.14929078740354778665| Ndiff loss:-49.9782325025|Sparsity loss:49.8289417151 \n",
      "tensor(-5.0163)\n",
      "tensor(75.0477)\n",
      "Epoch:626| Average Epoch loss:-0.14933038559595365746| Ndiff loss:-49.9782721390|Sparsity loss:49.8289417534 \n",
      "tensor(-5.0163)\n",
      "tensor(75.0758)\n",
      "Epoch:627| Average Epoch loss:-0.14936860924067196787| Ndiff loss:-49.9783103476|Sparsity loss:49.8289417384 \n",
      "tensor(-5.0163)\n",
      "tensor(75.1046)\n",
      "Epoch:628| Average Epoch loss:-0.14940769746902857196| Ndiff loss:-49.9783500358|Sparsity loss:49.8289423383 \n",
      "tensor(-5.0163)\n",
      "tensor(75.1277)\n",
      "Epoch:629| Average Epoch loss:-0.14944618961039266014| Ndiff loss:-49.9783884522|Sparsity loss:49.8289422626 \n",
      "tensor(-5.0163)\n",
      "tensor(75.1539)\n",
      "Epoch:630| Average Epoch loss:-0.14948455462801668592| Ndiff loss:-49.9784268323|Sparsity loss:49.8289422777 \n",
      "tensor(-5.0163)\n",
      "tensor(75.1832)\n",
      "Epoch:631| Average Epoch loss:-0.14952203848907311134| Ndiff loss:-49.9784647152|Sparsity loss:49.8289426767 \n",
      "tensor(-5.0163)\n",
      "tensor(75.2068)\n",
      "Epoch:632| Average Epoch loss:-0.14956090227816076776| Ndiff loss:-49.9785035691|Sparsity loss:49.8289426669 \n",
      "tensor(-5.0163)\n",
      "tensor(75.2354)\n",
      "Epoch:633| Average Epoch loss:-0.14959860304989427982| Ndiff loss:-49.9785415691|Sparsity loss:49.8289429661 \n",
      "tensor(-5.0163)\n",
      "tensor(75.2611)\n",
      "Epoch:634| Average Epoch loss:-0.14963626150832670669| Ndiff loss:-49.9785793274|Sparsity loss:49.8289430658 \n",
      "tensor(-5.0163)\n",
      "tensor(75.2850)\n",
      "Epoch:635| Average Epoch loss:-0.14967412022948975436| Ndiff loss:-49.9786173740|Sparsity loss:49.8289432538 \n",
      "tensor(-5.0163)\n",
      "tensor(75.3113)\n",
      "Epoch:636| Average Epoch loss:-0.14971158483027047215| Ndiff loss:-49.9786549271|Sparsity loss:49.8289433423 \n",
      "tensor(-5.0163)\n",
      "tensor(75.3381)\n",
      "Epoch:637| Average Epoch loss:-0.14974867732422225686| Ndiff loss:-49.9786922574|Sparsity loss:49.8289435801 \n",
      "tensor(-5.0163)\n",
      "tensor(75.3653)\n",
      "Epoch:638| Average Epoch loss:-0.14978686571135449435| Ndiff loss:-49.9787305855|Sparsity loss:49.8289437198 \n",
      "tensor(-5.0163)\n",
      "tensor(75.3913)\n",
      "Epoch:639| Average Epoch loss:-0.14982344822020168817| Ndiff loss:-49.9787675041|Sparsity loss:49.8289440559 \n",
      "tensor(-5.0163)\n",
      "tensor(75.4146)\n",
      "Epoch:640| Average Epoch loss:-0.14986046292339436081| Ndiff loss:-49.9788046974|Sparsity loss:49.8289442345 \n",
      "tensor(-5.0163)\n",
      "tensor(75.4357)\n",
      "Epoch:641| Average Epoch loss:-0.14989747459198138335| Ndiff loss:-49.9788415211|Sparsity loss:49.8289440465 \n",
      "tensor(-5.0163)\n",
      "tensor(75.4650)\n",
      "Epoch:642| Average Epoch loss:-0.14993454316462301312| Ndiff loss:-49.9788791264|Sparsity loss:49.8289445833 \n",
      "tensor(-5.0163)\n",
      "tensor(75.4890)\n",
      "Epoch:643| Average Epoch loss:-0.14997132042558389275| Ndiff loss:-49.9789158117|Sparsity loss:49.8289444913 \n",
      "tensor(-5.0163)\n",
      "tensor(75.5142)\n",
      "Epoch:644| Average Epoch loss:-0.15000787943005911007| Ndiff loss:-49.9789527179|Sparsity loss:49.8289448385 \n",
      "tensor(-5.0163)\n",
      "tensor(75.5380)\n",
      "Epoch:645| Average Epoch loss:-0.15004482269609870082| Ndiff loss:-49.9789895551|Sparsity loss:49.8289447324 \n",
      "tensor(-5.0163)\n",
      "tensor(75.5670)\n",
      "Epoch:646| Average Epoch loss:-0.15008109241156752933| Ndiff loss:-49.9790260382|Sparsity loss:49.8289449458 \n",
      "tensor(-5.0163)\n",
      "tensor(75.5946)\n",
      "Epoch:647| Average Epoch loss:-0.15011728198998852690| Ndiff loss:-49.9790626358|Sparsity loss:49.8289453538 \n",
      "tensor(-5.0163)\n",
      "tensor(75.6168)\n",
      "Epoch:648| Average Epoch loss:-0.15015372745805855015| Ndiff loss:-49.9790988878|Sparsity loss:49.8289451603 \n",
      "tensor(-5.0163)\n",
      "tensor(75.6446)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:649| Average Epoch loss:-0.15018965053705260471| Ndiff loss:-49.9791353309|Sparsity loss:49.8289456804 \n",
      "tensor(-5.0163)\n",
      "tensor(75.6670)\n",
      "Epoch:650| Average Epoch loss:-0.15022546888514654029| Ndiff loss:-49.9791710864|Sparsity loss:49.8289456175 \n",
      "tensor(-5.0163)\n",
      "tensor(75.6969)\n",
      "Epoch:651| Average Epoch loss:-0.15026070097240307177| Ndiff loss:-49.9792066345|Sparsity loss:49.8289459335 \n",
      "tensor(-5.0163)\n",
      "tensor(75.7186)\n",
      "Epoch:652| Average Epoch loss:-0.15029747765281145644| Ndiff loss:-49.9792434655|Sparsity loss:49.8289459878 \n",
      "tensor(-5.0163)\n",
      "tensor(75.7433)\n",
      "Epoch:653| Average Epoch loss:-0.15033227576760033184| Ndiff loss:-49.9792786270|Sparsity loss:49.8289463512 \n",
      "tensor(-5.0163)\n",
      "tensor(75.7648)\n",
      "Epoch:654| Average Epoch loss:-0.15036831218913743191| Ndiff loss:-49.9793144679|Sparsity loss:49.8289461557 \n",
      "tensor(-5.0163)\n",
      "tensor(75.7940)\n",
      "Epoch:655| Average Epoch loss:-0.15040303440592633910| Ndiff loss:-49.9793496334|Sparsity loss:49.8289465990 \n",
      "tensor(-5.0163)\n",
      "tensor(75.8164)\n",
      "Epoch:656| Average Epoch loss:-0.15043851606778110841| Ndiff loss:-49.9793850596|Sparsity loss:49.8289465436 \n",
      "tensor(-5.0163)\n",
      "tensor(75.8441)\n",
      "Epoch:657| Average Epoch loss:-0.15047368981485734207| Ndiff loss:-49.9794205523|Sparsity loss:49.8289468625 \n",
      "tensor(-5.0163)\n",
      "tensor(75.8668)\n",
      "Epoch:658| Average Epoch loss:-0.15050886800893595319| Ndiff loss:-49.9794558328|Sparsity loss:49.8289469647 \n",
      "tensor(-5.0163)\n",
      "tensor(75.8907)\n",
      "Epoch:659| Average Epoch loss:-0.15054380681621834515| Ndiff loss:-49.9794906796|Sparsity loss:49.8289468728 \n",
      "tensor(-5.0163)\n",
      "tensor(75.9216)\n",
      "Epoch:660| Average Epoch loss:-0.15057850663174063288| Ndiff loss:-49.9795257877|Sparsity loss:49.8289472811 \n",
      "tensor(-5.0163)\n",
      "tensor(75.9438)\n",
      "Epoch:661| Average Epoch loss:-0.15061269630426307731| Ndiff loss:-49.9795602296|Sparsity loss:49.8289475333 \n",
      "tensor(-5.0163)\n",
      "tensor(75.9673)\n",
      "Epoch:662| Average Epoch loss:-0.15064757959601493553| Ndiff loss:-49.9795950232|Sparsity loss:49.8289474436 \n",
      "tensor(-5.0163)\n",
      "tensor(75.9943)\n",
      "Epoch:663| Average Epoch loss:-0.15068225133641355296| Ndiff loss:-49.9796298927|Sparsity loss:49.8289476414 \n",
      "tensor(-5.0163)\n",
      "tensor(76.0205)\n",
      "Epoch:664| Average Epoch loss:-0.15071556328688848203| Ndiff loss:-49.9796635826|Sparsity loss:49.8289480194 \n",
      "tensor(-5.0163)\n",
      "tensor(76.0421)\n",
      "Epoch:665| Average Epoch loss:-0.15075029743969872720| Ndiff loss:-49.9796983088|Sparsity loss:49.8289480114 \n",
      "tensor(-5.0163)\n",
      "tensor(76.0665)\n",
      "Epoch:666| Average Epoch loss:-0.15078493272912080192| Ndiff loss:-49.9797330817|Sparsity loss:49.8289481490 \n",
      "tensor(-5.0163)\n",
      "tensor(76.0928)\n",
      "Epoch:667| Average Epoch loss:-0.15081923822841425409| Ndiff loss:-49.9797675143|Sparsity loss:49.8289482761 \n",
      "tensor(-5.0163)\n",
      "tensor(76.1165)\n",
      "Epoch:668| Average Epoch loss:-0.15085309690234222080| Ndiff loss:-49.9798014524|Sparsity loss:49.8289483555 \n",
      "tensor(-5.0163)\n",
      "tensor(76.1458)\n",
      "Epoch:669| Average Epoch loss:-0.15088775336118587234| Ndiff loss:-49.9798364478|Sparsity loss:49.8289486944 \n",
      "tensor(-5.0163)\n",
      "tensor(76.1673)\n",
      "Epoch:670| Average Epoch loss:-0.15092101038479080466| Ndiff loss:-49.9798697345|Sparsity loss:49.8289487241 \n",
      "tensor(-5.0163)\n",
      "tensor(76.1926)\n",
      "Epoch:671| Average Epoch loss:-0.15095392036356930499| Ndiff loss:-49.9799029303|Sparsity loss:49.8289490100 \n",
      "tensor(-5.0163)\n",
      "tensor(76.2158)\n",
      "Epoch:672| Average Epoch loss:-0.15098780415439547187| Ndiff loss:-49.9799368453|Sparsity loss:49.8289490412 \n",
      "tensor(-5.0163)\n",
      "tensor(76.2392)\n",
      "Epoch:673| Average Epoch loss:-0.15102109174859557061| Ndiff loss:-49.9799702877|Sparsity loss:49.8289491960 \n",
      "tensor(-5.0163)\n",
      "tensor(76.2616)\n",
      "Epoch:674| Average Epoch loss:-0.15105435585585447189| Ndiff loss:-49.9800037520|Sparsity loss:49.8289493962 \n",
      "tensor(-5.0163)\n",
      "tensor(76.2852)\n",
      "Epoch:675| Average Epoch loss:-0.15108784219546539385| Ndiff loss:-49.9800373459|Sparsity loss:49.8289495037 \n",
      "tensor(-5.0163)\n",
      "tensor(76.3113)\n",
      "Epoch:676| Average Epoch loss:-0.15112104200440987234| Ndiff loss:-49.9800707450|Sparsity loss:49.8289497030 \n",
      "tensor(-5.0163)\n",
      "tensor(76.3343)\n",
      "Epoch:677| Average Epoch loss:-0.15115407246449980017| Ndiff loss:-49.9801038486|Sparsity loss:49.8289497761 \n",
      "tensor(-5.0163)\n",
      "tensor(76.3586)\n",
      "Epoch:678| Average Epoch loss:-0.15118716830037864929| Ndiff loss:-49.9801371543|Sparsity loss:49.8289499860 \n",
      "tensor(-5.0163)\n",
      "tensor(76.3818)\n",
      "Epoch:679| Average Epoch loss:-0.15121972819130824472| Ndiff loss:-49.9801698403|Sparsity loss:49.8289501121 \n",
      "tensor(-5.0163)\n",
      "tensor(76.4042)\n",
      "Epoch:680| Average Epoch loss:-0.15125264178578923246| Ndiff loss:-49.9802027468|Sparsity loss:49.8289501050 \n",
      "tensor(-5.0163)\n",
      "tensor(76.4297)\n",
      "Epoch:681| Average Epoch loss:-0.15128515527898361848| Ndiff loss:-49.9802355343|Sparsity loss:49.8289503790 \n",
      "tensor(-5.0163)\n",
      "tensor(76.4548)\n",
      "Epoch:682| Average Epoch loss:-0.15131769615105264415| Ndiff loss:-49.9802683388|Sparsity loss:49.8289506427 \n",
      "tensor(-5.0163)\n",
      "tensor(76.4788)\n",
      "Epoch:683| Average Epoch loss:-0.15134995476486817756| Ndiff loss:-49.9803004914|Sparsity loss:49.8289505366 \n",
      "tensor(-5.0163)\n",
      "tensor(76.5040)\n",
      "Epoch:684| Average Epoch loss:-0.15138240691018090001| Ndiff loss:-49.9803331691|Sparsity loss:49.8289507622 \n",
      "tensor(-5.0163)\n",
      "tensor(76.5280)\n",
      "Epoch:685| Average Epoch loss:-0.15141472616240114757| Ndiff loss:-49.9803657125|Sparsity loss:49.8289509863 \n",
      "tensor(-5.0163)\n",
      "tensor(76.5517)\n",
      "Epoch:686| Average Epoch loss:-0.15144671352697219868| Ndiff loss:-49.9803977349|Sparsity loss:49.8289510213 \n",
      "tensor(-5.0163)\n",
      "tensor(76.5752)\n",
      "Epoch:687| Average Epoch loss:-0.15147949759808040926| Ndiff loss:-49.9804306237|Sparsity loss:49.8289511261 \n",
      "tensor(-5.0163)\n",
      "tensor(76.6012)\n",
      "Epoch:688| Average Epoch loss:-0.15151127030601133083| Ndiff loss:-49.9804627338|Sparsity loss:49.8289514635 \n",
      "tensor(-5.0163)\n",
      "tensor(76.6214)\n",
      "Epoch:689| Average Epoch loss:-0.15154280109462683890| Ndiff loss:-49.9804943095|Sparsity loss:49.8289515084 \n",
      "tensor(-5.0163)\n",
      "tensor(76.6436)\n",
      "Epoch:690| Average Epoch loss:-0.15157446626831549974| Ndiff loss:-49.9805259346|Sparsity loss:49.8289514683 \n",
      "tensor(-5.0163)\n",
      "tensor(76.6714)\n",
      "Epoch:691| Average Epoch loss:-0.15160598397779601054| Ndiff loss:-49.9805577286|Sparsity loss:49.8289517446 \n",
      "tensor(-5.0163)\n",
      "tensor(76.6957)\n",
      "Epoch:692| Average Epoch loss:-0.15163810882532124946| Ndiff loss:-49.9805900107|Sparsity loss:49.8289519018 \n",
      "tensor(-5.0163)\n",
      "tensor(76.7182)\n",
      "Epoch:693| Average Epoch loss:-0.15166967174932979856| Ndiff loss:-49.9806218265|Sparsity loss:49.8289521547 \n",
      "tensor(-5.0163)\n",
      "tensor(76.7407)\n",
      "Epoch:694| Average Epoch loss:-0.15170066494349873643| Ndiff loss:-49.9806529737|Sparsity loss:49.8289523087 \n",
      "tensor(-5.0163)\n",
      "tensor(76.7616)\n",
      "Epoch:695| Average Epoch loss:-0.15173285958179269506| Ndiff loss:-49.9806849996|Sparsity loss:49.8289521400 \n",
      "tensor(-5.0163)\n",
      "tensor(76.7893)\n",
      "Epoch:696| Average Epoch loss:-0.15176322148779025634| Ndiff loss:-49.9807157639|Sparsity loss:49.8289525424 \n",
      "tensor(-5.0163)\n",
      "tensor(76.8126)\n",
      "Epoch:697| Average Epoch loss:-0.15179453208460891300| Ndiff loss:-49.9807471712|Sparsity loss:49.8289526391 \n",
      "tensor(-5.0163)\n",
      "tensor(76.8350)\n",
      "Epoch:698| Average Epoch loss:-0.15182496033153786152| Ndiff loss:-49.9807777722|Sparsity loss:49.8289528119 \n",
      "tensor(-5.0163)\n",
      "tensor(76.8563)\n",
      "Epoch:699| Average Epoch loss:-0.15185610670668678313| Ndiff loss:-49.9808088787|Sparsity loss:49.8289527720 \n",
      "tensor(-5.0163)\n",
      "tensor(76.8808)\n",
      "Epoch:700| Average Epoch loss:-0.15188698364433664278| Ndiff loss:-49.9808399909|Sparsity loss:49.8289530073 \n",
      "tensor(-5.0163)\n",
      "tensor(76.9046)\n",
      "Epoch:701| Average Epoch loss:-0.15191735334254571899| Ndiff loss:-49.9808705920|Sparsity loss:49.8289532387 \n",
      "tensor(-5.0163)\n",
      "tensor(76.9262)\n",
      "Epoch:702| Average Epoch loss:-0.15194869635161328825| Ndiff loss:-49.9809017767|Sparsity loss:49.8289530803 \n",
      "tensor(-5.0163)\n",
      "tensor(76.9522)\n",
      "Epoch:703| Average Epoch loss:-0.15197888602808065639| Ndiff loss:-49.9809323738|Sparsity loss:49.8289534878 \n",
      "tensor(-5.0163)\n",
      "tensor(76.9768)\n",
      "Epoch:704| Average Epoch loss:-0.15200935663080786253| Ndiff loss:-49.9809628307|Sparsity loss:49.8289534741 \n",
      "tensor(-5.0163)\n",
      "tensor(77.0013)\n",
      "Epoch:705| Average Epoch loss:-0.15203979042456022830| Ndiff loss:-49.9809935847|Sparsity loss:49.8289537942 \n",
      "tensor(-5.0163)\n",
      "tensor(77.0231)\n",
      "Epoch:706| Average Epoch loss:-0.15207060424495663642| Ndiff loss:-49.9810242814|Sparsity loss:49.8289536772 \n",
      "tensor(-5.0163)\n",
      "tensor(77.0500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:707| Average Epoch loss:-0.15210033813563583749| Ndiff loss:-49.9810543911|Sparsity loss:49.8289540530 \n",
      "tensor(-5.0163)\n",
      "tensor(77.0711)\n",
      "Epoch:708| Average Epoch loss:-0.15213018289820112727| Ndiff loss:-49.9810842244|Sparsity loss:49.8289540415 \n",
      "tensor(-5.0163)\n",
      "tensor(77.0917)\n",
      "Epoch:709| Average Epoch loss:-0.15216035836401234360| Ndiff loss:-49.9811147009|Sparsity loss:49.8289543425 \n",
      "tensor(-5.0163)\n",
      "tensor(77.1137)\n",
      "Epoch:710| Average Epoch loss:-0.15219069525170189627| Ndiff loss:-49.9811449619|Sparsity loss:49.8289542666 \n",
      "tensor(-5.0163)\n",
      "tensor(77.1381)\n",
      "Epoch:711| Average Epoch loss:-0.15222054765562376133| Ndiff loss:-49.9811751116|Sparsity loss:49.8289545639 \n",
      "tensor(-5.0163)\n",
      "tensor(77.1595)\n",
      "Epoch:712| Average Epoch loss:-0.15225033417964478621| Ndiff loss:-49.9812049552|Sparsity loss:49.8289546210 \n",
      "tensor(-5.0163)\n",
      "tensor(77.1825)\n",
      "Epoch:713| Average Epoch loss:-0.15227922223420264913| Ndiff loss:-49.9812340797|Sparsity loss:49.8289548575 \n",
      "tensor(-5.0163)\n",
      "tensor(77.2030)\n",
      "Epoch:714| Average Epoch loss:-0.15230926048271933859| Ndiff loss:-49.9812640506|Sparsity loss:49.8289547901 \n",
      "tensor(-5.0163)\n",
      "tensor(77.2294)\n",
      "Epoch:715| Average Epoch loss:-0.15233854880821498523| Ndiff loss:-49.9812935863|Sparsity loss:49.8289550375 \n",
      "tensor(-5.0163)\n",
      "tensor(77.2514)\n",
      "Epoch:716| Average Epoch loss:-0.15236784422777086001| Ndiff loss:-49.9813230786|Sparsity loss:49.8289552343 \n",
      "tensor(-5.0163)\n",
      "tensor(77.2712)\n",
      "Epoch:717| Average Epoch loss:-0.15239735686826230698| Ndiff loss:-49.9813525238|Sparsity loss:49.8289551670 \n",
      "tensor(-5.0163)\n",
      "tensor(77.2969)\n",
      "Epoch:718| Average Epoch loss:-0.15242648605575859211| Ndiff loss:-49.9813819993|Sparsity loss:49.8289555132 \n",
      "tensor(-5.0163)\n",
      "tensor(77.3168)\n",
      "Epoch:719| Average Epoch loss:-0.15245588487450392745| Ndiff loss:-49.9814111251|Sparsity loss:49.8289552402 \n",
      "tensor(-5.0163)\n",
      "tensor(77.3449)\n",
      "Epoch:720| Average Epoch loss:-0.15248469321128788057| Ndiff loss:-49.9814405301|Sparsity loss:49.8289558369 \n",
      "tensor(-5.0163)\n",
      "tensor(77.3623)\n",
      "Epoch:721| Average Epoch loss:-0.15251372998208939658| Ndiff loss:-49.9814693531|Sparsity loss:49.8289556231 \n",
      "tensor(-5.0163)\n",
      "tensor(77.3876)\n",
      "Epoch:722| Average Epoch loss:-0.15254275120993357473| Ndiff loss:-49.9814987881|Sparsity loss:49.8289560369 \n",
      "tensor(-5.0163)\n",
      "tensor(77.4081)\n",
      "Epoch:723| Average Epoch loss:-0.15257136895554404554| Ndiff loss:-49.9815271688|Sparsity loss:49.8289557999 \n",
      "tensor(-5.0163)\n",
      "tensor(77.4341)\n",
      "Epoch:724| Average Epoch loss:-0.15260059559139646512| Ndiff loss:-49.9815568618|Sparsity loss:49.8289562662 \n",
      "tensor(-5.0163)\n",
      "tensor(77.4543)\n",
      "Epoch:725| Average Epoch loss:-0.15262880757314511992| Ndiff loss:-49.9815851281|Sparsity loss:49.8289563205 \n",
      "tensor(-5.0163)\n",
      "tensor(77.4762)\n",
      "Epoch:726| Average Epoch loss:-0.15265739629284563739| Ndiff loss:-49.9816136571|Sparsity loss:49.8289562609 \n",
      "tensor(-5.0163)\n",
      "tensor(77.5021)\n",
      "Epoch:727| Average Epoch loss:-0.15268605374669086405| Ndiff loss:-49.9816426766|Sparsity loss:49.8289566229 \n",
      "tensor(-5.0163)\n",
      "tensor(77.5236)\n",
      "Epoch:728| Average Epoch loss:-0.15271458891976330552| Ndiff loss:-49.9816712619|Sparsity loss:49.8289566730 \n",
      "tensor(-5.0163)\n",
      "tensor(77.5449)\n",
      "Epoch:729| Average Epoch loss:-0.15274246375832786771| Ndiff loss:-49.9816991068|Sparsity loss:49.8289566430 \n",
      "tensor(-5.0163)\n",
      "tensor(77.5700)\n",
      "Epoch:730| Average Epoch loss:-0.15277128050261545855| Ndiff loss:-49.9817283431|Sparsity loss:49.8289570626 \n",
      "tensor(-5.0163)\n",
      "tensor(77.5882)\n",
      "Epoch:731| Average Epoch loss:-0.15279956066645025703| Ndiff loss:-49.9817565419|Sparsity loss:49.8289569813 \n",
      "tensor(-5.0163)\n",
      "tensor(77.6116)\n",
      "Epoch:732| Average Epoch loss:-0.15282730105393860232| Ndiff loss:-49.9817843736|Sparsity loss:49.8289570725 \n",
      "tensor(-5.0163)\n",
      "tensor(77.6361)\n",
      "Epoch:733| Average Epoch loss:-0.15285508137494474568| Ndiff loss:-49.9818123032|Sparsity loss:49.8289572218 \n",
      "tensor(-5.0163)\n",
      "tensor(77.6600)\n",
      "Epoch:734| Average Epoch loss:-0.15288301071061460856| Ndiff loss:-49.9818404634|Sparsity loss:49.8289574527 \n",
      "tensor(-5.0163)\n",
      "tensor(77.6781)\n",
      "Epoch:735| Average Epoch loss:-0.15291096854089167301| Ndiff loss:-49.9818683813|Sparsity loss:49.8289574127 \n",
      "tensor(-5.0163)\n",
      "tensor(77.7018)\n",
      "Epoch:736| Average Epoch loss:-0.15293874475901722554| Ndiff loss:-49.9818964928|Sparsity loss:49.8289577480 \n",
      "tensor(-5.0163)\n",
      "tensor(77.7218)\n",
      "Epoch:737| Average Epoch loss:-0.15296675980072332868| Ndiff loss:-49.9819244049|Sparsity loss:49.8289576451 \n",
      "tensor(-5.0163)\n",
      "tensor(77.7474)\n",
      "Epoch:738| Average Epoch loss:-0.15299417969192832811| Ndiff loss:-49.9819521227|Sparsity loss:49.8289579430 \n",
      "tensor(-5.0163)\n",
      "tensor(77.7690)\n",
      "Epoch:739| Average Epoch loss:-0.15302193802726074545| Ndiff loss:-49.9819799269|Sparsity loss:49.8289579889 \n",
      "tensor(-5.0163)\n",
      "tensor(77.7921)\n",
      "Epoch:740| Average Epoch loss:-0.15304945517281609568| Ndiff loss:-49.9820077181|Sparsity loss:49.8289582630 \n",
      "tensor(-5.0163)\n",
      "tensor(77.8100)\n",
      "Epoch:741| Average Epoch loss:-0.15307685115659649955| Ndiff loss:-49.9820350472|Sparsity loss:49.8289581960 \n",
      "tensor(-5.0163)\n",
      "tensor(77.8335)\n",
      "Epoch:742| Average Epoch loss:-0.15310380382045549186| Ndiff loss:-49.9820621322|Sparsity loss:49.8289583283 \n",
      "tensor(-5.0163)\n",
      "tensor(77.8560)\n",
      "Epoch:743| Average Epoch loss:-0.15313088521499748640| Ndiff loss:-49.9820894256|Sparsity loss:49.8289585404 \n",
      "tensor(-5.0163)\n",
      "tensor(77.8777)\n",
      "Epoch:744| Average Epoch loss:-0.15316119754534598951| Ndiff loss:-49.9821197205|Sparsity loss:49.8289585229 \n",
      "tensor(-5.0163)\n",
      "tensor(77.9032)\n",
      "Epoch:745| Average Epoch loss:-0.15319109803818597992| Ndiff loss:-49.9821499420|Sparsity loss:49.8289588439 \n",
      "tensor(-5.0163)\n",
      "tensor(77.9223)\n",
      "Epoch:746| Average Epoch loss:-0.15322070588662561885| Ndiff loss:-49.9821795386|Sparsity loss:49.8289588327 \n",
      "tensor(-5.0163)\n",
      "tensor(77.9456)\n",
      "Epoch:747| Average Epoch loss:-0.15325012164547915927| Ndiff loss:-49.9822092293|Sparsity loss:49.8289591077 \n",
      "tensor(-5.0163)\n",
      "tensor(77.9678)\n",
      "Epoch:748| Average Epoch loss:-0.15327994748052692353| Ndiff loss:-49.9822390326|Sparsity loss:49.8289590851 \n",
      "tensor(-5.0163)\n",
      "tensor(77.9906)\n",
      "Epoch:749| Average Epoch loss:-0.15330926649084336555| Ndiff loss:-49.9822685549|Sparsity loss:49.8289592884 \n",
      "tensor(-5.0163)\n",
      "tensor(78.0129)\n",
      "Epoch:750| Average Epoch loss:-0.15333849733468932208| Ndiff loss:-49.9822980681|Sparsity loss:49.8289595707 \n",
      "tensor(-5.0163)\n",
      "tensor(78.0320)\n",
      "Epoch:751| Average Epoch loss:-0.15336817461512020078| Ndiff loss:-49.9823276978|Sparsity loss:49.8289595232 \n",
      "tensor(-5.0163)\n",
      "tensor(78.0558)\n",
      "Epoch:752| Average Epoch loss:-0.15339451745121518433| Ndiff loss:-49.9823541893|Sparsity loss:49.8289596718 \n",
      "tensor(-5.0163)\n",
      "tensor(78.0790)\n",
      "Epoch:753| Average Epoch loss:-0.15342089770888259204| Ndiff loss:-49.9823807347|Sparsity loss:49.8289598370 \n",
      "tensor(-5.0163)\n",
      "tensor(78.0984)\n",
      "Epoch:754| Average Epoch loss:-0.15344730986023139008| Ndiff loss:-49.9824070755|Sparsity loss:49.8289597657 \n",
      "tensor(-5.0163)\n",
      "tensor(78.1250)\n",
      "Epoch:755| Average Epoch loss:-0.15347377036265066885| Ndiff loss:-49.9824338429|Sparsity loss:49.8289600725 \n",
      "tensor(-5.0163)\n",
      "tensor(78.1441)\n",
      "Epoch:756| Average Epoch loss:-0.15349960601378576097| Ndiff loss:-49.9824597085|Sparsity loss:49.8289601025 \n",
      "tensor(-5.0163)\n",
      "tensor(78.1654)\n",
      "Epoch:757| Average Epoch loss:-0.15352588296747407548| Ndiff loss:-49.9824861360|Sparsity loss:49.8289602530 \n",
      "tensor(-5.0163)\n",
      "tensor(78.1860)\n",
      "Epoch:758| Average Epoch loss:-0.15355221499739318824| Ndiff loss:-49.9825124791|Sparsity loss:49.8289602641 \n",
      "tensor(-5.0163)\n",
      "tensor(78.2101)\n",
      "Epoch:759| Average Epoch loss:-0.15357775689078914660| Ndiff loss:-49.9825384015|Sparsity loss:49.8289606446 \n",
      "tensor(-5.0163)\n",
      "tensor(78.2269)\n",
      "Epoch:760| Average Epoch loss:-0.15360392522890642386| Ndiff loss:-49.9825642975|Sparsity loss:49.8289603723 \n",
      "tensor(-5.0163)\n",
      "tensor(78.2540)\n",
      "Epoch:761| Average Epoch loss:-0.15362949372098022582| Ndiff loss:-49.9825903434|Sparsity loss:49.8289608497 \n",
      "tensor(-5.0163)\n",
      "tensor(78.2726)\n",
      "Epoch:762| Average Epoch loss:-0.15365576974221184514| Ndiff loss:-49.9826164476|Sparsity loss:49.8289606779 \n",
      "tensor(-5.0163)\n",
      "tensor(78.2955)\n",
      "Epoch:763| Average Epoch loss:-0.15368129640186406482| Ndiff loss:-49.9826422481|Sparsity loss:49.8289609517 \n",
      "tensor(-5.0163)\n",
      "tensor(78.3149)\n",
      "Epoch:764| Average Epoch loss:-0.15370700465860309691| Ndiff loss:-49.9826681093|Sparsity loss:49.8289611046 \n",
      "tensor(-5.0163)\n",
      "tensor(78.3363)\n",
      "Epoch:765| Average Epoch loss:-0.15373266836463667095| Ndiff loss:-49.9826937411|Sparsity loss:49.8289610728 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-5.0163)\n",
      "tensor(78.3579)\n",
      "Epoch:766| Average Epoch loss:-0.15375783662786643435| Ndiff loss:-49.9827191250|Sparsity loss:49.8289612884 \n",
      "tensor(-5.0163)\n",
      "tensor(78.3796)\n",
      "Epoch:767| Average Epoch loss:-0.15378349775438515668| Ndiff loss:-49.9827448430|Sparsity loss:49.8289613452 \n",
      "tensor(-5.0163)\n",
      "tensor(78.4015)\n",
      "Epoch:768| Average Epoch loss:-0.15380872018125538170| Ndiff loss:-49.9827701651|Sparsity loss:49.8289614449 \n",
      "tensor(-5.0163)\n",
      "tensor(78.4226)\n",
      "Epoch:769| Average Epoch loss:-0.15383395421261999991| Ndiff loss:-49.9827954923|Sparsity loss:49.8289615381 \n",
      "tensor(-5.0163)\n",
      "tensor(78.4446)\n",
      "Epoch:770| Average Epoch loss:-0.15385915207606024047| Ndiff loss:-49.9828208532|Sparsity loss:49.8289617012 \n",
      "tensor(-5.0163)\n",
      "tensor(78.4668)\n",
      "Epoch:771| Average Epoch loss:-0.15388442551686568049| Ndiff loss:-49.9828462975|Sparsity loss:49.8289618720 \n",
      "tensor(-5.0163)\n",
      "tensor(78.4851)\n",
      "Epoch:772| Average Epoch loss:-0.15390966303671879678| Ndiff loss:-49.9828717296|Sparsity loss:49.8289620666 \n",
      "tensor(-5.0163)\n",
      "tensor(78.5035)\n",
      "Epoch:773| Average Epoch loss:-0.15393472856009970950| Ndiff loss:-49.9828966857|Sparsity loss:49.8289619571 \n",
      "tensor(-5.0163)\n",
      "tensor(78.5271)\n",
      "Epoch:774| Average Epoch loss:-0.15395942654229383129| Ndiff loss:-49.9829216129|Sparsity loss:49.8289621864 \n",
      "tensor(-5.0163)\n",
      "tensor(78.5480)\n",
      "Epoch:775| Average Epoch loss:-0.15398491737108738198| Ndiff loss:-49.9829471073|Sparsity loss:49.8289621899 \n",
      "tensor(-5.0163)\n",
      "tensor(78.5730)\n",
      "Epoch:776| Average Epoch loss:-0.15400978543414073352| Ndiff loss:-49.9829723092|Sparsity loss:49.8289625238 \n",
      "tensor(-5.0163)\n",
      "tensor(78.5906)\n",
      "Epoch:777| Average Epoch loss:-0.15403402985180314477| Ndiff loss:-49.9829964156|Sparsity loss:49.8289623858 \n",
      "tensor(-5.0163)\n",
      "tensor(78.6133)\n",
      "Epoch:778| Average Epoch loss:-0.15405890784551859451| Ndiff loss:-49.9830215597|Sparsity loss:49.8289626519 \n",
      "tensor(-5.0163)\n",
      "tensor(78.6342)\n",
      "Epoch:779| Average Epoch loss:-0.15408365874901461257| Ndiff loss:-49.9830463703|Sparsity loss:49.8289627116 \n",
      "tensor(-5.0163)\n",
      "tensor(78.6539)\n",
      "Epoch:780| Average Epoch loss:-0.15410823319213187710| Ndiff loss:-49.9830708931|Sparsity loss:49.8289626599 \n",
      "tensor(-5.0163)\n",
      "tensor(78.6785)\n",
      "Epoch:781| Average Epoch loss:-0.15413269277897967413| Ndiff loss:-49.9830956605|Sparsity loss:49.8289629677 \n",
      "tensor(-5.0163)\n",
      "tensor(78.6975)\n",
      "Epoch:782| Average Epoch loss:-0.15415701197242270837| Ndiff loss:-49.9831199732|Sparsity loss:49.8289629612 \n",
      "tensor(-5.0163)\n",
      "tensor(78.7207)\n",
      "Epoch:783| Average Epoch loss:-0.15418129003243308262| Ndiff loss:-49.9831445381|Sparsity loss:49.8289632481 \n",
      "tensor(-5.0163)\n",
      "tensor(78.7370)\n",
      "Epoch:784| Average Epoch loss:-0.15420617597779401331| Ndiff loss:-49.9831693528|Sparsity loss:49.8289631769 \n",
      "tensor(-5.0163)\n",
      "tensor(78.7605)\n",
      "Epoch:785| Average Epoch loss:-0.15423003314839198175| Ndiff loss:-49.9831933425|Sparsity loss:49.8289633094 \n",
      "tensor(-5.0163)\n",
      "tensor(78.7815)\n",
      "Epoch:786| Average Epoch loss:-0.15425402430309592683| Ndiff loss:-49.9832175993|Sparsity loss:49.8289635749 \n",
      "tensor(-5.0163)\n",
      "tensor(78.7988)\n",
      "Epoch:787| Average Epoch loss:-0.15427823088320616329| Ndiff loss:-49.9832417508|Sparsity loss:49.8289635199 \n",
      "tensor(-5.0163)\n",
      "tensor(78.8203)\n",
      "Epoch:788| Average Epoch loss:-0.15430239475792836834| Ndiff loss:-49.9832660249|Sparsity loss:49.8289636302 \n",
      "tensor(-5.0163)\n",
      "tensor(78.8420)\n",
      "Epoch:789| Average Epoch loss:-0.15432614553875051433| Ndiff loss:-49.9832899188|Sparsity loss:49.8289637732 \n",
      "tensor(-5.0163)\n",
      "tensor(78.8637)\n",
      "Epoch:790| Average Epoch loss:-0.15435023094269773036| Ndiff loss:-49.9833141117|Sparsity loss:49.8289638808 \n",
      "tensor(-5.0163)\n",
      "tensor(78.8834)\n",
      "Epoch:791| Average Epoch loss:-0.15437401639714051771| Ndiff loss:-49.9833379524|Sparsity loss:49.8289639360 \n",
      "tensor(-5.0163)\n",
      "tensor(78.9052)\n",
      "Epoch:792| Average Epoch loss:-0.15439798251113501237| Ndiff loss:-49.9833621513|Sparsity loss:49.8289641688 \n",
      "tensor(-5.0163)\n",
      "tensor(78.9246)\n",
      "Epoch:793| Average Epoch loss:-0.15442138045345921160| Ndiff loss:-49.9833855256|Sparsity loss:49.8289641451 \n",
      "tensor(-5.0163)\n",
      "tensor(78.9457)\n",
      "Epoch:794| Average Epoch loss:-0.15444518172670107514| Ndiff loss:-49.9834094606|Sparsity loss:49.8289642789 \n",
      "tensor(-5.0163)\n",
      "tensor(78.9665)\n",
      "Epoch:795| Average Epoch loss:-0.15446894043173742261| Ndiff loss:-49.9834334336|Sparsity loss:49.8289644932 \n",
      "tensor(-5.0163)\n",
      "tensor(78.9861)\n",
      "Epoch:796| Average Epoch loss:-0.15449242760505577099| Ndiff loss:-49.9834568781|Sparsity loss:49.8289644505 \n",
      "tensor(-5.0163)\n",
      "tensor(79.0085)\n",
      "Epoch:797| Average Epoch loss:-0.15451589154473704957| Ndiff loss:-49.9834805361|Sparsity loss:49.8289646446 \n",
      "tensor(-5.0163)\n",
      "tensor(79.0276)\n",
      "Epoch:798| Average Epoch loss:-0.15453913874853794641| Ndiff loss:-49.9835038243|Sparsity loss:49.8289646856 \n",
      "tensor(-5.0163)\n",
      "tensor(79.0496)\n",
      "Epoch:799| Average Epoch loss:-0.15456267733547335297| Ndiff loss:-49.9835274770|Sparsity loss:49.8289647997 \n",
      "tensor(-5.0163)\n",
      "tensor(79.0691)\n",
      "Epoch:800| Average Epoch loss:-0.15458604034586306830| Ndiff loss:-49.9835510530|Sparsity loss:49.8289650127 \n",
      "tensor(-5.0163)\n",
      "tensor(79.0872)\n",
      "Epoch:801| Average Epoch loss:-0.15460928127806639054| Ndiff loss:-49.9835742383|Sparsity loss:49.8289649570 \n",
      "tensor(-5.0163)\n",
      "tensor(79.1089)\n",
      "Epoch:802| Average Epoch loss:-0.15463207322505212460| Ndiff loss:-49.9835973047|Sparsity loss:49.8289652315 \n",
      "tensor(-5.0163)\n",
      "tensor(79.1261)\n",
      "Epoch:803| Average Epoch loss:-0.15465549763341396305| Ndiff loss:-49.9836206700|Sparsity loss:49.8289651724 \n",
      "tensor(-5.0163)\n",
      "tensor(79.1477)\n",
      "Epoch:804| Average Epoch loss:-0.15467841013472297118| Ndiff loss:-49.9836436380|Sparsity loss:49.8289652278 \n",
      "tensor(-5.0163)\n",
      "tensor(79.1705)\n",
      "Epoch:805| Average Epoch loss:-0.15470132476215742168| Ndiff loss:-49.9836668254|Sparsity loss:49.8289655006 \n",
      "tensor(-5.0163)\n",
      "tensor(79.1893)\n",
      "Epoch:806| Average Epoch loss:-0.15472435648279908582| Ndiff loss:-49.9836898673|Sparsity loss:49.8289655108 \n",
      "tensor(-5.0163)\n",
      "tensor(79.2077)\n",
      "Epoch:807| Average Epoch loss:-0.15474748908744551112| Ndiff loss:-49.9837131239|Sparsity loss:49.8289656348 \n",
      "tensor(-5.0163)\n",
      "tensor(79.2294)\n",
      "Epoch:808| Average Epoch loss:-0.15477006003337834272| Ndiff loss:-49.9837356611|Sparsity loss:49.8289656010 \n",
      "tensor(-5.0163)\n",
      "tensor(79.2531)\n",
      "Epoch:809| Average Epoch loss:-0.15479230960666415240| Ndiff loss:-49.9837583309|Sparsity loss:49.8289660213 \n",
      "tensor(-5.0163)\n",
      "tensor(79.2663)\n",
      "Epoch:810| Average Epoch loss:-0.15481566430381910049| Ndiff loss:-49.9837815268|Sparsity loss:49.8289658625 \n",
      "tensor(-5.0163)\n",
      "tensor(79.2870)\n",
      "Epoch:811| Average Epoch loss:-0.15483823963004578195| Ndiff loss:-49.9838042952|Sparsity loss:49.8289660556 \n",
      "tensor(-5.0163)\n",
      "tensor(79.3091)\n",
      "Epoch:812| Average Epoch loss:-0.15486067820589768940| Ndiff loss:-49.9838268180|Sparsity loss:49.8289661398 \n",
      "tensor(-5.0163)\n",
      "tensor(79.3276)\n",
      "Epoch:813| Average Epoch loss:-0.15488311843103494403| Ndiff loss:-49.9838492963|Sparsity loss:49.8289661778 \n",
      "tensor(-5.0163)\n",
      "tensor(79.3498)\n",
      "Epoch:814| Average Epoch loss:-0.15490591396780495348| Ndiff loss:-49.9838722875|Sparsity loss:49.8289663736 \n",
      "tensor(-5.0163)\n",
      "tensor(79.3673)\n",
      "Epoch:815| Average Epoch loss:-0.15492756678265706682| Ndiff loss:-49.9838940201|Sparsity loss:49.8289664533 \n",
      "tensor(-5.0163)\n",
      "tensor(79.3877)\n",
      "Epoch:816| Average Epoch loss:-0.15495035289037695225| Ndiff loss:-49.9839168573|Sparsity loss:49.8289665044 \n",
      "tensor(-5.0163)\n",
      "tensor(79.4091)\n",
      "Epoch:817| Average Epoch loss:-0.15497274199248542437| Ndiff loss:-49.9839394548|Sparsity loss:49.8289667128 \n",
      "tensor(-5.0163)\n",
      "tensor(79.4267)\n",
      "Epoch:818| Average Epoch loss:-0.15499471204852355299| Ndiff loss:-49.9839613775|Sparsity loss:49.8289666655 \n",
      "tensor(-5.0163)\n",
      "tensor(79.4473)\n",
      "Epoch:819| Average Epoch loss:-0.15501700390930395201| Ndiff loss:-49.9839839286|Sparsity loss:49.8289669247 \n",
      "tensor(-5.0163)\n",
      "tensor(79.4657)\n",
      "Epoch:820| Average Epoch loss:-0.15503967893616238394| Ndiff loss:-49.9840064620|Sparsity loss:49.8289667831 \n",
      "tensor(-5.0163)\n",
      "tensor(79.4865)\n",
      "Epoch:821| Average Epoch loss:-0.15506139611426267289| Ndiff loss:-49.9840284482|Sparsity loss:49.8289670521 \n",
      "tensor(-5.0163)\n",
      "tensor(79.5068)\n",
      "Epoch:822| Average Epoch loss:-0.15508341992904048356| Ndiff loss:-49.9840505898|Sparsity loss:49.8289671699 \n",
      "tensor(-5.0163)\n",
      "tensor(79.5247)\n",
      "Epoch:823| Average Epoch loss:-0.15510546214735004833| Ndiff loss:-49.9840727148|Sparsity loss:49.8289672526 \n",
      "tensor(-5.0163)\n",
      "tensor(79.5432)\n",
      "Epoch:824| Average Epoch loss:-0.15512718249820878214| Ndiff loss:-49.9840944862|Sparsity loss:49.8289673037 \n",
      "tensor(-5.0163)\n",
      "tensor(79.5638)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:825| Average Epoch loss:-0.15514895851003471239| Ndiff loss:-49.9841163506|Sparsity loss:49.8289673921 \n",
      "tensor(-5.0163)\n",
      "tensor(79.5842)\n",
      "Epoch:826| Average Epoch loss:-0.15517062445383761338| Ndiff loss:-49.9841381699|Sparsity loss:49.8289675454 \n",
      "tensor(-5.0163)\n",
      "tensor(79.6011)\n",
      "Epoch:827| Average Epoch loss:-0.15519309494274974304| Ndiff loss:-49.9841605785|Sparsity loss:49.8289674836 \n",
      "tensor(-5.0163)\n",
      "tensor(79.6240)\n",
      "Epoch:828| Average Epoch loss:-0.15521411118122646622| Ndiff loss:-49.9841819263|Sparsity loss:49.8289678151 \n",
      "tensor(-5.0163)\n",
      "tensor(79.6421)\n",
      "Epoch:829| Average Epoch loss:-0.15523553854740790303| Ndiff loss:-49.9842032082|Sparsity loss:49.8289676697 \n",
      "tensor(-5.0163)\n",
      "tensor(79.6631)\n",
      "Epoch:830| Average Epoch loss:-0.15525785892561849710| Ndiff loss:-49.9842257616|Sparsity loss:49.8289679027 \n",
      "tensor(-5.0163)\n",
      "tensor(79.6824)\n",
      "Epoch:831| Average Epoch loss:-0.15527888255036298437| Ndiff loss:-49.9842468947|Sparsity loss:49.8289680121 \n",
      "tensor(-5.0163)\n",
      "tensor(79.6992)\n",
      "Epoch:832| Average Epoch loss:-0.15530026100658034238| Ndiff loss:-49.9842683872|Sparsity loss:49.8289681262 \n",
      "tensor(-5.0163)\n",
      "tensor(79.7202)\n",
      "Epoch:833| Average Epoch loss:-0.15532183320699743945| Ndiff loss:-49.9842899256|Sparsity loss:49.8289680924 \n",
      "tensor(-5.0163)\n",
      "tensor(79.7417)\n",
      "Epoch:834| Average Epoch loss:-0.15534282875235858046| Ndiff loss:-49.9843110701|Sparsity loss:49.8289682414 \n",
      "tensor(-5.0163)\n",
      "tensor(79.7620)\n",
      "Epoch:835| Average Epoch loss:-0.15536414699774347969| Ndiff loss:-49.9843324891|Sparsity loss:49.8289683421 \n",
      "tensor(-5.0163)\n",
      "tensor(79.7812)\n",
      "Epoch:836| Average Epoch loss:-0.15538546232113820134| Ndiff loss:-49.9843539603|Sparsity loss:49.8289684980 \n",
      "tensor(-5.0163)\n",
      "tensor(79.7985)\n",
      "Epoch:837| Average Epoch loss:-0.15540669119134914444| Ndiff loss:-49.9843751888|Sparsity loss:49.8289684976 \n",
      "tensor(-5.0163)\n",
      "tensor(79.8197)\n",
      "Epoch:838| Average Epoch loss:-0.15542777382039929535| Ndiff loss:-49.9843964725|Sparsity loss:49.8289686987 \n",
      "tensor(-5.0163)\n",
      "tensor(79.8370)\n",
      "Epoch:839| Average Epoch loss:-0.15544877689045538682| Ndiff loss:-49.9844173949|Sparsity loss:49.8289686180 \n",
      "tensor(-5.0163)\n",
      "tensor(79.8584)\n",
      "Epoch:840| Average Epoch loss:-0.15547022045682210023| Ndiff loss:-49.9844390125|Sparsity loss:49.8289687921 \n",
      "tensor(-5.0163)\n",
      "tensor(79.8774)\n",
      "Epoch:841| Average Epoch loss:-0.15549083555699677595| Ndiff loss:-49.9844597705|Sparsity loss:49.8289689350 \n",
      "tensor(-5.0163)\n",
      "tensor(79.8950)\n",
      "Epoch:842| Average Epoch loss:-0.15551214546573255415| Ndiff loss:-49.9844811646|Sparsity loss:49.8289690191 \n",
      "tensor(-5.0163)\n",
      "tensor(79.9131)\n",
      "Epoch:843| Average Epoch loss:-0.15553276669756341266| Ndiff loss:-49.9845018424|Sparsity loss:49.8289690757 \n",
      "tensor(-5.0163)\n",
      "tensor(79.9334)\n",
      "Epoch:844| Average Epoch loss:-0.15555352456084195478| Ndiff loss:-49.9845227963|Sparsity loss:49.8289692718 \n",
      "tensor(-5.0163)\n",
      "tensor(79.9499)\n",
      "Epoch:845| Average Epoch loss:-0.15557474102645979519| Ndiff loss:-49.9845440057|Sparsity loss:49.8289692647 \n",
      "tensor(-5.0163)\n",
      "tensor(79.9695)\n",
      "Epoch:846| Average Epoch loss:-0.15559514000551644131| Ndiff loss:-49.9845646116|Sparsity loss:49.8289694716 \n",
      "tensor(-5.0163)\n",
      "tensor(79.9870)\n",
      "Epoch:847| Average Epoch loss:-0.15561592848552330270| Ndiff loss:-49.9845853602|Sparsity loss:49.8289694317 \n",
      "tensor(-5.0163)\n",
      "tensor(80.0076)\n",
      "Epoch:848| Average Epoch loss:-0.15563640474456935658| Ndiff loss:-49.9846059305|Sparsity loss:49.8289695258 \n",
      "tensor(-5.0163)\n",
      "tensor(80.0279)\n",
      "Epoch:849| Average Epoch loss:-0.15565702112300844329| Ndiff loss:-49.9846266996|Sparsity loss:49.8289696784 \n",
      "tensor(-5.0163)\n",
      "tensor(80.0462)\n",
      "Epoch:850| Average Epoch loss:-0.15567734604345220828| Ndiff loss:-49.9846471137|Sparsity loss:49.8289697676 \n",
      "tensor(-5.0163)\n",
      "tensor(80.0652)\n",
      "Epoch:851| Average Epoch loss:-0.15569787878246227342| Ndiff loss:-49.9846677039|Sparsity loss:49.8289698251 \n",
      "tensor(-5.0163)\n",
      "tensor(80.0841)\n",
      "Epoch:852| Average Epoch loss:-0.15571814387591390028| Ndiff loss:-49.9846879518|Sparsity loss:49.8289698079 \n",
      "tensor(-5.0163)\n",
      "tensor(80.1048)\n",
      "Epoch:853| Average Epoch loss:-0.15573796841228848553| Ndiff loss:-49.9847081295|Sparsity loss:49.8289701611 \n",
      "tensor(-5.0163)\n",
      "tensor(80.1197)\n",
      "Epoch:854| Average Epoch loss:-0.15575899699425438394| Ndiff loss:-49.9847290514|Sparsity loss:49.8289700544 \n",
      "tensor(-5.0163)\n",
      "tensor(80.1411)\n",
      "Epoch:855| Average Epoch loss:-0.15577939785886918411| Ndiff loss:-49.9847496050|Sparsity loss:49.8289702071 \n",
      "tensor(-5.0163)\n",
      "tensor(80.1590)\n",
      "Epoch:856| Average Epoch loss:-0.15579964787631675471| Ndiff loss:-49.9847699685|Sparsity loss:49.8289703207 \n",
      "tensor(-5.0163)\n",
      "tensor(80.1760)\n",
      "Epoch:857| Average Epoch loss:-0.15581951829232762452| Ndiff loss:-49.9847898192|Sparsity loss:49.8289703009 \n",
      "tensor(-5.0163)\n",
      "tensor(80.1977)\n",
      "Epoch:858| Average Epoch loss:-0.15583980676678954591| Ndiff loss:-49.9848101861|Sparsity loss:49.8289703793 \n",
      "tensor(-5.0163)\n",
      "tensor(80.2179)\n",
      "Epoch:859| Average Epoch loss:-0.15585976688879041308| Ndiff loss:-49.9848303270|Sparsity loss:49.8289705601 \n",
      "tensor(-5.0163)\n",
      "tensor(80.2361)\n",
      "Epoch:860| Average Epoch loss:-0.15587965572894940669| Ndiff loss:-49.9848502349|Sparsity loss:49.8289705792 \n",
      "tensor(-5.0163)\n",
      "tensor(80.2567)\n",
      "Epoch:861| Average Epoch loss:-0.15589940494340875921| Ndiff loss:-49.9848702812|Sparsity loss:49.8289708762 \n",
      "tensor(-5.0163)\n",
      "tensor(80.2714)\n",
      "Epoch:862| Average Epoch loss:-0.15591910904172578967| Ndiff loss:-49.9848899452|Sparsity loss:49.8289708361 \n",
      "tensor(-5.0163)\n",
      "tensor(80.2917)\n",
      "Epoch:863| Average Epoch loss:-0.15593925476117101447| Ndiff loss:-49.9849101469|Sparsity loss:49.8289708922 \n",
      "tensor(-5.0163)\n",
      "tensor(80.3122)\n",
      "Epoch:864| Average Epoch loss:-0.15595909774301081052| Ndiff loss:-49.9849301127|Sparsity loss:49.8289710149 \n",
      "tensor(-5.0163)\n",
      "tensor(80.3295)\n",
      "Epoch:865| Average Epoch loss:-0.15597920757627845023| Ndiff loss:-49.9849502382|Sparsity loss:49.8289710306 \n",
      "tensor(-5.0163)\n",
      "tensor(80.3489)\n",
      "Epoch:866| Average Epoch loss:-0.15599881253296427053| Ndiff loss:-49.9849700418|Sparsity loss:49.8289712292 \n",
      "tensor(-5.0163)\n",
      "tensor(80.3652)\n",
      "Epoch:867| Average Epoch loss:-0.15601841608796718219| Ndiff loss:-49.9849896515|Sparsity loss:49.8289712354 \n",
      "tensor(-5.0163)\n",
      "tensor(80.3841)\n",
      "Epoch:868| Average Epoch loss:-0.15603801788160687192| Ndiff loss:-49.9850092766|Sparsity loss:49.8289712587 \n",
      "tensor(-5.0163)\n",
      "tensor(80.4039)\n",
      "Epoch:869| Average Epoch loss:-0.15605761973015930266| Ndiff loss:-49.9850290722|Sparsity loss:49.8289714524 \n",
      "tensor(-5.0163)\n",
      "tensor(80.4217)\n",
      "Epoch:870| Average Epoch loss:-0.15607727288763978413| Ndiff loss:-49.9850488041|Sparsity loss:49.8289715312 \n",
      "tensor(-5.0163)\n",
      "tensor(80.4379)\n",
      "Epoch:871| Average Epoch loss:-0.15609660346187739788| Ndiff loss:-49.9850681074|Sparsity loss:49.8289715040 \n",
      "tensor(-5.0163)\n",
      "tensor(80.4586)\n",
      "Epoch:872| Average Epoch loss:-0.15611595934031699540| Ndiff loss:-49.9850876151|Sparsity loss:49.8289716558 \n",
      "tensor(-5.0163)\n",
      "tensor(80.4779)\n",
      "Epoch:873| Average Epoch loss:-0.15613544206066462539| Ndiff loss:-49.9851072804|Sparsity loss:49.8289718384 \n",
      "tensor(-5.0163)\n",
      "tensor(80.4940)\n",
      "Epoch:874| Average Epoch loss:-0.15615458940509321928| Ndiff loss:-49.9851264291|Sparsity loss:49.8289718397 \n",
      "tensor(-5.0163)\n",
      "tensor(80.5132)\n",
      "Epoch:875| Average Epoch loss:-0.15617381803988944489| Ndiff loss:-49.9851457352|Sparsity loss:49.8289719172 \n",
      "tensor(-5.0163)\n",
      "tensor(80.5307)\n",
      "Epoch:876| Average Epoch loss:-0.15619316927970908204| Ndiff loss:-49.9851652319|Sparsity loss:49.8289720627 \n",
      "tensor(-5.0163)\n",
      "tensor(80.5474)\n",
      "Epoch:877| Average Epoch loss:-0.15621241741754271493| Ndiff loss:-49.9851844931|Sparsity loss:49.8289720757 \n",
      "tensor(-5.0163)\n",
      "tensor(80.5666)\n",
      "Epoch:878| Average Epoch loss:-0.15623166931734169816| Ndiff loss:-49.9852038775|Sparsity loss:49.8289722082 \n",
      "tensor(-5.0163)\n",
      "tensor(80.5860)\n",
      "Epoch:879| Average Epoch loss:-0.15625086641645757890| Ndiff loss:-49.9852230772|Sparsity loss:49.8289722108 \n",
      "tensor(-5.0163)\n",
      "tensor(80.6058)\n",
      "Epoch:880| Average Epoch loss:-0.15626989836635254982| Ndiff loss:-49.9852422259|Sparsity loss:49.8289723275 \n",
      "tensor(-5.0163)\n",
      "tensor(80.6234)\n",
      "Epoch:881| Average Epoch loss:-0.15628892961742993362| Ndiff loss:-49.9852614303|Sparsity loss:49.8289725007 \n",
      "tensor(-5.0163)\n",
      "tensor(80.6404)\n",
      "Epoch:882| Average Epoch loss:-0.15630818866562673497| Ndiff loss:-49.9852806121|Sparsity loss:49.8289724234 \n",
      "tensor(-5.0163)\n",
      "tensor(80.6603)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:883| Average Epoch loss:-0.15632681904424849950| Ndiff loss:-49.9852995655|Sparsity loss:49.8289727465 \n",
      "tensor(-5.0163)\n",
      "tensor(80.6754)\n",
      "Epoch:884| Average Epoch loss:-0.15634575277658216419| Ndiff loss:-49.9853184098|Sparsity loss:49.8289726570 \n",
      "tensor(-5.0163)\n",
      "tensor(80.6953)\n",
      "Epoch:885| Average Epoch loss:-0.15636458648535978000| Ndiff loss:-49.9853373366|Sparsity loss:49.8289727501 \n",
      "tensor(-5.0163)\n",
      "tensor(80.7135)\n",
      "Epoch:886| Average Epoch loss:-0.15638326290946402697| Ndiff loss:-49.9853561290|Sparsity loss:49.8289728661 \n",
      "tensor(-5.0163)\n",
      "tensor(80.7311)\n",
      "Epoch:887| Average Epoch loss:-0.15640205420787564594| Ndiff loss:-49.9853750123|Sparsity loss:49.8289729581 \n",
      "tensor(-5.0163)\n",
      "tensor(80.7496)\n",
      "Epoch:888| Average Epoch loss:-0.15642064028176369539| Ndiff loss:-49.9853936250|Sparsity loss:49.8289729847 \n",
      "tensor(-5.0163)\n",
      "tensor(80.7663)\n",
      "Epoch:889| Average Epoch loss:-0.15643947352989961974| Ndiff loss:-49.9854125838|Sparsity loss:49.8289731102 \n",
      "tensor(-5.0163)\n",
      "tensor(80.7857)\n",
      "Epoch:890| Average Epoch loss:-0.15645787754799775349| Ndiff loss:-49.9854309752|Sparsity loss:49.8289730977 \n",
      "tensor(-5.0163)\n",
      "tensor(80.8054)\n",
      "Epoch:891| Average Epoch loss:-0.15647644516056719022| Ndiff loss:-49.9854498647|Sparsity loss:49.8289734196 \n",
      "tensor(-5.0163)\n",
      "tensor(80.8190)\n",
      "Epoch:892| Average Epoch loss:-0.15649478467767133361| Ndiff loss:-49.9854680940|Sparsity loss:49.8289733093 \n",
      "tensor(-5.0163)\n",
      "tensor(80.8376)\n",
      "Epoch:893| Average Epoch loss:-0.15651339542405218186| Ndiff loss:-49.9854867380|Sparsity loss:49.8289733425 \n",
      "tensor(-5.0163)\n",
      "tensor(80.8583)\n",
      "Epoch:894| Average Epoch loss:-0.15653196704228300451| Ndiff loss:-49.9855054831|Sparsity loss:49.8289735161 \n",
      "tensor(-5.0163)\n",
      "tensor(80.8765)\n",
      "Epoch:895| Average Epoch loss:-0.15655020616604689576| Ndiff loss:-49.9855237552|Sparsity loss:49.8289735491 \n",
      "tensor(-5.0163)\n",
      "tensor(80.8941)\n",
      "Epoch:896| Average Epoch loss:-0.15656862407829347239| Ndiff loss:-49.9855422668|Sparsity loss:49.8289736427 \n",
      "tensor(-5.0163)\n",
      "tensor(80.9136)\n",
      "Epoch:897| Average Epoch loss:-0.15658687919688990542| Ndiff loss:-49.9855606536|Sparsity loss:49.8289737744 \n",
      "tensor(-5.0163)\n",
      "tensor(80.9290)\n",
      "Epoch:898| Average Epoch loss:-0.15660542355718279350| Ndiff loss:-49.9855793144|Sparsity loss:49.8289738908 \n",
      "tensor(-5.0163)\n",
      "tensor(80.9452)\n",
      "Epoch:899| Average Epoch loss:-0.15662362793005574213| Ndiff loss:-49.9855975304|Sparsity loss:49.8289739025 \n",
      "tensor(-5.0163)\n",
      "tensor(80.9627)\n",
      "Epoch:900| Average Epoch loss:-0.15664144448890798822| Ndiff loss:-49.9856153876|Sparsity loss:49.8289739431 \n",
      "tensor(-5.0163)\n",
      "tensor(80.9834)\n",
      "Epoch:901| Average Epoch loss:-0.15665963723355127990| Ndiff loss:-49.9856337314|Sparsity loss:49.8289740942 \n",
      "tensor(-5.0163)\n",
      "tensor(80.9991)\n",
      "Epoch:902| Average Epoch loss:-0.15667784957677277635| Ndiff loss:-49.9856519925|Sparsity loss:49.8289741430 \n",
      "tensor(-5.0163)\n",
      "tensor(81.0171)\n",
      "Epoch:903| Average Epoch loss:-0.15669579245840933868| Ndiff loss:-49.9856701010|Sparsity loss:49.8289743085 \n",
      "tensor(-5.0163)\n",
      "tensor(81.0322)\n",
      "Epoch:904| Average Epoch loss:-0.15671372197843544405| Ndiff loss:-49.9856879525|Sparsity loss:49.8289742305 \n",
      "tensor(-5.0163)\n",
      "tensor(81.0520)\n",
      "Epoch:905| Average Epoch loss:-0.15673175112705056700| Ndiff loss:-49.9857061258|Sparsity loss:49.8289743746 \n",
      "tensor(-5.0163)\n",
      "tensor(81.0708)\n",
      "Epoch:906| Average Epoch loss:-0.15675007946474098230| Ndiff loss:-49.9857246122|Sparsity loss:49.8289745328 \n",
      "tensor(-5.0163)\n",
      "tensor(81.0874)\n",
      "Epoch:907| Average Epoch loss:-0.15676769735675538664| Ndiff loss:-49.9857422174|Sparsity loss:49.8289745201 \n",
      "tensor(-5.0163)\n",
      "tensor(81.1056)\n",
      "Epoch:908| Average Epoch loss:-0.15678560366998833819| Ndiff loss:-49.9857601752|Sparsity loss:49.8289745716 \n",
      "tensor(-5.0163)\n",
      "tensor(81.1248)\n",
      "Epoch:909| Average Epoch loss:-0.15680313204782139747| Ndiff loss:-49.9857779040|Sparsity loss:49.8289747720 \n",
      "tensor(-5.0163)\n",
      "tensor(81.1397)\n",
      "Epoch:910| Average Epoch loss:-0.15682118413085691100| Ndiff loss:-49.9857958578|Sparsity loss:49.8289746737 \n",
      "tensor(-5.0163)\n",
      "tensor(81.1611)\n",
      "Epoch:911| Average Epoch loss:-0.15683897361925738800| Ndiff loss:-49.9858139178|Sparsity loss:49.8289749442 \n",
      "tensor(-5.0163)\n",
      "tensor(81.1775)\n",
      "Epoch:912| Average Epoch loss:-0.15685646562497268519| Ndiff loss:-49.9858313734|Sparsity loss:49.8289749078 \n",
      "tensor(-5.0163)\n",
      "tensor(81.1953)\n",
      "Epoch:913| Average Epoch loss:-0.15687421656286795746| Ndiff loss:-49.9858491939|Sparsity loss:49.8289749774 \n",
      "tensor(-5.0163)\n",
      "tensor(81.2140)\n",
      "Epoch:914| Average Epoch loss:-0.15689184065305677995| Ndiff loss:-49.9858669699|Sparsity loss:49.8289751293 \n",
      "tensor(-5.0163)\n",
      "tensor(81.2295)\n",
      "Epoch:915| Average Epoch loss:-0.15690903036859576991| Ndiff loss:-49.9858841349|Sparsity loss:49.8289751046 \n",
      "tensor(-5.0163)\n",
      "tensor(81.2499)\n",
      "Epoch:916| Average Epoch loss:-0.15692632545351592466| Ndiff loss:-49.9859016203|Sparsity loss:49.8289752949 \n",
      "tensor(-5.0163)\n",
      "tensor(81.2669)\n",
      "Epoch:917| Average Epoch loss:-0.15694422483010189717| Ndiff loss:-49.9859195539|Sparsity loss:49.8289753291 \n",
      "tensor(-5.0163)\n",
      "tensor(81.2836)\n",
      "Epoch:918| Average Epoch loss:-0.15696157749211930854| Ndiff loss:-49.9859370765|Sparsity loss:49.8289754990 \n",
      "tensor(-5.0163)\n",
      "tensor(81.2980)\n",
      "Epoch:919| Average Epoch loss:-0.15697894970765424727| Ndiff loss:-49.9859543788|Sparsity loss:49.8289754291 \n",
      "tensor(-5.0163)\n",
      "tensor(81.3184)\n",
      "Epoch:920| Average Epoch loss:-0.15699631179398604308| Ndiff loss:-49.9859718044|Sparsity loss:49.8289754926 \n",
      "tensor(-5.0163)\n",
      "tensor(81.3367)\n",
      "Epoch:921| Average Epoch loss:-0.15701365331674643766| Ndiff loss:-49.9859893201|Sparsity loss:49.8289756668 \n",
      "tensor(-5.0163)\n",
      "tensor(81.3533)\n",
      "Epoch:922| Average Epoch loss:-0.15703101678100375715| Ndiff loss:-49.9860067324|Sparsity loss:49.8289757156 \n",
      "tensor(-5.0163)\n",
      "tensor(81.3696)\n",
      "Epoch:923| Average Epoch loss:-0.15704819487457180593| Ndiff loss:-49.9860239276|Sparsity loss:49.8289757327 \n",
      "tensor(-5.0163)\n",
      "tensor(81.3890)\n",
      "Epoch:924| Average Epoch loss:-0.15706553500978634452| Ndiff loss:-49.9860414296|Sparsity loss:49.8289758946 \n",
      "tensor(-5.0163)\n",
      "tensor(81.4059)\n",
      "Epoch:925| Average Epoch loss:-0.15708243185303968903| Ndiff loss:-49.9860583489|Sparsity loss:49.8289759170 \n",
      "tensor(-5.0163)\n",
      "tensor(81.4221)\n",
      "Epoch:926| Average Epoch loss:-0.15709940213665005149| Ndiff loss:-49.9860754221|Sparsity loss:49.8289760200 \n",
      "tensor(-5.0163)\n",
      "tensor(81.4393)\n",
      "Epoch:927| Average Epoch loss:-0.15711672379747673722| Ndiff loss:-49.9860927751|Sparsity loss:49.8289760513 \n",
      "tensor(-5.0163)\n",
      "tensor(81.4568)\n",
      "Epoch:928| Average Epoch loss:-0.15713363561371687660| Ndiff loss:-49.9861098282|Sparsity loss:49.8289761926 \n",
      "tensor(-5.0163)\n",
      "tensor(81.4721)\n",
      "Epoch:929| Average Epoch loss:-0.15715078057867554184| Ndiff loss:-49.9861270330|Sparsity loss:49.8289762524 \n",
      "tensor(-5.0163)\n",
      "tensor(81.4904)\n",
      "Epoch:930| Average Epoch loss:-0.15716798198503509343| Ndiff loss:-49.9861442633|Sparsity loss:49.8289762813 \n",
      "tensor(-5.0163)\n",
      "tensor(81.5092)\n",
      "Epoch:931| Average Epoch loss:-0.15718456368306535365| Ndiff loss:-49.9861608974|Sparsity loss:49.8289763338 \n",
      "tensor(-5.0163)\n",
      "tensor(81.5258)\n",
      "Epoch:932| Average Epoch loss:-0.15720152124839811836| Ndiff loss:-49.9861780783|Sparsity loss:49.8289765571 \n",
      "tensor(-5.0163)\n",
      "tensor(81.5399)\n",
      "Epoch:933| Average Epoch loss:-0.15721835294955452400| Ndiff loss:-49.9861948159|Sparsity loss:49.8289764630 \n",
      "tensor(-5.0163)\n",
      "tensor(81.5596)\n",
      "Epoch:934| Average Epoch loss:-0.15723526548344324283| Ndiff loss:-49.9862118476|Sparsity loss:49.8289765822 \n",
      "tensor(-5.0163)\n",
      "tensor(81.5773)\n",
      "Epoch:935| Average Epoch loss:-0.15725202729864465323| Ndiff loss:-49.9862287666|Sparsity loss:49.8289767393 \n",
      "tensor(-5.0163)\n",
      "tensor(81.5929)\n",
      "Epoch:936| Average Epoch loss:-0.15726888708092603975| Ndiff loss:-49.9862456032|Sparsity loss:49.8289767161 \n",
      "tensor(-5.0163)\n",
      "tensor(81.6105)\n",
      "Epoch:937| Average Epoch loss:-0.15728533752519405220| Ndiff loss:-49.9862621870|Sparsity loss:49.8289768495 \n",
      "tensor(-5.0163)\n",
      "tensor(81.6271)\n",
      "Epoch:938| Average Epoch loss:-0.15730194515938655808| Ndiff loss:-49.9862788665|Sparsity loss:49.8289769214 \n",
      "tensor(-5.0163)\n",
      "tensor(81.6437)\n",
      "Epoch:939| Average Epoch loss:-0.15731884787415692517| Ndiff loss:-49.9862957857|Sparsity loss:49.8289769378 \n",
      "tensor(-5.0163)\n",
      "tensor(81.6609)\n",
      "Epoch:940| Average Epoch loss:-0.15733518605767848886| Ndiff loss:-49.9863122606|Sparsity loss:49.8289770746 \n",
      "tensor(-5.0163)\n",
      "tensor(81.6780)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:941| Average Epoch loss:-0.15735180668956910699| Ndiff loss:-49.9863288922|Sparsity loss:49.8289770855 \n",
      "tensor(-5.0163)\n",
      "tensor(81.6949)\n",
      "Epoch:942| Average Epoch loss:-0.15736830879677457529| Ndiff loss:-49.9863454516|Sparsity loss:49.8289771428 \n",
      "tensor(-5.0163)\n",
      "tensor(81.7135)\n",
      "Epoch:943| Average Epoch loss:-0.15738471834449027642| Ndiff loss:-49.9863620093|Sparsity loss:49.8289772909 \n",
      "tensor(-5.0163)\n",
      "tensor(81.7292)\n",
      "Epoch:944| Average Epoch loss:-0.15740113443952610806| Ndiff loss:-49.9863784855|Sparsity loss:49.8289773511 \n",
      "tensor(-5.0163)\n",
      "tensor(81.7450)\n",
      "Epoch:945| Average Epoch loss:-0.15741766094094147843| Ndiff loss:-49.9863950100|Sparsity loss:49.8289773491 \n",
      "tensor(-5.0163)\n",
      "tensor(81.7649)\n",
      "Epoch:946| Average Epoch loss:-0.15743406017155259224| Ndiff loss:-49.9864115913|Sparsity loss:49.8289775311 \n",
      "tensor(-5.0163)\n",
      "tensor(81.7800)\n",
      "Epoch:947| Average Epoch loss:-0.15745023425501297742| Ndiff loss:-49.9864278545|Sparsity loss:49.8289776202 \n",
      "tensor(-5.0163)\n",
      "tensor(81.7951)\n",
      "Epoch:948| Average Epoch loss:-0.15746679571963895228| Ndiff loss:-49.9864444391|Sparsity loss:49.8289776433 \n",
      "tensor(-5.0163)\n",
      "tensor(81.8110)\n",
      "Epoch:949| Average Epoch loss:-0.15748289495178646735| Ndiff loss:-49.9864605007|Sparsity loss:49.8289776057 \n",
      "tensor(-5.0163)\n",
      "tensor(81.8306)\n",
      "Epoch:950| Average Epoch loss:-0.15749911444935213445| Ndiff loss:-49.9864768940|Sparsity loss:49.8289777796 \n",
      "tensor(-5.0163)\n",
      "tensor(81.8466)\n",
      "Epoch:951| Average Epoch loss:-0.15751480053458799535| Ndiff loss:-49.9864926965|Sparsity loss:49.8289778960 \n",
      "tensor(-5.0163)\n",
      "tensor(81.8633)\n",
      "Epoch:952| Average Epoch loss:-0.15753130628764544507| Ndiff loss:-49.9865092171|Sparsity loss:49.8289779108 \n",
      "tensor(-5.0163)\n",
      "tensor(81.8794)\n",
      "Epoch:953| Average Epoch loss:-0.15754738575778523546| Ndiff loss:-49.9865253385|Sparsity loss:49.8289779527 \n",
      "tensor(-5.0163)\n",
      "tensor(81.8973)\n",
      "Epoch:954| Average Epoch loss:-0.15756336766549555728| Ndiff loss:-49.9865414045|Sparsity loss:49.8289780369 \n",
      "tensor(-5.0163)\n",
      "tensor(81.9130)\n",
      "Epoch:955| Average Epoch loss:-0.15757947318399109782| Ndiff loss:-49.9865576298|Sparsity loss:49.8289781566 \n",
      "tensor(-5.0163)\n",
      "tensor(81.9293)\n",
      "Epoch:956| Average Epoch loss:-0.15759540513075620538| Ndiff loss:-49.9865736179|Sparsity loss:49.8289782127 \n",
      "tensor(-5.0163)\n",
      "tensor(81.9455)\n",
      "Epoch:957| Average Epoch loss:-0.15761130849200336024| Ndiff loss:-49.9865895214|Sparsity loss:49.8289782129 \n",
      "tensor(-5.0163)\n",
      "tensor(81.9642)\n",
      "Epoch:958| Average Epoch loss:-0.15762743223483136057| Ndiff loss:-49.9866057426|Sparsity loss:49.8289783103 \n",
      "tensor(-5.0163)\n",
      "tensor(81.9813)\n",
      "Epoch:959| Average Epoch loss:-0.15764312933326174448| Ndiff loss:-49.9866215361|Sparsity loss:49.8289784068 \n",
      "tensor(-5.0163)\n",
      "tensor(81.9987)\n",
      "Epoch:960| Average Epoch loss:-0.15765902707248161119| Ndiff loss:-49.9866375312|Sparsity loss:49.8289785041 \n",
      "tensor(-5.0163)\n",
      "tensor(82.0137)\n",
      "Epoch:961| Average Epoch loss:-0.15767519326232065646| Ndiff loss:-49.9866537699|Sparsity loss:49.8289785766 \n",
      "tensor(-5.0163)\n",
      "tensor(82.0298)\n",
      "Epoch:962| Average Epoch loss:-0.15769075839289767305| Ndiff loss:-49.9866693596|Sparsity loss:49.8289786012 \n",
      "tensor(-5.0163)\n",
      "tensor(82.0480)\n",
      "Epoch:963| Average Epoch loss:-0.15770655083407683628| Ndiff loss:-49.9866853076|Sparsity loss:49.8289787568 \n",
      "tensor(-5.0163)\n",
      "tensor(82.0614)\n",
      "Epoch:964| Average Epoch loss:-0.15772224521878147607| Ndiff loss:-49.9867010291|Sparsity loss:49.8289787839 \n",
      "tensor(-5.0163)\n",
      "tensor(82.0784)\n",
      "Epoch:965| Average Epoch loss:-0.15773795405661850122| Ndiff loss:-49.9867167189|Sparsity loss:49.8289787649 \n",
      "tensor(-5.0163)\n",
      "tensor(82.0968)\n",
      "Epoch:966| Average Epoch loss:-0.15775361667807649702| Ndiff loss:-49.9867325591|Sparsity loss:49.8289789424 \n",
      "tensor(-5.0163)\n",
      "tensor(82.1137)\n",
      "Epoch:967| Average Epoch loss:-0.15776898099871061731| Ndiff loss:-49.9867480022|Sparsity loss:49.8289790212 \n",
      "tensor(-5.0163)\n",
      "tensor(82.1285)\n",
      "Epoch:968| Average Epoch loss:-0.15778490637199935054| Ndiff loss:-49.9867638810|Sparsity loss:49.8289789746 \n",
      "tensor(-5.0163)\n",
      "tensor(82.1465)\n",
      "Epoch:969| Average Epoch loss:-0.15780047121397838827| Ndiff loss:-49.9867795359|Sparsity loss:49.8289790647 \n",
      "tensor(-5.0163)\n",
      "tensor(82.1660)\n",
      "Epoch:970| Average Epoch loss:-0.15781563130077222445| Ndiff loss:-49.9867949802|Sparsity loss:49.8289793489 \n",
      "tensor(-5.0163)\n",
      "tensor(82.1774)\n",
      "Epoch:971| Average Epoch loss:-0.15783138730175691467| Ndiff loss:-49.9868105029|Sparsity loss:49.8289791156 \n",
      "tensor(-5.0163)\n",
      "tensor(82.1989)\n",
      "Epoch:972| Average Epoch loss:-0.15784677810407365950| Ndiff loss:-49.9868262264|Sparsity loss:49.8289794483 \n",
      "tensor(-5.0163)\n",
      "tensor(82.2118)\n",
      "Epoch:973| Average Epoch loss:-0.15786214526251127199| Ndiff loss:-49.9868415066|Sparsity loss:49.8289793614 \n",
      "tensor(-5.0163)\n",
      "tensor(82.2288)\n",
      "Epoch:974| Average Epoch loss:-0.15787747251739897569| Ndiff loss:-49.9868568783|Sparsity loss:49.8289794058 \n",
      "tensor(-5.0163)\n",
      "tensor(82.2453)\n",
      "Epoch:975| Average Epoch loss:-0.15789289341964105051| Ndiff loss:-49.9868723875|Sparsity loss:49.8289794941 \n",
      "tensor(-5.0163)\n",
      "tensor(82.2624)\n",
      "Epoch:976| Average Epoch loss:-0.15790812768101028518| Ndiff loss:-49.9868876589|Sparsity loss:49.8289795312 \n",
      "tensor(-5.0163)\n",
      "tensor(82.2788)\n",
      "Epoch:977| Average Epoch loss:-0.15792336959823552456| Ndiff loss:-49.9869031060|Sparsity loss:49.8289797364 \n",
      "tensor(-5.0163)\n",
      "tensor(82.2935)\n",
      "Epoch:978| Average Epoch loss:-0.15793868509970110381| Ndiff loss:-49.9869183240|Sparsity loss:49.8289796389 \n",
      "tensor(-5.0163)\n",
      "tensor(82.3105)\n",
      "Epoch:979| Average Epoch loss:-0.15795354779740478079| Ndiff loss:-49.9869334488|Sparsity loss:49.8289799010 \n",
      "tensor(-5.0163)\n",
      "tensor(82.3238)\n",
      "Epoch:980| Average Epoch loss:-0.15796884810243247421| Ndiff loss:-49.9869486886|Sparsity loss:49.8289798405 \n",
      "tensor(-5.0163)\n",
      "tensor(82.3409)\n",
      "Epoch:981| Average Epoch loss:-0.15798410757919295611| Ndiff loss:-49.9869639782|Sparsity loss:49.8289798706 \n",
      "tensor(-5.0163)\n",
      "tensor(82.3573)\n",
      "Epoch:982| Average Epoch loss:-0.15799945475385021587| Ndiff loss:-49.9869794753|Sparsity loss:49.8289800206 \n",
      "tensor(-5.0163)\n",
      "tensor(82.3722)\n",
      "Epoch:983| Average Epoch loss:-0.15801462012737566010| Ndiff loss:-49.9869945886|Sparsity loss:49.8289799685 \n",
      "tensor(-5.0163)\n",
      "tensor(82.3901)\n",
      "Epoch:984| Average Epoch loss:-0.15802962929222827415| Ndiff loss:-49.9870097950|Sparsity loss:49.8289801657 \n",
      "tensor(-5.0163)\n",
      "tensor(82.4055)\n",
      "Epoch:985| Average Epoch loss:-0.15804450427695904136| Ndiff loss:-49.9870246515|Sparsity loss:49.8289801472 \n",
      "tensor(-5.0163)\n",
      "tensor(82.4227)\n",
      "Epoch:986| Average Epoch loss:-0.15805958228839303570| Ndiff loss:-49.9870398193|Sparsity loss:49.8289802371 \n",
      "tensor(-5.0163)\n",
      "tensor(82.4390)\n",
      "Epoch:987| Average Epoch loss:-0.15807442284079956107| Ndiff loss:-49.9870547271|Sparsity loss:49.8289803042 \n",
      "tensor(-5.0163)\n",
      "tensor(82.4547)\n",
      "Epoch:988| Average Epoch loss:-0.15808943891118609759| Ndiff loss:-49.9870698185|Sparsity loss:49.8289803796 \n",
      "tensor(-5.0163)\n",
      "tensor(82.4702)\n",
      "Epoch:989| Average Epoch loss:-0.15810429654213978279| Ndiff loss:-49.9870846786|Sparsity loss:49.8289803820 \n",
      "tensor(-5.0163)\n",
      "tensor(82.4864)\n",
      "Epoch:990| Average Epoch loss:-0.15811935806065116616| Ndiff loss:-49.9870999232|Sparsity loss:49.8289805651 \n",
      "tensor(-5.0163)\n",
      "tensor(82.5007)\n",
      "Epoch:991| Average Epoch loss:-0.15813408546691537504| Ndiff loss:-49.9871146980|Sparsity loss:49.8289806126 \n",
      "tensor(-5.0163)\n",
      "tensor(82.5153)\n",
      "Epoch:992| Average Epoch loss:-0.15814899016259983955| Ndiff loss:-49.9871296203|Sparsity loss:49.8289806302 \n",
      "tensor(-5.0163)\n",
      "tensor(82.5323)\n",
      "Epoch:993| Average Epoch loss:-0.15816364458133355675| Ndiff loss:-49.9871443606|Sparsity loss:49.8289807160 \n",
      "tensor(-5.0163)\n",
      "tensor(82.5500)\n",
      "Epoch:994| Average Epoch loss:-0.15817820860039213948| Ndiff loss:-49.9871589035|Sparsity loss:49.8289806949 \n",
      "tensor(-5.0163)\n",
      "tensor(82.5674)\n",
      "Epoch:995| Average Epoch loss:-0.15819307878475263873| Ndiff loss:-49.9871738997|Sparsity loss:49.8289808209 \n",
      "tensor(-5.0163)\n",
      "tensor(82.5827)\n",
      "Epoch:996| Average Epoch loss:-0.15820763782350549809| Ndiff loss:-49.9871885714|Sparsity loss:49.8289809336 \n",
      "tensor(-5.0163)\n",
      "tensor(82.5988)\n",
      "Epoch:997| Average Epoch loss:-0.15822241596704600397| Ndiff loss:-49.9872034605|Sparsity loss:49.8289810446 \n",
      "tensor(-5.0163)\n",
      "tensor(82.6113)\n",
      "Epoch:998| Average Epoch loss:-0.15823701727741756873| Ndiff loss:-49.9872180348|Sparsity loss:49.8289810176 \n",
      "tensor(-5.0163)\n",
      "tensor(82.6298)\n",
      "Epoch:999| Average Epoch loss:-0.15825168800582606332| Ndiff loss:-49.9872327113|Sparsity loss:49.8289810233 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-5.0163)\n",
      "tensor(82.6460)\n",
      "Epoch:1000| Average Epoch loss:-0.15826616671626286825| Ndiff loss:-49.9872473280|Sparsity loss:49.8289811612 \n",
      "tensor(-5.0163)\n",
      "tensor(82.6622)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class RegNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(500,500)\n",
    "        self.fc2 = nn.Linear(500,500)\n",
    "        self.fc3 = nn.Linear(500,1,bias=False)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.thr = nn.Sigmoid()\n",
    "        self.thr1 = nn.ReLU()\n",
    "        self.thr2 = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #x=self.thr2(self.fc1(x))\n",
    "        x=self.thr2(self.fc2(x))\n",
    "        x=self.thr(self.fc3(x))\n",
    "        return x \n",
    "\n",
    "#import hdf5storage\n",
    "#mat = hdf5storage.loadmat('wrongsource.mat') \n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('wrongsource.mat')\n",
    "\n",
    "import torch\n",
    "#import h5py\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pylab as plt\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "dtype = torch.float32\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "H_right=mat['source']\n",
    "H_wrong=mat['wsource']\n",
    "\n",
    "#Convert into torch arrays\n",
    "Hr=torch.from_numpy(H_right)\n",
    "Hw=torch.from_numpy(H_wrong)\n",
    "\n",
    "nValidation=100\n",
    "nTrain=Hr.shape[1]-nValidation\n",
    "\n",
    "print(nTrain)\n",
    "#Hr=Hr[:,0:500]\n",
    "#Hw=Hw[:,0:500]\n",
    "# initial scrambling \n",
    "perm = torch.randperm(nTrain+nValidation)\n",
    "Hr = Hr[:,perm]\n",
    "Hw = Hw[:,perm]\n",
    "\n",
    "# validation dataset\n",
    "val_r = Hr[:,-nValidation:]\n",
    "val_w = Hw[:,-nValidation:]\n",
    "\n",
    "\n",
    "N=50\n",
    "nEpochs=1000\n",
    "\n",
    "net1 = RegNet()\n",
    "net1 = net1.float()\n",
    "\n",
    "# Loss and optimizer\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.SGD(net1.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "#with torch.no_grad():\n",
    "#    net1.fc2.weight.data = torch.abs(net1.fc2.weight.data)/torch.norm(net1.fc2.weight.data,2)\n",
    "\n",
    "\n",
    "beta=0.0007\n",
    "beta1=0.0007\n",
    "beta5 = 0.0002\n",
    "for t in range(nEpochs):\n",
    "    tloss=0\n",
    "    ndloss=0\n",
    "    sploss = 0\n",
    "    perm = torch.randperm(nTrain)\n",
    "    for b_ix in np.arange(0,nTrain,N):\n",
    "        \n",
    "        \n",
    "        ##Pre-processing sparse codes for input \n",
    "        #xr=Hr[:,perm[b_ix:b_ix+N]].reshape(N,Hr.shape[0])\n",
    "        #xw=Hw[:,perm[b_ix:b_ix+N]].reshape(N,Hw.shape[0])\n",
    "        xr=Hr[:,perm[b_ix:b_ix+N]].transpose(0,1) #+ torch.rand(N,500).type(dtype=torch.float64)*0.1\n",
    "        xw=Hw[:,perm[b_ix:b_ix+N]].transpose(0,1) #+ torch.rand(N,500).type(dtype=torch.float64)*0.1\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        normr = net1(xr.float()).type(dtype=torch.float64)\n",
    "        normw = net1(xw.float()).type(dtype=torch.float64)\n",
    "        spp = beta5 *torch.abs((normr - torch.abs(torch.sum(xr,1)))).sum()\n",
    "        ndiff = (normr-normw).sum() \n",
    "        \n",
    "        \n",
    "        #loss1 = (normr-normw).sum() + beta5*torch.abs((normr.sum()-torch.sum(torch.abs(xr))))#/(N*(torch.max(torch.abs(normw-normr)))) # + beta*torch.norm(net1.fc2.weight.data,2) + beta1*torch.norm(net1.fc1.weight.data,2)\n",
    "        loss1 =  ndiff + spp\n",
    "        \n",
    "        \n",
    "       \n",
    "        # Backward and optimize\n",
    "        \n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #for p in net1.parameters():\n",
    "        #    p.data.clamp_(0)\n",
    "        #with torch.no_grad():\n",
    "        #    net1.fc1.weight.data = self.thr(net1.fc1.weight.data)  ##Projecting the weights to positive\n",
    "        #    net1.fc2.weight.data = self.thr(net1.fc2.weight.data)\n",
    "        tloss=tloss+loss1\n",
    "        ndloss = ndloss + ndiff\n",
    "        sploss = sploss + spp\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            #loss = (normw-normr).sum()/(N*(torch.max(torch.abs(normw-normr))))\n",
    "            #tl=tl+loss\n",
    "\n",
    "                \n",
    "            if b_ix / N == (nTrain/N)-1:\n",
    "                print('Epoch:{:d}| Average Epoch loss:{:.20f}| Ndiff loss:{:.10f}|Sparsity loss:{:.10f} '.format(t+1, tloss/(nTrain/N),ndloss/(nTrain/N),sploss/(nTrain/N)))\n",
    "                print(net1.fc1.weight.sum())\n",
    "                print(net1.fc2.weight.sum())\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#main problem \n",
    "import numpy as np\n",
    "import torch \n",
    "from numpy.linalg import matrix_power\n",
    "N=500\n",
    "alpha=25\n",
    "s=1/(2*alpha)\n",
    "A=torch.zeros((N,N))\n",
    "\n",
    "for i in range(0,N-1):\n",
    "    A[i,i]=1-2*s\n",
    "    A[i,i-1]=s\n",
    "    A[i,i+1]=s\n",
    "    \n",
    "\n",
    "#A[:,0]=0\n",
    "A[0,1]=0\n",
    "#A[:,N-1]=0\n",
    "#A[0,:]=0\n",
    "A[N-1,N-2]=0\n",
    "A[N-1,N-1] =1\n",
    "u=torch.zeros((N,1))\n",
    "#u[100]=50.56\n",
    "#u[130]=100.55\n",
    "#u[150]=100.55\n",
    "#u[400]=100.44\n",
    "\n",
    "k = np.random.randint(0,N-50,15)\n",
    "u[k+25] = 50*torch.rand(15,1)\n",
    "Ncount=1500\n",
    "\n",
    "Fw=torch.matrix_power(A, Ncount)\n",
    "F1=torch.matrix_power(A, 1000)\n",
    "meas=Fw@u\n",
    "measn= meas+torch.rand(meas.shape)*.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13097f62668>]"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(meas.numpy())\n",
    "plt.plot(u.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1solv(Fw1,meas):\n",
    "# Create variable.\n",
    "   x_l1 = cp.Variable(shape=(N,1))\n",
    "   constraints = [x_l1>=0]\n",
    "# Form objective.\n",
    "   obj = cp.Minimize(cp.norm(x_l1, 1)+cp.norm(Fw1.numpy()@x_l1-meas, 2)**2*1e3)\n",
    "# Form and solve problem.\n",
    "   prob = cp.Problem(obj, constraints)\n",
    "   prob.solve()\n",
    "   x2 = torch.from_numpy(x_l1.value[:,0]).cpu().type(dtype=torch.float32)\n",
    "   plt.plot(x_l1.value)\n",
    " #  return torch.norm(x2,0.1)*1e-20+torch.norm((Fw1@x2).reshape(500,1)-meas)*1e-2\n",
    "   return net1(x2)#,torch.norm((Fw1@x2).reshape(500,1)-meas)*1e-10*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.446455"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(meas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left:677.0,right:7000.0, estimation:7000.0\n",
      "left:728.0,right:7000.0, estimation:7000.0\n",
      "left:728.0,right:7000.0, estimation:7000.0\n",
      "left:728.0,right:7000.0, estimation:7000.0\n",
      "left:728.0,right:7000.0, estimation:7000.0\n",
      "left:970.0,right:7000.0, estimation:7000.0\n",
      "left:970.0,right:7000.0, estimation:7000.0\n",
      "left:1116.0,right:7000.0, estimation:7000.0\n",
      "left:1379.0,right:7000.0, estimation:7000.0\n",
      "left:1424.0,right:7000.0, estimation:7000.0\n",
      "left:1455.0,right:7000.0, estimation:7000.0\n",
      "left:1455.0,right:1729.0, estimation:1729.0\n",
      "left:1455.0,right:1729.0, estimation:1729.0\n",
      "left:1455.0,right:1729.0, estimation:1729.0\n",
      "left:1455.0,right:1635.0, estimation:1635.0\n",
      "left:1455.0,right:1635.0, estimation:1635.0\n",
      "left:1455.0,right:1635.0, estimation:1635.0\n",
      "left:1455.0,right:1620.0, estimation:1620.0\n",
      "left:1455.0,right:1620.0, estimation:1620.0\n",
      "left:1455.0,right:1612.0, estimation:1612.0\n",
      "left:1455.0,right:1612.0, estimation:1612.0\n",
      "left:1455.0,right:1612.0, estimation:1612.0\n",
      "left:1455.0,right:1612.0, estimation:1612.0\n",
      "left:1455.0,right:1612.0, estimation:1612.0\n",
      "left:1455.0,right:1612.0, estimation:1612.0\n",
      "left:1455.0,right:1506.0, estimation:1506.0\n",
      "left:1455.0,right:1506.0, estimation:1506.0\n",
      "left:1455.0,right:1506.0, estimation:1506.0\n",
      "left:1455.0,right:1506.0, estimation:1506.0\n",
      "left:1455.0,right:1506.0, estimation:1506.0\n",
      "left:1455.0,right:1506.0, estimation:1506.0\n",
      "left:1455.0,right:1506.0, estimation:1506.0\n",
      "left:1455.0,right:1506.0, estimation:1506.0\n",
      "left:1455.0,right:1483.0, estimation:1483.0\n",
      "left:1456.0,right:1483.0, estimation:1483.0\n",
      "left:1456.0,right:1483.0, estimation:1483.0\n",
      "left:1456.0,right:1483.0, estimation:1483.0\n",
      "left:1456.0,right:1483.0, estimation:1483.0\n",
      "left:1456.0,right:1483.0, estimation:1483.0\n",
      "left:1456.0,right:1483.0, estimation:1483.0\n",
      "left:1456.0,right:1483.0, estimation:1483.0\n",
      "left:1456.0,right:1483.0, estimation:1483.0\n",
      "left:1456.0,right:1483.0, estimation:1483.0\n",
      "left:1456.0,right:1483.0, estimation:1483.0\n",
      "left:1456.0,right:1483.0, estimation:1483.0\n",
      "left:1456.0,right:1483.0, estimation:1483.0\n",
      "left:1456.0,right:1483.0, estimation:1483.0\n",
      "left:1456.0,right:1483.0, estimation:1483.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-546-95ab21fa0ac1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mFl\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mthr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mFr\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mthr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m       \u001b[0mmid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlf\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m       \u001b[0mFm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml1solv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix_power\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmeas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mFm\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mthr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmid\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mlf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-544-05ee2e87fc5c>\u001b[0m in \u001b[0;36ml1solv\u001b[1;34m(Fw1, meas)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Form and solve problem.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m    \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProblem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m    \u001b[0mprob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m    \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m    \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\problems\\problem.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0msolve_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msolve_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\problems\\problem.py\u001b[0m in \u001b[0;36m_solve\u001b[1;34m(self, solver, warm_start, verbose, gp, qcp, requires_grad, enforce_dpp, **kwargs)\u001b[0m\n\u001b[0;32m    917\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m         data, solving_chain, inverse_data = self.get_problem_data(\n\u001b[1;32m--> 919\u001b[1;33m             solver, gp, enforce_dpp, verbose)\n\u001b[0m\u001b[0;32m    920\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\problems\\problem.py\u001b[0m in \u001b[0;36mget_problem_data\u001b[1;34m(self, solver, gp, enforce_dpp, verbose)\u001b[0m\n\u001b[0;32m    589\u001b[0m                     \u001b[1;34mf'{reduction_chain_str}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m                 )\n\u001b[1;32m--> 591\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minverse_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolving_chain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m             safe_to_cache = (\n\u001b[0;32m    593\u001b[0m                 \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\reductions\\chain.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, problem, verbose)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLOGGER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Applying reduction {type(r).__name__}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mproblem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             \u001b[0minverse_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mproblem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minverse_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\reductions\\dcp2cone\\cone_matrix_stuffing.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, problem)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# Batch expressions together, then split apart.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[0mexpr_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordered_cons\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mparams_to_problem_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0minverse_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mMinimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\utilities\\coeff_extractor.py\u001b[0m in \u001b[0;36maffine\u001b[1;34m(self, expr)\u001b[0m\n\u001b[0;32m     86\u001b[0m                                                  \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_to_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                                                  \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_id_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                                                  num_rows)\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextract_quadratic_coeffs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maffine_expr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquad_forms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\cvxcore\\python\\canonInterface.py\u001b[0m in \u001b[0;36mget_problem_matrix\u001b[1;34m(linOps, var_length, id_to_col, param_to_size, param_to_col, constr_length)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_V\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparam_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             I.append(tensor_I[param_id][i] +\n\u001b[1;32m--> 348\u001b[1;33m                      tensor_J[param_id][i]*constr_length)\n\u001b[0m\u001b[0;32m    349\u001b[0m             \u001b[0mJ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_J\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparam_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "lf = 500\n",
    "rb = 7000\n",
    "mid = (lf+rb)/2\n",
    "Fl = l1solv(torch.matrix_power(A, int(lf)),meas)\n",
    "Fr = l1solv(torch.matrix_power(A, int(rb)),meas)\n",
    "thr=1e-5*np.linalg.norm(meas)\n",
    "walk =300;\n",
    "for j in range(100):\n",
    "    if j==40:\n",
    "        walk = 300\n",
    "    if (Fl>thr) & (Fr<thr):\n",
    "      mid = lf + np.random.randint(-walk,walk)\n",
    "      Fm = l1solv(torch.matrix_power(A, int(mid)),meas)\n",
    "      if Fm>thr:\n",
    "        if mid > lf:\n",
    "           lf = mid\n",
    "      else:\n",
    "        if mid <rb:\n",
    "          rb = mid\n",
    "    elif Fl<thr:\n",
    "        lf = lf/2\n",
    "    else:\n",
    "        rb = rb+1000\n",
    "    print('left:{:.1f},right:{:.1f}, estimation:{:.1f}'.format(lf,rb,max(lf,rb)))\n",
    "# Create variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
